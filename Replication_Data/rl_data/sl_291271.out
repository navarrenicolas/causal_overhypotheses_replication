I am job 291271
I'm running on mcclintock
Job started at 09_11_23_22_37
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

/home/s1955786/miniconda3/envs/replication_env/lib/python3.7/site-packages/stable_baselines/__init__.py:33: UserWarning: stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.
  "stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation."
WARNING:tensorflow:From /home/s1955786/miniconda3/envs/replication_env/lib/python3.7/site-packages/stable_baselines/common/misc_util.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING:tensorflow:From /home/s1955786/miniconda3/envs/replication_env/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /home/s1955786/miniconda3/envs/replication_env/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From /home/s1955786/miniconda3/envs/replication_env/lib/python3.7/site-packages/stable_baselines/common/policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /home/s1955786/miniconda3/envs/replication_env/lib/python3.7/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/s1955786/miniconda3/envs/replication_env/lib/python3.7/site-packages/stable_baselines/common/policies.py:420: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
WARNING:tensorflow:From /home/s1955786/miniconda3/envs/replication_env/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
WARNING:tensorflow:From /home/s1955786/miniconda3/envs/replication_env/lib/python3.7/site-packages/stable_baselines/common/tf_layers.py:123: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /home/s1955786/miniconda3/envs/replication_env/lib/python3.7/site-packages/stable_baselines/common/distributions.py:326: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /home/s1955786/miniconda3/envs/replication_env/lib/python3.7/site-packages/stable_baselines/common/distributions.py:327: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From /home/s1955786/miniconda3/envs/replication_env/lib/python3.7/site-packages/stable_baselines/a2c/a2c.py:160: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /home/s1955786/miniconda3/envs/replication_env/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:449: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

WARNING:tensorflow:From /home/s1955786/miniconda3/envs/replication_env/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:449: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

WARNING:tensorflow:From /home/s1955786/miniconda3/envs/replication_env/lib/python3.7/site-packages/tensorflow_core/python/ops/clip_ops.py:301: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /home/s1955786/miniconda3/envs/replication_env/lib/python3.7/site-packages/stable_baselines/a2c/a2c.py:184: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.

WARNING:tensorflow:From /home/s1955786/miniconda3/envs/replication_env/lib/python3.7/site-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /home/s1955786/miniconda3/envs/replication_env/lib/python3.7/site-packages/stable_baselines/a2c/a2c.py:194: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /home/s1955786/miniconda3/envs/replication_env/lib/python3.7/site-packages/stable_baselines/a2c/a2c.py:196: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

WARNING:tensorflow:From /home/s1955786/miniconda3/envs/replication_env/lib/python3.7/site-packages/stable_baselines/common/base_class.py:1169: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING:tensorflow:From /home/s1955786/miniconda3/envs/replication_env/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:502: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.

---------------------------------
| explained_variance | -0.0359  |
| fps                | 17       |
| nupdates           | 1        |
| policy_entropy     | 2.71     |
| total_timesteps    | 20       |
| value_loss         | 0.219    |
---------------------------------
---------------------------------
| explained_variance | -0.708   |
| fps                | 346      |
| nupdates           | 100      |
| policy_entropy     | 2.46     |
| total_timesteps    | 2000     |
| value_loss         | 0.205    |
---------------------------------
---------------------------------
| explained_variance | -12.1    |
| fps                | 389      |
| nupdates           | 200      |
| policy_entropy     | 2.31     |
| total_timesteps    | 4000     |
| value_loss         | 0.0179   |
---------------------------------
---------------------------------
| explained_variance | -0.0217  |
| fps                | 405      |
| nupdates           | 300      |
| policy_entropy     | 2.37     |
| total_timesteps    | 6000     |
| value_loss         | 0.485    |
---------------------------------
---------------------------------
| explained_variance | -48.4    |
| fps                | 398      |
| nupdates           | 400      |
| policy_entropy     | 2.23     |
| total_timesteps    | 8000     |
| value_loss         | 0.00648  |
---------------------------------
---------------------------------
| explained_variance | -85.1    |
| fps                | 406      |
| nupdates           | 500      |
| policy_entropy     | 2.35     |
| total_timesteps    | 10000    |
| value_loss         | 0.00851  |
---------------------------------
---------------------------------
| explained_variance | -2.15    |
| fps                | 412      |
| nupdates           | 600      |
| policy_entropy     | 2.16     |
| total_timesteps    | 12000    |
| value_loss         | 0.00651  |
---------------------------------
---------------------------------
| explained_variance | -3       |
| fps                | 417      |
| nupdates           | 700      |
| policy_entropy     | 2.26     |
| total_timesteps    | 14000    |
| value_loss         | 0.00168  |
---------------------------------
---------------------------------
| explained_variance | -126     |
| fps                | 419      |
| nupdates           | 800      |
| policy_entropy     | 2.25     |
| total_timesteps    | 16000    |
| value_loss         | 0.00555  |
---------------------------------
---------------------------------
| explained_variance | -0.527   |
| fps                | 422      |
| nupdates           | 900      |
| policy_entropy     | 2.21     |
| total_timesteps    | 18000    |
| value_loss         | 0.00441  |
---------------------------------
Eval num_timesteps=20000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
New best mean reward!
---------------------------------
| explained_variance | -27      |
| fps                | 418      |
| nupdates           | 1000     |
| policy_entropy     | 1.97     |
| total_timesteps    | 20000    |
| value_loss         | 0.0209   |
---------------------------------
---------------------------------
| explained_variance | -1.44    |
| fps                | 421      |
| nupdates           | 1100     |
| policy_entropy     | 1.92     |
| total_timesteps    | 22000    |
| value_loss         | 0.0438   |
---------------------------------
---------------------------------
| explained_variance | -1.41    |
| fps                | 422      |
| nupdates           | 1200     |
| policy_entropy     | 1.98     |
| total_timesteps    | 24000    |
| value_loss         | 0.0254   |
---------------------------------
---------------------------------
| explained_variance | -0.0272  |
| fps                | 424      |
| nupdates           | 1300     |
| policy_entropy     | 1.96     |
| total_timesteps    | 26000    |
| value_loss         | 0.0207   |
---------------------------------
---------------------------------
| explained_variance | -144     |
| fps                | 425      |
| nupdates           | 1400     |
| policy_entropy     | 2.01     |
| total_timesteps    | 28000    |
| value_loss         | 0.00269  |
---------------------------------
---------------------------------
| explained_variance | 0.175    |
| fps                | 426      |
| nupdates           | 1500     |
| policy_entropy     | 1.9      |
| total_timesteps    | 30000    |
| value_loss         | 0.00879  |
---------------------------------
---------------------------------
| explained_variance | -1.58    |
| fps                | 428      |
| nupdates           | 1600     |
| policy_entropy     | 2.32     |
| total_timesteps    | 32000    |
| value_loss         | 0.000999 |
---------------------------------
---------------------------------
| explained_variance | 0.202    |
| fps                | 429      |
| nupdates           | 1700     |
| policy_entropy     | 2.31     |
| total_timesteps    | 34000    |
| value_loss         | 0.00224  |
---------------------------------
---------------------------------
| explained_variance | -6.22    |
| fps                | 430      |
| nupdates           | 1800     |
| policy_entropy     | 2.32     |
| total_timesteps    | 36000    |
| value_loss         | 0.000306 |
---------------------------------
---------------------------------
| explained_variance | -29.2    |
| fps                | 430      |
| nupdates           | 1900     |
| policy_entropy     | 2.34     |
| total_timesteps    | 38000    |
| value_loss         | 0.00452  |
---------------------------------
Eval num_timesteps=40000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -3.04    |
| fps                | 429      |
| nupdates           | 2000     |
| policy_entropy     | 2.36     |
| total_timesteps    | 40000    |
| value_loss         | 8.88e-05 |
---------------------------------
---------------------------------
| explained_variance | -3.21    |
| fps                | 430      |
| nupdates           | 2100     |
| policy_entropy     | 2.38     |
| total_timesteps    | 42000    |
| value_loss         | 0.00117  |
---------------------------------
---------------------------------
| explained_variance | -64.8    |
| fps                | 431      |
| nupdates           | 2200     |
| policy_entropy     | 2.15     |
| total_timesteps    | 44000    |
| value_loss         | 0.00119  |
---------------------------------
---------------------------------
| explained_variance | -0.369   |
| fps                | 431      |
| nupdates           | 2300     |
| policy_entropy     | 2.4      |
| total_timesteps    | 46000    |
| value_loss         | 0.00138  |
---------------------------------
---------------------------------
| explained_variance | 0.306    |
| fps                | 432      |
| nupdates           | 2400     |
| policy_entropy     | 2.44     |
| total_timesteps    | 48000    |
| value_loss         | 0.000719 |
---------------------------------
---------------------------------
| explained_variance | -2.38    |
| fps                | 432      |
| nupdates           | 2500     |
| policy_entropy     | 2.32     |
| total_timesteps    | 50000    |
| value_loss         | 0.00372  |
---------------------------------
---------------------------------
| explained_variance | -0.833   |
| fps                | 433      |
| nupdates           | 2600     |
| policy_entropy     | 2.43     |
| total_timesteps    | 52000    |
| value_loss         | 0.0105   |
---------------------------------
---------------------------------
| explained_variance | -0.246   |
| fps                | 433      |
| nupdates           | 2700     |
| policy_entropy     | 2.44     |
| total_timesteps    | 54000    |
| value_loss         | 0.000509 |
---------------------------------
---------------------------------
| explained_variance | -1.53    |
| fps                | 434      |
| nupdates           | 2800     |
| policy_entropy     | 2.4      |
| total_timesteps    | 56000    |
| value_loss         | 0.000484 |
---------------------------------
---------------------------------
| explained_variance | 0.21     |
| fps                | 434      |
| nupdates           | 2900     |
| policy_entropy     | 2.34     |
| total_timesteps    | 58000    |
| value_loss         | 3.29e-05 |
---------------------------------
Eval num_timesteps=60000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -0.423   |
| fps                | 433      |
| nupdates           | 3000     |
| policy_entropy     | 2.43     |
| total_timesteps    | 60000    |
| value_loss         | 6.17e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.83    |
| fps                | 434      |
| nupdates           | 3100     |
| policy_entropy     | 2.48     |
| total_timesteps    | 62000    |
| value_loss         | 0.00234  |
---------------------------------
---------------------------------
| explained_variance | 0.149    |
| fps                | 434      |
| nupdates           | 3200     |
| policy_entropy     | 2.47     |
| total_timesteps    | 64000    |
| value_loss         | 0.000171 |
---------------------------------
---------------------------------
| explained_variance | -1.04    |
| fps                | 434      |
| nupdates           | 3300     |
| policy_entropy     | 2.39     |
| total_timesteps    | 66000    |
| value_loss         | 0.000226 |
---------------------------------
---------------------------------
| explained_variance | -0.392   |
| fps                | 435      |
| nupdates           | 3400     |
| policy_entropy     | 2.46     |
| total_timesteps    | 68000    |
| value_loss         | 0.00026  |
---------------------------------
---------------------------------
| explained_variance | 0.128    |
| fps                | 435      |
| nupdates           | 3500     |
| policy_entropy     | 2.47     |
| total_timesteps    | 70000    |
| value_loss         | 5.9e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.409    |
| fps                | 436      |
| nupdates           | 3600     |
| policy_entropy     | 2.36     |
| total_timesteps    | 72000    |
| value_loss         | 1.86e-05 |
---------------------------------
---------------------------------
| explained_variance | -5.02    |
| fps                | 436      |
| nupdates           | 3700     |
| policy_entropy     | 2.43     |
| total_timesteps    | 74000    |
| value_loss         | 0.000618 |
---------------------------------
---------------------------------
| explained_variance | -0.764   |
| fps                | 436      |
| nupdates           | 3800     |
| policy_entropy     | 2.36     |
| total_timesteps    | 76000    |
| value_loss         | 2.44e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.777   |
| fps                | 436      |
| nupdates           | 3900     |
| policy_entropy     | 2.48     |
| total_timesteps    | 78000    |
| value_loss         | 0.00129  |
---------------------------------
Eval num_timesteps=80000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -17.3    |
| fps                | 436      |
| nupdates           | 4000     |
| policy_entropy     | 2.33     |
| total_timesteps    | 80000    |
| value_loss         | 0.00104  |
---------------------------------
---------------------------------
| explained_variance | -19.8    |
| fps                | 436      |
| nupdates           | 4100     |
| policy_entropy     | 2.31     |
| total_timesteps    | 82000    |
| value_loss         | 0.00039  |
---------------------------------
---------------------------------
| explained_variance | -2.65    |
| fps                | 436      |
| nupdates           | 4200     |
| policy_entropy     | 2.35     |
| total_timesteps    | 84000    |
| value_loss         | 0.000281 |
---------------------------------
---------------------------------
| explained_variance | -3.63    |
| fps                | 437      |
| nupdates           | 4300     |
| policy_entropy     | 2.39     |
| total_timesteps    | 86000    |
| value_loss         | 0.000697 |
---------------------------------
---------------------------------
| explained_variance | -0.47    |
| fps                | 437      |
| nupdates           | 4400     |
| policy_entropy     | 2.43     |
| total_timesteps    | 88000    |
| value_loss         | 0.000426 |
---------------------------------
---------------------------------
| explained_variance | -1.89    |
| fps                | 437      |
| nupdates           | 4500     |
| policy_entropy     | 2.46     |
| total_timesteps    | 90000    |
| value_loss         | 0.000123 |
---------------------------------
---------------------------------
| explained_variance | -0.198   |
| fps                | 437      |
| nupdates           | 4600     |
| policy_entropy     | 2.43     |
| total_timesteps    | 92000    |
| value_loss         | 3.99e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.185    |
| fps                | 437      |
| nupdates           | 4700     |
| policy_entropy     | 2.38     |
| total_timesteps    | 94000    |
| value_loss         | 4.06e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.431    |
| fps                | 437      |
| nupdates           | 4800     |
| policy_entropy     | 2.48     |
| total_timesteps    | 96000    |
| value_loss         | 2.22e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.2     |
| fps                | 437      |
| nupdates           | 4900     |
| policy_entropy     | 2.45     |
| total_timesteps    | 98000    |
| value_loss         | 0.000756 |
---------------------------------
Eval num_timesteps=100000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -3.57    |
| fps                | 437      |
| nupdates           | 5000     |
| policy_entropy     | 2.47     |
| total_timesteps    | 100000   |
| value_loss         | 8.97e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.0674  |
| fps                | 436      |
| nupdates           | 5100     |
| policy_entropy     | 2.39     |
| total_timesteps    | 102000   |
| value_loss         | 8.43e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.538    |
| fps                | 436      |
| nupdates           | 5200     |
| policy_entropy     | 2.44     |
| total_timesteps    | 104000   |
| value_loss         | 5.78e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.201    |
| fps                | 435      |
| nupdates           | 5300     |
| policy_entropy     | 2.56     |
| total_timesteps    | 106000   |
| value_loss         | 0.000181 |
---------------------------------
---------------------------------
| explained_variance | -0.963   |
| fps                | 435      |
| nupdates           | 5400     |
| policy_entropy     | 2.46     |
| total_timesteps    | 108000   |
| value_loss         | 0.00057  |
---------------------------------
---------------------------------
| explained_variance | -0.236   |
| fps                | 434      |
| nupdates           | 5500     |
| policy_entropy     | 2.46     |
| total_timesteps    | 110000   |
| value_loss         | 0.000336 |
---------------------------------
---------------------------------
| explained_variance | -1.58    |
| fps                | 434      |
| nupdates           | 5600     |
| policy_entropy     | 2.44     |
| total_timesteps    | 112000   |
| value_loss         | 7.28e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.0865   |
| fps                | 435      |
| nupdates           | 5700     |
| policy_entropy     | 2.37     |
| total_timesteps    | 114000   |
| value_loss         | 0.000115 |
---------------------------------
---------------------------------
| explained_variance | -15.3    |
| fps                | 435      |
| nupdates           | 5800     |
| policy_entropy     | 2.42     |
| total_timesteps    | 116000   |
| value_loss         | 0.000544 |
---------------------------------
---------------------------------
| explained_variance | -1.59    |
| fps                | 435      |
| nupdates           | 5900     |
| policy_entropy     | 2.44     |
| total_timesteps    | 118000   |
| value_loss         | 0.000145 |
---------------------------------
Eval num_timesteps=120000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -0.108   |
| fps                | 435      |
| nupdates           | 6000     |
| policy_entropy     | 2.41     |
| total_timesteps    | 120000   |
| value_loss         | 0.000274 |
---------------------------------
---------------------------------
| explained_variance | -0.00355 |
| fps                | 435      |
| nupdates           | 6100     |
| policy_entropy     | 2.43     |
| total_timesteps    | 122000   |
| value_loss         | 0.000159 |
---------------------------------
---------------------------------
| explained_variance | -0.907   |
| fps                | 435      |
| nupdates           | 6200     |
| policy_entropy     | 2.45     |
| total_timesteps    | 124000   |
| value_loss         | 0.000623 |
---------------------------------
---------------------------------
| explained_variance | -0.651   |
| fps                | 435      |
| nupdates           | 6300     |
| policy_entropy     | 2.37     |
| total_timesteps    | 126000   |
| value_loss         | 1.99e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.214    |
| fps                | 435      |
| nupdates           | 6400     |
| policy_entropy     | 2.5      |
| total_timesteps    | 128000   |
| value_loss         | 9.99e-05 |
---------------------------------
---------------------------------
| explained_variance | -2.96    |
| fps                | 435      |
| nupdates           | 6500     |
| policy_entropy     | 2.45     |
| total_timesteps    | 130000   |
| value_loss         | 0.000178 |
---------------------------------
---------------------------------
| explained_variance | 0.626    |
| fps                | 436      |
| nupdates           | 6600     |
| policy_entropy     | 2.43     |
| total_timesteps    | 132000   |
| value_loss         | 1.32e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.557    |
| fps                | 436      |
| nupdates           | 6700     |
| policy_entropy     | 2.42     |
| total_timesteps    | 134000   |
| value_loss         | 3.18e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.11    |
| fps                | 436      |
| nupdates           | 6800     |
| policy_entropy     | 2.45     |
| total_timesteps    | 136000   |
| value_loss         | 0.000446 |
---------------------------------
---------------------------------
| explained_variance | -1.43    |
| fps                | 436      |
| nupdates           | 6900     |
| policy_entropy     | 2.4      |
| total_timesteps    | 138000   |
| value_loss         | 0.000904 |
---------------------------------
Eval num_timesteps=140000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -0.797   |
| fps                | 436      |
| nupdates           | 7000     |
| policy_entropy     | 2.42     |
| total_timesteps    | 140000   |
| value_loss         | 0.000447 |
---------------------------------
---------------------------------
| explained_variance | -3.32    |
| fps                | 436      |
| nupdates           | 7100     |
| policy_entropy     | 2.37     |
| total_timesteps    | 142000   |
| value_loss         | 0.000716 |
---------------------------------
---------------------------------
| explained_variance | -0.0928  |
| fps                | 436      |
| nupdates           | 7200     |
| policy_entropy     | 2.45     |
| total_timesteps    | 144000   |
| value_loss         | 0.000213 |
---------------------------------
---------------------------------
| explained_variance | -4.46    |
| fps                | 436      |
| nupdates           | 7300     |
| policy_entropy     | 2.47     |
| total_timesteps    | 146000   |
| value_loss         | 0.000107 |
---------------------------------
---------------------------------
| explained_variance | 0.216    |
| fps                | 437      |
| nupdates           | 7400     |
| policy_entropy     | 2.46     |
| total_timesteps    | 148000   |
| value_loss         | 0.00015  |
---------------------------------
---------------------------------
| explained_variance | -0.937   |
| fps                | 437      |
| nupdates           | 7500     |
| policy_entropy     | 2.46     |
| total_timesteps    | 150000   |
| value_loss         | 0.000351 |
---------------------------------
---------------------------------
| explained_variance | -8       |
| fps                | 437      |
| nupdates           | 7600     |
| policy_entropy     | 2.46     |
| total_timesteps    | 152000   |
| value_loss         | 0.000107 |
---------------------------------
---------------------------------
| explained_variance | 0.215    |
| fps                | 437      |
| nupdates           | 7700     |
| policy_entropy     | 2.5      |
| total_timesteps    | 154000   |
| value_loss         | 7.89e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.38    |
| fps                | 437      |
| nupdates           | 7800     |
| policy_entropy     | 2.47     |
| total_timesteps    | 156000   |
| value_loss         | 4.5e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.425    |
| fps                | 437      |
| nupdates           | 7900     |
| policy_entropy     | 2.42     |
| total_timesteps    | 158000   |
| value_loss         | 9.43e-06 |
---------------------------------
Eval num_timesteps=160000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.597    |
| fps                | 437      |
| nupdates           | 8000     |
| policy_entropy     | 2.43     |
| total_timesteps    | 160000   |
| value_loss         | 1.33e-05 |
---------------------------------
---------------------------------
| explained_variance | -12.4    |
| fps                | 437      |
| nupdates           | 8100     |
| policy_entropy     | 2.39     |
| total_timesteps    | 162000   |
| value_loss         | 0.000183 |
---------------------------------
---------------------------------
| explained_variance | 0.0177   |
| fps                | 437      |
| nupdates           | 8200     |
| policy_entropy     | 2.42     |
| total_timesteps    | 164000   |
| value_loss         | 1.63e-05 |
---------------------------------
---------------------------------
| explained_variance | -6.74    |
| fps                | 438      |
| nupdates           | 8300     |
| policy_entropy     | 2.46     |
| total_timesteps    | 166000   |
| value_loss         | 0.000195 |
---------------------------------
---------------------------------
| explained_variance | -2.78    |
| fps                | 438      |
| nupdates           | 8400     |
| policy_entropy     | 2.46     |
| total_timesteps    | 168000   |
| value_loss         | 0.000164 |
---------------------------------
---------------------------------
| explained_variance | 0.0672   |
| fps                | 438      |
| nupdates           | 8500     |
| policy_entropy     | 2.54     |
| total_timesteps    | 170000   |
| value_loss         | 0.000125 |
---------------------------------
---------------------------------
| explained_variance | -2.23    |
| fps                | 438      |
| nupdates           | 8600     |
| policy_entropy     | 2.46     |
| total_timesteps    | 172000   |
| value_loss         | 0.00196  |
---------------------------------
---------------------------------
| explained_variance | -0.776   |
| fps                | 438      |
| nupdates           | 8700     |
| policy_entropy     | 2.45     |
| total_timesteps    | 174000   |
| value_loss         | 4.5e-05  |
---------------------------------
---------------------------------
| explained_variance | -2.89    |
| fps                | 438      |
| nupdates           | 8800     |
| policy_entropy     | 2.47     |
| total_timesteps    | 176000   |
| value_loss         | 0.000927 |
---------------------------------
---------------------------------
| explained_variance | 0.299    |
| fps                | 438      |
| nupdates           | 8900     |
| policy_entropy     | 2.45     |
| total_timesteps    | 178000   |
| value_loss         | 7e-05    |
---------------------------------
Eval num_timesteps=180000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.128    |
| fps                | 438      |
| nupdates           | 9000     |
| policy_entropy     | 2.49     |
| total_timesteps    | 180000   |
| value_loss         | 2.42e-05 |
---------------------------------
---------------------------------
| explained_variance | -4.13    |
| fps                | 438      |
| nupdates           | 9100     |
| policy_entropy     | 2.43     |
| total_timesteps    | 182000   |
| value_loss         | 0.000759 |
---------------------------------
---------------------------------
| explained_variance | -2.07    |
| fps                | 438      |
| nupdates           | 9200     |
| policy_entropy     | 2.49     |
| total_timesteps    | 184000   |
| value_loss         | 0.000202 |
---------------------------------
---------------------------------
| explained_variance | -1.16    |
| fps                | 438      |
| nupdates           | 9300     |
| policy_entropy     | 2.42     |
| total_timesteps    | 186000   |
| value_loss         | 4.94e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.66    |
| fps                | 438      |
| nupdates           | 9400     |
| policy_entropy     | 2.37     |
| total_timesteps    | 188000   |
| value_loss         | 0.000689 |
---------------------------------
---------------------------------
| explained_variance | -8.12    |
| fps                | 439      |
| nupdates           | 9500     |
| policy_entropy     | 2.28     |
| total_timesteps    | 190000   |
| value_loss         | 0.00172  |
---------------------------------
---------------------------------
| explained_variance | -2.18    |
| fps                | 439      |
| nupdates           | 9600     |
| policy_entropy     | 2.41     |
| total_timesteps    | 192000   |
| value_loss         | 0.000586 |
---------------------------------
---------------------------------
| explained_variance | -1.03    |
| fps                | 439      |
| nupdates           | 9700     |
| policy_entropy     | 2.42     |
| total_timesteps    | 194000   |
| value_loss         | 5.74e-05 |
---------------------------------
---------------------------------
| explained_variance | -3.27    |
| fps                | 439      |
| nupdates           | 9800     |
| policy_entropy     | 2.39     |
| total_timesteps    | 196000   |
| value_loss         | 0.00022  |
---------------------------------
---------------------------------
| explained_variance | -1.64    |
| fps                | 439      |
| nupdates           | 9900     |
| policy_entropy     | 2.49     |
| total_timesteps    | 198000   |
| value_loss         | 5e-05    |
---------------------------------
Eval num_timesteps=200000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -1.16    |
| fps                | 439      |
| nupdates           | 10000    |
| policy_entropy     | 2.49     |
| total_timesteps    | 200000   |
| value_loss         | 0.000145 |
---------------------------------
---------------------------------
| explained_variance | -0.532   |
| fps                | 439      |
| nupdates           | 10100    |
| policy_entropy     | 2.44     |
| total_timesteps    | 202000   |
| value_loss         | 2.43e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.351    |
| fps                | 439      |
| nupdates           | 10200    |
| policy_entropy     | 2.46     |
| total_timesteps    | 204000   |
| value_loss         | 2.59e-05 |
---------------------------------
---------------------------------
| explained_variance | -2.64    |
| fps                | 439      |
| nupdates           | 10300    |
| policy_entropy     | 2.45     |
| total_timesteps    | 206000   |
| value_loss         | 6.87e-05 |
---------------------------------
---------------------------------
| explained_variance | -13.5    |
| fps                | 439      |
| nupdates           | 10400    |
| policy_entropy     | 2.41     |
| total_timesteps    | 208000   |
| value_loss         | 0.00026  |
---------------------------------
---------------------------------
| explained_variance | 0.313    |
| fps                | 439      |
| nupdates           | 10500    |
| policy_entropy     | 2.41     |
| total_timesteps    | 210000   |
| value_loss         | 8.84e-06 |
---------------------------------
---------------------------------
| explained_variance | -4.2     |
| fps                | 439      |
| nupdates           | 10600    |
| policy_entropy     | 2.43     |
| total_timesteps    | 212000   |
| value_loss         | 0.000129 |
---------------------------------
---------------------------------
| explained_variance | 0.654    |
| fps                | 439      |
| nupdates           | 10700    |
| policy_entropy     | 2.44     |
| total_timesteps    | 214000   |
| value_loss         | 1.02e-05 |
---------------------------------
---------------------------------
| explained_variance | -7.9     |
| fps                | 439      |
| nupdates           | 10800    |
| policy_entropy     | 2.42     |
| total_timesteps    | 216000   |
| value_loss         | 7.72e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.231    |
| fps                | 439      |
| nupdates           | 10900    |
| policy_entropy     | 2.42     |
| total_timesteps    | 218000   |
| value_loss         | 0.000122 |
---------------------------------
Eval num_timesteps=220000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -8.55    |
| fps                | 439      |
| nupdates           | 11000    |
| policy_entropy     | 2.39     |
| total_timesteps    | 220000   |
| value_loss         | 0.000459 |
---------------------------------
---------------------------------
| explained_variance | 0.143    |
| fps                | 439      |
| nupdates           | 11100    |
| policy_entropy     | 2.43     |
| total_timesteps    | 222000   |
| value_loss         | 0.000139 |
---------------------------------
---------------------------------
| explained_variance | -0.116   |
| fps                | 439      |
| nupdates           | 11200    |
| policy_entropy     | 2.45     |
| total_timesteps    | 224000   |
| value_loss         | 2.8e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.144    |
| fps                | 440      |
| nupdates           | 11300    |
| policy_entropy     | 2.52     |
| total_timesteps    | 226000   |
| value_loss         | 1.95e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.793   |
| fps                | 440      |
| nupdates           | 11400    |
| policy_entropy     | 2.48     |
| total_timesteps    | 228000   |
| value_loss         | 0.000126 |
---------------------------------
---------------------------------
| explained_variance | -0.874   |
| fps                | 440      |
| nupdates           | 11500    |
| policy_entropy     | 2.49     |
| total_timesteps    | 230000   |
| value_loss         | 0.000334 |
---------------------------------
---------------------------------
| explained_variance | -2.1     |
| fps                | 440      |
| nupdates           | 11600    |
| policy_entropy     | 2.49     |
| total_timesteps    | 232000   |
| value_loss         | 0.000138 |
---------------------------------
---------------------------------
| explained_variance | -0.753   |
| fps                | 440      |
| nupdates           | 11700    |
| policy_entropy     | 2.46     |
| total_timesteps    | 234000   |
| value_loss         | 5.12e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.45    |
| fps                | 440      |
| nupdates           | 11800    |
| policy_entropy     | 2.46     |
| total_timesteps    | 236000   |
| value_loss         | 0.000389 |
---------------------------------
---------------------------------
| explained_variance | 0.33     |
| fps                | 440      |
| nupdates           | 11900    |
| policy_entropy     | 2.42     |
| total_timesteps    | 238000   |
| value_loss         | 0.000113 |
---------------------------------
Eval num_timesteps=240000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -0.0809  |
| fps                | 440      |
| nupdates           | 12000    |
| policy_entropy     | 2.42     |
| total_timesteps    | 240000   |
| value_loss         | 6.7e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.0986   |
| fps                | 440      |
| nupdates           | 12100    |
| policy_entropy     | 2.49     |
| total_timesteps    | 242000   |
| value_loss         | 0.00026  |
---------------------------------
---------------------------------
| explained_variance | 0.391    |
| fps                | 440      |
| nupdates           | 12200    |
| policy_entropy     | 2.49     |
| total_timesteps    | 244000   |
| value_loss         | 4.29e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.654    |
| fps                | 440      |
| nupdates           | 12300    |
| policy_entropy     | 2.43     |
| total_timesteps    | 246000   |
| value_loss         | 6.78e-06 |
---------------------------------
---------------------------------
| explained_variance | -2.18    |
| fps                | 440      |
| nupdates           | 12400    |
| policy_entropy     | 2.48     |
| total_timesteps    | 248000   |
| value_loss         | 0.000437 |
---------------------------------
---------------------------------
| explained_variance | -0.0943  |
| fps                | 440      |
| nupdates           | 12500    |
| policy_entropy     | 2.49     |
| total_timesteps    | 250000   |
| value_loss         | 2.88e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.0585  |
| fps                | 440      |
| nupdates           | 12600    |
| policy_entropy     | 2.43     |
| total_timesteps    | 252000   |
| value_loss         | 0.000122 |
---------------------------------
---------------------------------
| explained_variance | -0.851   |
| fps                | 440      |
| nupdates           | 12700    |
| policy_entropy     | 2.45     |
| total_timesteps    | 254000   |
| value_loss         | 0.000353 |
---------------------------------
---------------------------------
| explained_variance | -0.276   |
| fps                | 440      |
| nupdates           | 12800    |
| policy_entropy     | 2.46     |
| total_timesteps    | 256000   |
| value_loss         | 5.05e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.772    |
| fps                | 440      |
| nupdates           | 12900    |
| policy_entropy     | 2.4      |
| total_timesteps    | 258000   |
| value_loss         | 4.1e-06  |
---------------------------------
Eval num_timesteps=260000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.426    |
| fps                | 440      |
| nupdates           | 13000    |
| policy_entropy     | 2.46     |
| total_timesteps    | 260000   |
| value_loss         | 1.1e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.222    |
| fps                | 440      |
| nupdates           | 13100    |
| policy_entropy     | 2.55     |
| total_timesteps    | 262000   |
| value_loss         | 0.000325 |
---------------------------------
---------------------------------
| explained_variance | -0.136   |
| fps                | 440      |
| nupdates           | 13200    |
| policy_entropy     | 2.52     |
| total_timesteps    | 264000   |
| value_loss         | 8.61e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.664   |
| fps                | 440      |
| nupdates           | 13300    |
| policy_entropy     | 2.44     |
| total_timesteps    | 266000   |
| value_loss         | 0.00014  |
---------------------------------
---------------------------------
| explained_variance | 0.339    |
| fps                | 440      |
| nupdates           | 13400    |
| policy_entropy     | 2.52     |
| total_timesteps    | 268000   |
| value_loss         | 0.000335 |
---------------------------------
---------------------------------
| explained_variance | 0.522    |
| fps                | 441      |
| nupdates           | 13500    |
| policy_entropy     | 2.5      |
| total_timesteps    | 270000   |
| value_loss         | 9.55e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.3      |
| fps                | 441      |
| nupdates           | 13600    |
| policy_entropy     | 2.46     |
| total_timesteps    | 272000   |
| value_loss         | 9.43e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.514   |
| fps                | 441      |
| nupdates           | 13700    |
| policy_entropy     | 2.46     |
| total_timesteps    | 274000   |
| value_loss         | 2.81e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.304    |
| fps                | 441      |
| nupdates           | 13800    |
| policy_entropy     | 2.49     |
| total_timesteps    | 276000   |
| value_loss         | 3.59e-05 |
---------------------------------
---------------------------------
| explained_variance | -3.31    |
| fps                | 441      |
| nupdates           | 13900    |
| policy_entropy     | 2.43     |
| total_timesteps    | 278000   |
| value_loss         | 0.0011   |
---------------------------------
Eval num_timesteps=280000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -0.0573  |
| fps                | 441      |
| nupdates           | 14000    |
| policy_entropy     | 2.47     |
| total_timesteps    | 280000   |
| value_loss         | 0.000174 |
---------------------------------
---------------------------------
| explained_variance | 0.423    |
| fps                | 441      |
| nupdates           | 14100    |
| policy_entropy     | 2.47     |
| total_timesteps    | 282000   |
| value_loss         | 1.61e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.0343  |
| fps                | 441      |
| nupdates           | 14200    |
| policy_entropy     | 2.43     |
| total_timesteps    | 284000   |
| value_loss         | 4.77e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.486    |
| fps                | 441      |
| nupdates           | 14300    |
| policy_entropy     | 2.46     |
| total_timesteps    | 286000   |
| value_loss         | 1.62e-05 |
---------------------------------
---------------------------------
| explained_variance | -2.37    |
| fps                | 441      |
| nupdates           | 14400    |
| policy_entropy     | 2.4      |
| total_timesteps    | 288000   |
| value_loss         | 2.22e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.145    |
| fps                | 441      |
| nupdates           | 14500    |
| policy_entropy     | 2.49     |
| total_timesteps    | 290000   |
| value_loss         | 9.14e-05 |
---------------------------------
---------------------------------
| explained_variance | -4.01    |
| fps                | 441      |
| nupdates           | 14600    |
| policy_entropy     | 2.44     |
| total_timesteps    | 292000   |
| value_loss         | 0.000198 |
---------------------------------
---------------------------------
| explained_variance | -0.0119  |
| fps                | 441      |
| nupdates           | 14700    |
| policy_entropy     | 2.44     |
| total_timesteps    | 294000   |
| value_loss         | 3.24e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.511    |
| fps                | 441      |
| nupdates           | 14800    |
| policy_entropy     | 2.49     |
| total_timesteps    | 296000   |
| value_loss         | 1.61e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.637    |
| fps                | 441      |
| nupdates           | 14900    |
| policy_entropy     | 2.39     |
| total_timesteps    | 298000   |
| value_loss         | 4.96e-06 |
---------------------------------
Eval num_timesteps=300000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.317    |
| fps                | 441      |
| nupdates           | 15000    |
| policy_entropy     | 2.49     |
| total_timesteps    | 300000   |
| value_loss         | 3.97e-05 |
---------------------------------
---------------------------------
| explained_variance | -7.32    |
| fps                | 441      |
| nupdates           | 15100    |
| policy_entropy     | 2.39     |
| total_timesteps    | 302000   |
| value_loss         | 6.16e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.303    |
| fps                | 441      |
| nupdates           | 15200    |
| policy_entropy     | 2.49     |
| total_timesteps    | 304000   |
| value_loss         | 4.51e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.185    |
| fps                | 441      |
| nupdates           | 15300    |
| policy_entropy     | 2.46     |
| total_timesteps    | 306000   |
| value_loss         | 1.87e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.411    |
| fps                | 441      |
| nupdates           | 15400    |
| policy_entropy     | 2.39     |
| total_timesteps    | 308000   |
| value_loss         | 1.33e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.105   |
| fps                | 441      |
| nupdates           | 15500    |
| policy_entropy     | 2.46     |
| total_timesteps    | 310000   |
| value_loss         | 6.93e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.0379  |
| fps                | 441      |
| nupdates           | 15600    |
| policy_entropy     | 2.44     |
| total_timesteps    | 312000   |
| value_loss         | 8.33e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.17    |
| fps                | 441      |
| nupdates           | 15700    |
| policy_entropy     | 2.4      |
| total_timesteps    | 314000   |
| value_loss         | 0.00182  |
---------------------------------
---------------------------------
| explained_variance | 0.614    |
| fps                | 441      |
| nupdates           | 15800    |
| policy_entropy     | 2.45     |
| total_timesteps    | 316000   |
| value_loss         | 1.55e-05 |
---------------------------------
---------------------------------
| explained_variance | -2.76    |
| fps                | 442      |
| nupdates           | 15900    |
| policy_entropy     | 2.42     |
| total_timesteps    | 318000   |
| value_loss         | 0.000636 |
---------------------------------
Eval num_timesteps=320000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.786    |
| fps                | 441      |
| nupdates           | 16000    |
| policy_entropy     | 2.39     |
| total_timesteps    | 320000   |
| value_loss         | 5.73e-06 |
---------------------------------
---------------------------------
| explained_variance | -0.147   |
| fps                | 441      |
| nupdates           | 16100    |
| policy_entropy     | 2.5      |
| total_timesteps    | 322000   |
| value_loss         | 0.000129 |
---------------------------------
---------------------------------
| explained_variance | -0.402   |
| fps                | 441      |
| nupdates           | 16200    |
| policy_entropy     | 2.44     |
| total_timesteps    | 324000   |
| value_loss         | 0.000155 |
---------------------------------
---------------------------------
| explained_variance | 0.374    |
| fps                | 442      |
| nupdates           | 16300    |
| policy_entropy     | 2.47     |
| total_timesteps    | 326000   |
| value_loss         | 2.15e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.137   |
| fps                | 442      |
| nupdates           | 16400    |
| policy_entropy     | 2.47     |
| total_timesteps    | 328000   |
| value_loss         | 4.11e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.629   |
| fps                | 442      |
| nupdates           | 16500    |
| policy_entropy     | 2.39     |
| total_timesteps    | 330000   |
| value_loss         | 7.28e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.415    |
| fps                | 442      |
| nupdates           | 16600    |
| policy_entropy     | 2.42     |
| total_timesteps    | 332000   |
| value_loss         | 4.66e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.111    |
| fps                | 442      |
| nupdates           | 16700    |
| policy_entropy     | 2.49     |
| total_timesteps    | 334000   |
| value_loss         | 5.12e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.288   |
| fps                | 442      |
| nupdates           | 16800    |
| policy_entropy     | 2.48     |
| total_timesteps    | 336000   |
| value_loss         | 0.000107 |
---------------------------------
---------------------------------
| explained_variance | 0.344    |
| fps                | 442      |
| nupdates           | 16900    |
| policy_entropy     | 2.48     |
| total_timesteps    | 338000   |
| value_loss         | 4.03e-05 |
---------------------------------
Eval num_timesteps=340000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.177    |
| fps                | 442      |
| nupdates           | 17000    |
| policy_entropy     | 2.44     |
| total_timesteps    | 340000   |
| value_loss         | 8.51e-05 |
---------------------------------
---------------------------------
| explained_variance | -2.3     |
| fps                | 442      |
| nupdates           | 17100    |
| policy_entropy     | 2.48     |
| total_timesteps    | 342000   |
| value_loss         | 0.000237 |
---------------------------------
---------------------------------
| explained_variance | -2.62    |
| fps                | 442      |
| nupdates           | 17200    |
| policy_entropy     | 2.45     |
| total_timesteps    | 344000   |
| value_loss         | 0.000186 |
---------------------------------
---------------------------------
| explained_variance | 0.441    |
| fps                | 442      |
| nupdates           | 17300    |
| policy_entropy     | 2.46     |
| total_timesteps    | 346000   |
| value_loss         | 2.71e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.18    |
| fps                | 442      |
| nupdates           | 17400    |
| policy_entropy     | 2.45     |
| total_timesteps    | 348000   |
| value_loss         | 0.00212  |
---------------------------------
---------------------------------
| explained_variance | -0.304   |
| fps                | 442      |
| nupdates           | 17500    |
| policy_entropy     | 2.42     |
| total_timesteps    | 350000   |
| value_loss         | 2.29e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.833    |
| fps                | 442      |
| nupdates           | 17600    |
| policy_entropy     | 2.39     |
| total_timesteps    | 352000   |
| value_loss         | 1.6e-05  |
---------------------------------
---------------------------------
| explained_variance | -3.19    |
| fps                | 442      |
| nupdates           | 17700    |
| policy_entropy     | 2.41     |
| total_timesteps    | 354000   |
| value_loss         | 0.000221 |
---------------------------------
---------------------------------
| explained_variance | 0.465    |
| fps                | 442      |
| nupdates           | 17800    |
| policy_entropy     | 2.49     |
| total_timesteps    | 356000   |
| value_loss         | 4.93e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.146    |
| fps                | 442      |
| nupdates           | 17900    |
| policy_entropy     | 2.48     |
| total_timesteps    | 358000   |
| value_loss         | 1.4e-05  |
---------------------------------
Eval num_timesteps=360000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -6.25    |
| fps                | 442      |
| nupdates           | 18000    |
| policy_entropy     | 2.49     |
| total_timesteps    | 360000   |
| value_loss         | 0.000318 |
---------------------------------
---------------------------------
| explained_variance | 0.406    |
| fps                | 442      |
| nupdates           | 18100    |
| policy_entropy     | 2.42     |
| total_timesteps    | 362000   |
| value_loss         | 5.8e-06  |
---------------------------------
---------------------------------
| explained_variance | -6.43    |
| fps                | 442      |
| nupdates           | 18200    |
| policy_entropy     | 2.41     |
| total_timesteps    | 364000   |
| value_loss         | 0.00013  |
---------------------------------
---------------------------------
| explained_variance | -0.432   |
| fps                | 442      |
| nupdates           | 18300    |
| policy_entropy     | 2.41     |
| total_timesteps    | 366000   |
| value_loss         | 3.24e-05 |
---------------------------------
---------------------------------
| explained_variance | -2.39    |
| fps                | 442      |
| nupdates           | 18400    |
| policy_entropy     | 2.4      |
| total_timesteps    | 368000   |
| value_loss         | 0.000143 |
---------------------------------
---------------------------------
| explained_variance | -4.63    |
| fps                | 442      |
| nupdates           | 18500    |
| policy_entropy     | 2.45     |
| total_timesteps    | 370000   |
| value_loss         | 7.09e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.468    |
| fps                | 442      |
| nupdates           | 18600    |
| policy_entropy     | 2.51     |
| total_timesteps    | 372000   |
| value_loss         | 1.38e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.69    |
| fps                | 442      |
| nupdates           | 18700    |
| policy_entropy     | 2.56     |
| total_timesteps    | 374000   |
| value_loss         | 9.4e-05  |
---------------------------------
---------------------------------
| explained_variance | -0.306   |
| fps                | 443      |
| nupdates           | 18800    |
| policy_entropy     | 2.53     |
| total_timesteps    | 376000   |
| value_loss         | 0.000106 |
---------------------------------
---------------------------------
| explained_variance | -1.01    |
| fps                | 443      |
| nupdates           | 18900    |
| policy_entropy     | 2.48     |
| total_timesteps    | 378000   |
| value_loss         | 0.000275 |
---------------------------------
Eval num_timesteps=380000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.404    |
| fps                | 442      |
| nupdates           | 19000    |
| policy_entropy     | 2.49     |
| total_timesteps    | 380000   |
| value_loss         | 3.23e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.644    |
| fps                | 442      |
| nupdates           | 19100    |
| policy_entropy     | 2.42     |
| total_timesteps    | 382000   |
| value_loss         | 4.7e-06  |
---------------------------------
---------------------------------
| explained_variance | -1.86    |
| fps                | 443      |
| nupdates           | 19200    |
| policy_entropy     | 2.36     |
| total_timesteps    | 384000   |
| value_loss         | 1.9e-05  |
---------------------------------
---------------------------------
| explained_variance | -4.25    |
| fps                | 443      |
| nupdates           | 19300    |
| policy_entropy     | 2.41     |
| total_timesteps    | 386000   |
| value_loss         | 0.000667 |
---------------------------------
---------------------------------
| explained_variance | 0.158    |
| fps                | 443      |
| nupdates           | 19400    |
| policy_entropy     | 2.45     |
| total_timesteps    | 388000   |
| value_loss         | 4.85e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.132    |
| fps                | 443      |
| nupdates           | 19500    |
| policy_entropy     | 2.53     |
| total_timesteps    | 390000   |
| value_loss         | 2.78e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.105    |
| fps                | 443      |
| nupdates           | 19600    |
| policy_entropy     | 2.53     |
| total_timesteps    | 392000   |
| value_loss         | 3.55e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.308   |
| fps                | 443      |
| nupdates           | 19700    |
| policy_entropy     | 2.48     |
| total_timesteps    | 394000   |
| value_loss         | 9.81e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.01    |
| fps                | 443      |
| nupdates           | 19800    |
| policy_entropy     | 2.45     |
| total_timesteps    | 396000   |
| value_loss         | 0.000402 |
---------------------------------
---------------------------------
| explained_variance | 0.0888   |
| fps                | 443      |
| nupdates           | 19900    |
| policy_entropy     | 2.46     |
| total_timesteps    | 398000   |
| value_loss         | 1.82e-05 |
---------------------------------
Eval num_timesteps=400000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -5.29    |
| fps                | 443      |
| nupdates           | 20000    |
| policy_entropy     | 2.5      |
| total_timesteps    | 400000   |
| value_loss         | 0.00158  |
---------------------------------
---------------------------------
| explained_variance | 0.244    |
| fps                | 443      |
| nupdates           | 20100    |
| policy_entropy     | 2.49     |
| total_timesteps    | 402000   |
| value_loss         | 8.08e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.147    |
| fps                | 443      |
| nupdates           | 20200    |
| policy_entropy     | 2.46     |
| total_timesteps    | 404000   |
| value_loss         | 2.4e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.141    |
| fps                | 443      |
| nupdates           | 20300    |
| policy_entropy     | 2.42     |
| total_timesteps    | 406000   |
| value_loss         | 0.000109 |
---------------------------------
---------------------------------
| explained_variance | -2.68    |
| fps                | 443      |
| nupdates           | 20400    |
| policy_entropy     | 2.47     |
| total_timesteps    | 408000   |
| value_loss         | 8.33e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.174    |
| fps                | 443      |
| nupdates           | 20500    |
| policy_entropy     | 2.45     |
| total_timesteps    | 410000   |
| value_loss         | 1.44e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.37     |
| fps                | 443      |
| nupdates           | 20600    |
| policy_entropy     | 2.45     |
| total_timesteps    | 412000   |
| value_loss         | 2.84e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.194    |
| fps                | 443      |
| nupdates           | 20700    |
| policy_entropy     | 2.42     |
| total_timesteps    | 414000   |
| value_loss         | 0.000168 |
---------------------------------
---------------------------------
| explained_variance | 0.418    |
| fps                | 443      |
| nupdates           | 20800    |
| policy_entropy     | 2.46     |
| total_timesteps    | 416000   |
| value_loss         | 9.39e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.224    |
| fps                | 443      |
| nupdates           | 20900    |
| policy_entropy     | 2.53     |
| total_timesteps    | 418000   |
| value_loss         | 4.52e-05 |
---------------------------------
Eval num_timesteps=420000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.496    |
| fps                | 443      |
| nupdates           | 21000    |
| policy_entropy     | 2.53     |
| total_timesteps    | 420000   |
| value_loss         | 6.16e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.721    |
| fps                | 443      |
| nupdates           | 21100    |
| policy_entropy     | 2.46     |
| total_timesteps    | 422000   |
| value_loss         | 7.21e-06 |
---------------------------------
---------------------------------
| explained_variance | -1.01    |
| fps                | 443      |
| nupdates           | 21200    |
| policy_entropy     | 2.43     |
| total_timesteps    | 424000   |
| value_loss         | 0.000186 |
---------------------------------
---------------------------------
| explained_variance | 0.386    |
| fps                | 443      |
| nupdates           | 21300    |
| policy_entropy     | 2.44     |
| total_timesteps    | 426000   |
| value_loss         | 1.21e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.476    |
| fps                | 443      |
| nupdates           | 21400    |
| policy_entropy     | 2.46     |
| total_timesteps    | 428000   |
| value_loss         | 4.87e-05 |
---------------------------------
---------------------------------
| explained_variance | -2.23    |
| fps                | 443      |
| nupdates           | 21500    |
| policy_entropy     | 2.4      |
| total_timesteps    | 430000   |
| value_loss         | 4.77e-05 |
---------------------------------
---------------------------------
| explained_variance | -2.36    |
| fps                | 443      |
| nupdates           | 21600    |
| policy_entropy     | 2.44     |
| total_timesteps    | 432000   |
| value_loss         | 0.000413 |
---------------------------------
---------------------------------
| explained_variance | 0.63     |
| fps                | 443      |
| nupdates           | 21700    |
| policy_entropy     | 2.49     |
| total_timesteps    | 434000   |
| value_loss         | 7.34e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.359    |
| fps                | 443      |
| nupdates           | 21800    |
| policy_entropy     | 2.51     |
| total_timesteps    | 436000   |
| value_loss         | 2.08e-05 |
---------------------------------
---------------------------------
| explained_variance | -5.23    |
| fps                | 443      |
| nupdates           | 21900    |
| policy_entropy     | 2.43     |
| total_timesteps    | 438000   |
| value_loss         | 0.000307 |
---------------------------------
Eval num_timesteps=440000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -1.01    |
| fps                | 443      |
| nupdates           | 22000    |
| policy_entropy     | 2.46     |
| total_timesteps    | 440000   |
| value_loss         | 6.45e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.594    |
| fps                | 443      |
| nupdates           | 22100    |
| policy_entropy     | 2.47     |
| total_timesteps    | 442000   |
| value_loss         | 8.23e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.611    |
| fps                | 443      |
| nupdates           | 22200    |
| policy_entropy     | 2.46     |
| total_timesteps    | 444000   |
| value_loss         | 5.32e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.293   |
| fps                | 443      |
| nupdates           | 22300    |
| policy_entropy     | 2.47     |
| total_timesteps    | 446000   |
| value_loss         | 3.26e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.107    |
| fps                | 443      |
| nupdates           | 22400    |
| policy_entropy     | 2.45     |
| total_timesteps    | 448000   |
| value_loss         | 1.77e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.504    |
| fps                | 443      |
| nupdates           | 22500    |
| policy_entropy     | 2.39     |
| total_timesteps    | 450000   |
| value_loss         | 5.96e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.538    |
| fps                | 443      |
| nupdates           | 22600    |
| policy_entropy     | 2.45     |
| total_timesteps    | 452000   |
| value_loss         | 1.99e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.603    |
| fps                | 443      |
| nupdates           | 22700    |
| policy_entropy     | 2.47     |
| total_timesteps    | 454000   |
| value_loss         | 2.54e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.942   |
| fps                | 444      |
| nupdates           | 22800    |
| policy_entropy     | 2.42     |
| total_timesteps    | 456000   |
| value_loss         | 3.56e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.0487   |
| fps                | 444      |
| nupdates           | 22900    |
| policy_entropy     | 2.46     |
| total_timesteps    | 458000   |
| value_loss         | 4.91e-05 |
---------------------------------
Eval num_timesteps=460000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.213    |
| fps                | 443      |
| nupdates           | 23000    |
| policy_entropy     | 2.48     |
| total_timesteps    | 460000   |
| value_loss         | 1.19e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.19    |
| fps                | 443      |
| nupdates           | 23100    |
| policy_entropy     | 2.39     |
| total_timesteps    | 462000   |
| value_loss         | 5.65e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.205    |
| fps                | 444      |
| nupdates           | 23200    |
| policy_entropy     | 2.48     |
| total_timesteps    | 464000   |
| value_loss         | 2.86e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.293   |
| fps                | 444      |
| nupdates           | 23300    |
| policy_entropy     | 2.53     |
| total_timesteps    | 466000   |
| value_loss         | 1.82e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.605   |
| fps                | 444      |
| nupdates           | 23400    |
| policy_entropy     | 2.46     |
| total_timesteps    | 468000   |
| value_loss         | 5.45e-05 |
---------------------------------
---------------------------------
| explained_variance | -3.92    |
| fps                | 444      |
| nupdates           | 23500    |
| policy_entropy     | 2.44     |
| total_timesteps    | 470000   |
| value_loss         | 0.000154 |
---------------------------------
---------------------------------
| explained_variance | -5.21    |
| fps                | 444      |
| nupdates           | 23600    |
| policy_entropy     | 2.41     |
| total_timesteps    | 472000   |
| value_loss         | 9.57e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.17    |
| fps                | 444      |
| nupdates           | 23700    |
| policy_entropy     | 2.54     |
| total_timesteps    | 474000   |
| value_loss         | 0.000118 |
---------------------------------
---------------------------------
| explained_variance | -1.67    |
| fps                | 444      |
| nupdates           | 23800    |
| policy_entropy     | 2.42     |
| total_timesteps    | 476000   |
| value_loss         | 5.27e-05 |
---------------------------------
---------------------------------
| explained_variance | -2.61    |
| fps                | 444      |
| nupdates           | 23900    |
| policy_entropy     | 2.41     |
| total_timesteps    | 478000   |
| value_loss         | 0.000312 |
---------------------------------
Eval num_timesteps=480000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -8.27    |
| fps                | 444      |
| nupdates           | 24000    |
| policy_entropy     | 2.39     |
| total_timesteps    | 480000   |
| value_loss         | 0.000708 |
---------------------------------
---------------------------------
| explained_variance | 0.506    |
| fps                | 444      |
| nupdates           | 24100    |
| policy_entropy     | 2.5      |
| total_timesteps    | 482000   |
| value_loss         | 1.12e-05 |
---------------------------------
---------------------------------
| explained_variance | -3.52    |
| fps                | 444      |
| nupdates           | 24200    |
| policy_entropy     | 2.42     |
| total_timesteps    | 484000   |
| value_loss         | 5.76e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.277    |
| fps                | 444      |
| nupdates           | 24300    |
| policy_entropy     | 2.55     |
| total_timesteps    | 486000   |
| value_loss         | 3e-05    |
---------------------------------
---------------------------------
| explained_variance | 0.655    |
| fps                | 444      |
| nupdates           | 24400    |
| policy_entropy     | 2.43     |
| total_timesteps    | 488000   |
| value_loss         | 2.76e-05 |
---------------------------------
---------------------------------
| explained_variance | -3.31    |
| fps                | 444      |
| nupdates           | 24500    |
| policy_entropy     | 2.39     |
| total_timesteps    | 490000   |
| value_loss         | 0.000191 |
---------------------------------
---------------------------------
| explained_variance | -1.35    |
| fps                | 444      |
| nupdates           | 24600    |
| policy_entropy     | 2.46     |
| total_timesteps    | 492000   |
| value_loss         | 0.000396 |
---------------------------------
---------------------------------
| explained_variance | -1.25    |
| fps                | 444      |
| nupdates           | 24700    |
| policy_entropy     | 2.48     |
| total_timesteps    | 494000   |
| value_loss         | 4.16e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.72     |
| fps                | 444      |
| nupdates           | 24800    |
| policy_entropy     | 2.4      |
| total_timesteps    | 496000   |
| value_loss         | 4.64e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.275    |
| fps                | 444      |
| nupdates           | 24900    |
| policy_entropy     | 2.52     |
| total_timesteps    | 498000   |
| value_loss         | 9.11e-05 |
---------------------------------
Eval num_timesteps=500000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.069    |
| fps                | 444      |
| nupdates           | 25000    |
| policy_entropy     | 2.42     |
| total_timesteps    | 500000   |
| value_loss         | 1.21e-05 |
---------------------------------
---------------------------------
| explained_variance | -2.42    |
| fps                | 444      |
| nupdates           | 25100    |
| policy_entropy     | 2.4      |
| total_timesteps    | 502000   |
| value_loss         | 4.06e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.56     |
| fps                | 444      |
| nupdates           | 25200    |
| policy_entropy     | 2.5      |
| total_timesteps    | 504000   |
| value_loss         | 2.34e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.195    |
| fps                | 444      |
| nupdates           | 25300    |
| policy_entropy     | 2.47     |
| total_timesteps    | 506000   |
| value_loss         | 1.73e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.224    |
| fps                | 444      |
| nupdates           | 25400    |
| policy_entropy     | 2.41     |
| total_timesteps    | 508000   |
| value_loss         | 1.33e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.496    |
| fps                | 444      |
| nupdates           | 25500    |
| policy_entropy     | 2.53     |
| total_timesteps    | 510000   |
| value_loss         | 2.06e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.419    |
| fps                | 444      |
| nupdates           | 25600    |
| policy_entropy     | 2.53     |
| total_timesteps    | 512000   |
| value_loss         | 1.52e-05 |
---------------------------------
---------------------------------
| explained_variance | -6.88    |
| fps                | 444      |
| nupdates           | 25700    |
| policy_entropy     | 2.39     |
| total_timesteps    | 514000   |
| value_loss         | 9.23e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.0322   |
| fps                | 444      |
| nupdates           | 25800    |
| policy_entropy     | 2.47     |
| total_timesteps    | 516000   |
| value_loss         | 6.9e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.583    |
| fps                | 444      |
| nupdates           | 25900    |
| policy_entropy     | 2.45     |
| total_timesteps    | 518000   |
| value_loss         | 1.2e-05  |
---------------------------------
Eval num_timesteps=520000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -4.76    |
| fps                | 444      |
| nupdates           | 26000    |
| policy_entropy     | 2.42     |
| total_timesteps    | 520000   |
| value_loss         | 0.000301 |
---------------------------------
---------------------------------
| explained_variance | -0.0152  |
| fps                | 444      |
| nupdates           | 26100    |
| policy_entropy     | 2.45     |
| total_timesteps    | 522000   |
| value_loss         | 5.58e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.393    |
| fps                | 444      |
| nupdates           | 26200    |
| policy_entropy     | 2.53     |
| total_timesteps    | 524000   |
| value_loss         | 2.93e-05 |
---------------------------------
---------------------------------
| explained_variance | -3.99    |
| fps                | 444      |
| nupdates           | 26300    |
| policy_entropy     | 2.4      |
| total_timesteps    | 526000   |
| value_loss         | 0.000179 |
---------------------------------
---------------------------------
| explained_variance | 0.326    |
| fps                | 444      |
| nupdates           | 26400    |
| policy_entropy     | 2.47     |
| total_timesteps    | 528000   |
| value_loss         | 1.39e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.872   |
| fps                | 444      |
| nupdates           | 26500    |
| policy_entropy     | 2.4      |
| total_timesteps    | 530000   |
| value_loss         | 3.04e-05 |
---------------------------------
---------------------------------
| explained_variance | -2.04    |
| fps                | 444      |
| nupdates           | 26600    |
| policy_entropy     | 2.48     |
| total_timesteps    | 532000   |
| value_loss         | 6.94e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.67    |
| fps                | 444      |
| nupdates           | 26700    |
| policy_entropy     | 2.45     |
| total_timesteps    | 534000   |
| value_loss         | 0.00022  |
---------------------------------
---------------------------------
| explained_variance | 0.13     |
| fps                | 444      |
| nupdates           | 26800    |
| policy_entropy     | 2.38     |
| total_timesteps    | 536000   |
| value_loss         | 4.26e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.566    |
| fps                | 444      |
| nupdates           | 26900    |
| policy_entropy     | 2.41     |
| total_timesteps    | 538000   |
| value_loss         | 1.23e-05 |
---------------------------------
Eval num_timesteps=540000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -1.3     |
| fps                | 444      |
| nupdates           | 27000    |
| policy_entropy     | 2.47     |
| total_timesteps    | 540000   |
| value_loss         | 3.03e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.12    |
| fps                | 444      |
| nupdates           | 27100    |
| policy_entropy     | 2.45     |
| total_timesteps    | 542000   |
| value_loss         | 0.000504 |
---------------------------------
---------------------------------
| explained_variance | 0.623    |
| fps                | 444      |
| nupdates           | 27200    |
| policy_entropy     | 2.49     |
| total_timesteps    | 544000   |
| value_loss         | 2.51e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.584    |
| fps                | 444      |
| nupdates           | 27300    |
| policy_entropy     | 2.43     |
| total_timesteps    | 546000   |
| value_loss         | 1.12e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.00498  |
| fps                | 444      |
| nupdates           | 27400    |
| policy_entropy     | 2.43     |
| total_timesteps    | 548000   |
| value_loss         | 2.77e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.219    |
| fps                | 444      |
| nupdates           | 27500    |
| policy_entropy     | 2.46     |
| total_timesteps    | 550000   |
| value_loss         | 0.00021  |
---------------------------------
---------------------------------
| explained_variance | -0.355   |
| fps                | 444      |
| nupdates           | 27600    |
| policy_entropy     | 2.46     |
| total_timesteps    | 552000   |
| value_loss         | 2.37e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.52    |
| fps                | 445      |
| nupdates           | 27700    |
| policy_entropy     | 2.49     |
| total_timesteps    | 554000   |
| value_loss         | 0.0006   |
---------------------------------
---------------------------------
| explained_variance | 0.116    |
| fps                | 445      |
| nupdates           | 27800    |
| policy_entropy     | 2.46     |
| total_timesteps    | 556000   |
| value_loss         | 7.07e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.675    |
| fps                | 445      |
| nupdates           | 27900    |
| policy_entropy     | 2.43     |
| total_timesteps    | 558000   |
| value_loss         | 1.55e-05 |
---------------------------------
Eval num_timesteps=560000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.433    |
| fps                | 444      |
| nupdates           | 28000    |
| policy_entropy     | 2.4      |
| total_timesteps    | 560000   |
| value_loss         | 1.02e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.15    |
| fps                | 444      |
| nupdates           | 28100    |
| policy_entropy     | 2.5      |
| total_timesteps    | 562000   |
| value_loss         | 7.98e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.87    |
| fps                | 445      |
| nupdates           | 28200    |
| policy_entropy     | 2.46     |
| total_timesteps    | 564000   |
| value_loss         | 0.000163 |
---------------------------------
---------------------------------
| explained_variance | 0.172    |
| fps                | 445      |
| nupdates           | 28300    |
| policy_entropy     | 2.52     |
| total_timesteps    | 566000   |
| value_loss         | 2.28e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.399    |
| fps                | 445      |
| nupdates           | 28400    |
| policy_entropy     | 2.52     |
| total_timesteps    | 568000   |
| value_loss         | 2.23e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.161    |
| fps                | 445      |
| nupdates           | 28500    |
| policy_entropy     | 2.46     |
| total_timesteps    | 570000   |
| value_loss         | 2.93e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.499    |
| fps                | 445      |
| nupdates           | 28600    |
| policy_entropy     | 2.49     |
| total_timesteps    | 572000   |
| value_loss         | 1.15e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.512    |
| fps                | 445      |
| nupdates           | 28700    |
| policy_entropy     | 2.45     |
| total_timesteps    | 574000   |
| value_loss         | 1.77e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.413    |
| fps                | 445      |
| nupdates           | 28800    |
| policy_entropy     | 2.39     |
| total_timesteps    | 576000   |
| value_loss         | 2.21e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.621    |
| fps                | 445      |
| nupdates           | 28900    |
| policy_entropy     | 2.39     |
| total_timesteps    | 578000   |
| value_loss         | 5.79e-06 |
---------------------------------
Eval num_timesteps=580000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -0.131   |
| fps                | 445      |
| nupdates           | 29000    |
| policy_entropy     | 2.45     |
| total_timesteps    | 580000   |
| value_loss         | 2.5e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.53     |
| fps                | 445      |
| nupdates           | 29100    |
| policy_entropy     | 2.48     |
| total_timesteps    | 582000   |
| value_loss         | 1.9e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.164    |
| fps                | 445      |
| nupdates           | 29200    |
| policy_entropy     | 2.42     |
| total_timesteps    | 584000   |
| value_loss         | 3.27e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.03    |
| fps                | 445      |
| nupdates           | 29300    |
| policy_entropy     | 2.46     |
| total_timesteps    | 586000   |
| value_loss         | 0.000129 |
---------------------------------
---------------------------------
| explained_variance | 0.487    |
| fps                | 445      |
| nupdates           | 29400    |
| policy_entropy     | 2.49     |
| total_timesteps    | 588000   |
| value_loss         | 2.15e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.614    |
| fps                | 445      |
| nupdates           | 29500    |
| policy_entropy     | 2.46     |
| total_timesteps    | 590000   |
| value_loss         | 1.41e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.853    |
| fps                | 445      |
| nupdates           | 29600    |
| policy_entropy     | 2.36     |
| total_timesteps    | 592000   |
| value_loss         | 3.63e-05 |
---------------------------------
---------------------------------
| explained_variance | -2.66    |
| fps                | 445      |
| nupdates           | 29700    |
| policy_entropy     | 2.45     |
| total_timesteps    | 594000   |
| value_loss         | 0.0014   |
---------------------------------
---------------------------------
| explained_variance | 0.265    |
| fps                | 445      |
| nupdates           | 29800    |
| policy_entropy     | 2.48     |
| total_timesteps    | 596000   |
| value_loss         | 1.36e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.675    |
| fps                | 445      |
| nupdates           | 29900    |
| policy_entropy     | 2.43     |
| total_timesteps    | 598000   |
| value_loss         | 7.4e-06  |
---------------------------------
Eval num_timesteps=600000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -2.28    |
| fps                | 445      |
| nupdates           | 30000    |
| policy_entropy     | 2.52     |
| total_timesteps    | 600000   |
| value_loss         | 0.00047  |
---------------------------------
---------------------------------
| explained_variance | 0.408    |
| fps                | 445      |
| nupdates           | 30100    |
| policy_entropy     | 2.5      |
| total_timesteps    | 602000   |
| value_loss         | 4.26e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.366   |
| fps                | 445      |
| nupdates           | 30200    |
| policy_entropy     | 2.4      |
| total_timesteps    | 604000   |
| value_loss         | 3.26e-05 |
---------------------------------
----------------------------------
| explained_variance | -0.000953 |
| fps                | 445       |
| nupdates           | 30300     |
| policy_entropy     | 2.46      |
| total_timesteps    | 606000    |
| value_loss         | 3.25e-05  |
----------------------------------
---------------------------------
| explained_variance | -1.65    |
| fps                | 445      |
| nupdates           | 30400    |
| policy_entropy     | 2.42     |
| total_timesteps    | 608000   |
| value_loss         | 1.57e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.428    |
| fps                | 445      |
| nupdates           | 30500    |
| policy_entropy     | 2.52     |
| total_timesteps    | 610000   |
| value_loss         | 1.94e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.522    |
| fps                | 445      |
| nupdates           | 30600    |
| policy_entropy     | 2.46     |
| total_timesteps    | 612000   |
| value_loss         | 1.78e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.737    |
| fps                | 445      |
| nupdates           | 30700    |
| policy_entropy     | 2.39     |
| total_timesteps    | 614000   |
| value_loss         | 1.61e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.5      |
| fps                | 445      |
| nupdates           | 30800    |
| policy_entropy     | 2.49     |
| total_timesteps    | 616000   |
| value_loss         | 1.15e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.814    |
| fps                | 445      |
| nupdates           | 30900    |
| policy_entropy     | 2.4      |
| total_timesteps    | 618000   |
| value_loss         | 1.81e-06 |
---------------------------------
Eval num_timesteps=620000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -2.89    |
| fps                | 445      |
| nupdates           | 31000    |
| policy_entropy     | 2.43     |
| total_timesteps    | 620000   |
| value_loss         | 5.02e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.487    |
| fps                | 445      |
| nupdates           | 31100    |
| policy_entropy     | 2.46     |
| total_timesteps    | 622000   |
| value_loss         | 1.61e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.404    |
| fps                | 445      |
| nupdates           | 31200    |
| policy_entropy     | 2.46     |
| total_timesteps    | 624000   |
| value_loss         | 3.17e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.179    |
| fps                | 445      |
| nupdates           | 31300    |
| policy_entropy     | 2.53     |
| total_timesteps    | 626000   |
| value_loss         | 4.17e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.09    |
| fps                | 445      |
| nupdates           | 31400    |
| policy_entropy     | 2.49     |
| total_timesteps    | 628000   |
| value_loss         | 0.000105 |
---------------------------------
---------------------------------
| explained_variance | 0.17     |
| fps                | 445      |
| nupdates           | 31500    |
| policy_entropy     | 2.45     |
| total_timesteps    | 630000   |
| value_loss         | 6.88e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.308    |
| fps                | 445      |
| nupdates           | 31600    |
| policy_entropy     | 2.49     |
| total_timesteps    | 632000   |
| value_loss         | 2.66e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.0425  |
| fps                | 445      |
| nupdates           | 31700    |
| policy_entropy     | 2.45     |
| total_timesteps    | 634000   |
| value_loss         | 0.00021  |
---------------------------------
---------------------------------
| explained_variance | -0.41    |
| fps                | 445      |
| nupdates           | 31800    |
| policy_entropy     | 2.46     |
| total_timesteps    | 636000   |
| value_loss         | 2.1e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.093    |
| fps                | 445      |
| nupdates           | 31900    |
| policy_entropy     | 2.49     |
| total_timesteps    | 638000   |
| value_loss         | 1.93e-05 |
---------------------------------
Eval num_timesteps=640000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.237    |
| fps                | 445      |
| nupdates           | 32000    |
| policy_entropy     | 2.46     |
| total_timesteps    | 640000   |
| value_loss         | 1.23e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.534    |
| fps                | 445      |
| nupdates           | 32100    |
| policy_entropy     | 2.42     |
| total_timesteps    | 642000   |
| value_loss         | 2.95e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.24    |
| fps                | 445      |
| nupdates           | 32200    |
| policy_entropy     | 2.42     |
| total_timesteps    | 644000   |
| value_loss         | 2.27e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.484    |
| fps                | 445      |
| nupdates           | 32300    |
| policy_entropy     | 2.45     |
| total_timesteps    | 646000   |
| value_loss         | 2.64e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.32     |
| fps                | 445      |
| nupdates           | 32400    |
| policy_entropy     | 2.52     |
| total_timesteps    | 648000   |
| value_loss         | 5.29e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.196    |
| fps                | 445      |
| nupdates           | 32500    |
| policy_entropy     | 2.49     |
| total_timesteps    | 650000   |
| value_loss         | 1.61e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.701    |
| fps                | 445      |
| nupdates           | 32600    |
| policy_entropy     | 2.43     |
| total_timesteps    | 652000   |
| value_loss         | 8.47e-06 |
---------------------------------
---------------------------------
| explained_variance | -1.92    |
| fps                | 445      |
| nupdates           | 32700    |
| policy_entropy     | 2.49     |
| total_timesteps    | 654000   |
| value_loss         | 0.0002   |
---------------------------------
---------------------------------
| explained_variance | -2.81    |
| fps                | 445      |
| nupdates           | 32800    |
| policy_entropy     | 2.49     |
| total_timesteps    | 656000   |
| value_loss         | 0.000112 |
---------------------------------
---------------------------------
| explained_variance | 0.118    |
| fps                | 445      |
| nupdates           | 32900    |
| policy_entropy     | 2.49     |
| total_timesteps    | 658000   |
| value_loss         | 2.82e-05 |
---------------------------------
Eval num_timesteps=660000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.207    |
| fps                | 445      |
| nupdates           | 33000    |
| policy_entropy     | 2.43     |
| total_timesteps    | 660000   |
| value_loss         | 2.26e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.268   |
| fps                | 445      |
| nupdates           | 33100    |
| policy_entropy     | 2.53     |
| total_timesteps    | 662000   |
| value_loss         | 5.95e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.536    |
| fps                | 445      |
| nupdates           | 33200    |
| policy_entropy     | 2.46     |
| total_timesteps    | 664000   |
| value_loss         | 2.9e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.432    |
| fps                | 445      |
| nupdates           | 33300    |
| policy_entropy     | 2.39     |
| total_timesteps    | 666000   |
| value_loss         | 7.11e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.59     |
| fps                | 445      |
| nupdates           | 33400    |
| policy_entropy     | 2.42     |
| total_timesteps    | 668000   |
| value_loss         | 2.58e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.557    |
| fps                | 445      |
| nupdates           | 33500    |
| policy_entropy     | 2.45     |
| total_timesteps    | 670000   |
| value_loss         | 8.12e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.437    |
| fps                | 445      |
| nupdates           | 33600    |
| policy_entropy     | 2.5      |
| total_timesteps    | 672000   |
| value_loss         | 1.69e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.293    |
| fps                | 445      |
| nupdates           | 33700    |
| policy_entropy     | 2.49     |
| total_timesteps    | 674000   |
| value_loss         | 2.7e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.526    |
| fps                | 445      |
| nupdates           | 33800    |
| policy_entropy     | 2.42     |
| total_timesteps    | 676000   |
| value_loss         | 1.49e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.551    |
| fps                | 445      |
| nupdates           | 33900    |
| policy_entropy     | 2.43     |
| total_timesteps    | 678000   |
| value_loss         | 9.59e-06 |
---------------------------------
Eval num_timesteps=680000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.681    |
| fps                | 445      |
| nupdates           | 34000    |
| policy_entropy     | 2.46     |
| total_timesteps    | 680000   |
| value_loss         | 6.65e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.461    |
| fps                | 445      |
| nupdates           | 34100    |
| policy_entropy     | 2.49     |
| total_timesteps    | 682000   |
| value_loss         | 1.85e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.334   |
| fps                | 445      |
| nupdates           | 34200    |
| policy_entropy     | 2.45     |
| total_timesteps    | 684000   |
| value_loss         | 0.000158 |
---------------------------------
---------------------------------
| explained_variance | -0.059   |
| fps                | 445      |
| nupdates           | 34300    |
| policy_entropy     | 2.45     |
| total_timesteps    | 686000   |
| value_loss         | 0.000109 |
---------------------------------
---------------------------------
| explained_variance | 0.523    |
| fps                | 445      |
| nupdates           | 34400    |
| policy_entropy     | 2.49     |
| total_timesteps    | 688000   |
| value_loss         | 1.01e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.512   |
| fps                | 445      |
| nupdates           | 34500    |
| policy_entropy     | 2.48     |
| total_timesteps    | 690000   |
| value_loss         | 8.41e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.458    |
| fps                | 445      |
| nupdates           | 34600    |
| policy_entropy     | 2.5      |
| total_timesteps    | 692000   |
| value_loss         | 2.38e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.511    |
| fps                | 445      |
| nupdates           | 34700    |
| policy_entropy     | 2.46     |
| total_timesteps    | 694000   |
| value_loss         | 1.64e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.282    |
| fps                | 445      |
| nupdates           | 34800    |
| policy_entropy     | 2.46     |
| total_timesteps    | 696000   |
| value_loss         | 9.28e-05 |
---------------------------------
---------------------------------
| explained_variance | -2.61    |
| fps                | 445      |
| nupdates           | 34900    |
| policy_entropy     | 2.43     |
| total_timesteps    | 698000   |
| value_loss         | 2.96e-05 |
---------------------------------
Eval num_timesteps=700000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.602    |
| fps                | 445      |
| nupdates           | 35000    |
| policy_entropy     | 2.41     |
| total_timesteps    | 700000   |
| value_loss         | 3e-05    |
---------------------------------
---------------------------------
| explained_variance | -0.502   |
| fps                | 445      |
| nupdates           | 35100    |
| policy_entropy     | 2.49     |
| total_timesteps    | 702000   |
| value_loss         | 7.96e-05 |
---------------------------------
---------------------------------
| explained_variance | -3.37    |
| fps                | 445      |
| nupdates           | 35200    |
| policy_entropy     | 2.46     |
| total_timesteps    | 704000   |
| value_loss         | 9.78e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.228    |
| fps                | 445      |
| nupdates           | 35300    |
| policy_entropy     | 2.48     |
| total_timesteps    | 706000   |
| value_loss         | 3.85e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.495    |
| fps                | 445      |
| nupdates           | 35400    |
| policy_entropy     | 2.45     |
| total_timesteps    | 708000   |
| value_loss         | 1.89e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.108    |
| fps                | 445      |
| nupdates           | 35500    |
| policy_entropy     | 2.49     |
| total_timesteps    | 710000   |
| value_loss         | 4.69e-05 |
---------------------------------
---------------------------------
| explained_variance | -10.7    |
| fps                | 446      |
| nupdates           | 35600    |
| policy_entropy     | 2.42     |
| total_timesteps    | 712000   |
| value_loss         | 0.000174 |
---------------------------------
---------------------------------
| explained_variance | -3.42    |
| fps                | 446      |
| nupdates           | 35700    |
| policy_entropy     | 2.42     |
| total_timesteps    | 714000   |
| value_loss         | 2.86e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.395    |
| fps                | 446      |
| nupdates           | 35800    |
| policy_entropy     | 2.48     |
| total_timesteps    | 716000   |
| value_loss         | 2.53e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.611   |
| fps                | 446      |
| nupdates           | 35900    |
| policy_entropy     | 2.45     |
| total_timesteps    | 718000   |
| value_loss         | 2.76e-05 |
---------------------------------
Eval num_timesteps=720000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.692    |
| fps                | 445      |
| nupdates           | 36000    |
| policy_entropy     | 2.43     |
| total_timesteps    | 720000   |
| value_loss         | 7.97e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.139    |
| fps                | 446      |
| nupdates           | 36100    |
| policy_entropy     | 2.43     |
| total_timesteps    | 722000   |
| value_loss         | 2.94e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.439   |
| fps                | 446      |
| nupdates           | 36200    |
| policy_entropy     | 2.46     |
| total_timesteps    | 724000   |
| value_loss         | 3.41e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.99    |
| fps                | 446      |
| nupdates           | 36300    |
| policy_entropy     | 2.43     |
| total_timesteps    | 726000   |
| value_loss         | 7.17e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.287   |
| fps                | 446      |
| nupdates           | 36400    |
| policy_entropy     | 2.48     |
| total_timesteps    | 728000   |
| value_loss         | 0.000189 |
---------------------------------
---------------------------------
| explained_variance | 0.361    |
| fps                | 446      |
| nupdates           | 36500    |
| policy_entropy     | 2.45     |
| total_timesteps    | 730000   |
| value_loss         | 2.46e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.229   |
| fps                | 446      |
| nupdates           | 36600    |
| policy_entropy     | 2.48     |
| total_timesteps    | 732000   |
| value_loss         | 2.62e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.184    |
| fps                | 446      |
| nupdates           | 36700    |
| policy_entropy     | 2.46     |
| total_timesteps    | 734000   |
| value_loss         | 2.7e-05  |
---------------------------------
---------------------------------
| explained_variance | -5.69    |
| fps                | 446      |
| nupdates           | 36800    |
| policy_entropy     | 2.39     |
| total_timesteps    | 736000   |
| value_loss         | 0.000106 |
---------------------------------
---------------------------------
| explained_variance | 0.843    |
| fps                | 446      |
| nupdates           | 36900    |
| policy_entropy     | 2.39     |
| total_timesteps    | 738000   |
| value_loss         | 2.23e-06 |
---------------------------------
Eval num_timesteps=740000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -0.789   |
| fps                | 446      |
| nupdates           | 37000    |
| policy_entropy     | 2.39     |
| total_timesteps    | 740000   |
| value_loss         | 8.25e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.256    |
| fps                | 446      |
| nupdates           | 37100    |
| policy_entropy     | 2.46     |
| total_timesteps    | 742000   |
| value_loss         | 1.44e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.325    |
| fps                | 446      |
| nupdates           | 37200    |
| policy_entropy     | 2.46     |
| total_timesteps    | 744000   |
| value_loss         | 2.11e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.442    |
| fps                | 446      |
| nupdates           | 37300    |
| policy_entropy     | 2.48     |
| total_timesteps    | 746000   |
| value_loss         | 1.38e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.288    |
| fps                | 446      |
| nupdates           | 37400    |
| policy_entropy     | 2.48     |
| total_timesteps    | 748000   |
| value_loss         | 1.96e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.688    |
| fps                | 446      |
| nupdates           | 37500    |
| policy_entropy     | 2.43     |
| total_timesteps    | 750000   |
| value_loss         | 1.76e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.583    |
| fps                | 446      |
| nupdates           | 37600    |
| policy_entropy     | 2.49     |
| total_timesteps    | 752000   |
| value_loss         | 1.62e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.373    |
| fps                | 446      |
| nupdates           | 37700    |
| policy_entropy     | 2.49     |
| total_timesteps    | 754000   |
| value_loss         | 8.9e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.474    |
| fps                | 446      |
| nupdates           | 37800    |
| policy_entropy     | 2.42     |
| total_timesteps    | 756000   |
| value_loss         | 4.31e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.559    |
| fps                | 446      |
| nupdates           | 37900    |
| policy_entropy     | 2.49     |
| total_timesteps    | 758000   |
| value_loss         | 2.37e-05 |
---------------------------------
Eval num_timesteps=760000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -0.617   |
| fps                | 446      |
| nupdates           | 38000    |
| policy_entropy     | 2.42     |
| total_timesteps    | 760000   |
| value_loss         | 6.89e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.226    |
| fps                | 446      |
| nupdates           | 38100    |
| policy_entropy     | 2.49     |
| total_timesteps    | 762000   |
| value_loss         | 2.29e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.213   |
| fps                | 446      |
| nupdates           | 38200    |
| policy_entropy     | 2.49     |
| total_timesteps    | 764000   |
| value_loss         | 2.56e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.689    |
| fps                | 446      |
| nupdates           | 38300    |
| policy_entropy     | 2.48     |
| total_timesteps    | 766000   |
| value_loss         | 4.45e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.228    |
| fps                | 446      |
| nupdates           | 38400    |
| policy_entropy     | 2.49     |
| total_timesteps    | 768000   |
| value_loss         | 3.04e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.507    |
| fps                | 446      |
| nupdates           | 38500    |
| policy_entropy     | 2.53     |
| total_timesteps    | 770000   |
| value_loss         | 1.41e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.5      |
| fps                | 446      |
| nupdates           | 38600    |
| policy_entropy     | 2.43     |
| total_timesteps    | 772000   |
| value_loss         | 1.23e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.329    |
| fps                | 446      |
| nupdates           | 38700    |
| policy_entropy     | 2.42     |
| total_timesteps    | 774000   |
| value_loss         | 5.35e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.543   |
| fps                | 446      |
| nupdates           | 38800    |
| policy_entropy     | 2.43     |
| total_timesteps    | 776000   |
| value_loss         | 2.82e-05 |
---------------------------------
---------------------------------
| explained_variance | -2.56    |
| fps                | 446      |
| nupdates           | 38900    |
| policy_entropy     | 2.45     |
| total_timesteps    | 778000   |
| value_loss         | 0.000142 |
---------------------------------
Eval num_timesteps=780000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -1.38    |
| fps                | 446      |
| nupdates           | 39000    |
| policy_entropy     | 2.5      |
| total_timesteps    | 780000   |
| value_loss         | 4.69e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.34     |
| fps                | 446      |
| nupdates           | 39100    |
| policy_entropy     | 2.5      |
| total_timesteps    | 782000   |
| value_loss         | 2.66e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.456    |
| fps                | 446      |
| nupdates           | 39200    |
| policy_entropy     | 2.43     |
| total_timesteps    | 784000   |
| value_loss         | 2.12e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.0456  |
| fps                | 446      |
| nupdates           | 39300    |
| policy_entropy     | 2.46     |
| total_timesteps    | 786000   |
| value_loss         | 0.000232 |
---------------------------------
---------------------------------
| explained_variance | 0.173    |
| fps                | 446      |
| nupdates           | 39400    |
| policy_entropy     | 2.4      |
| total_timesteps    | 788000   |
| value_loss         | 1.27e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.0703  |
| fps                | 446      |
| nupdates           | 39500    |
| policy_entropy     | 2.52     |
| total_timesteps    | 790000   |
| value_loss         | 8.39e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.18    |
| fps                | 446      |
| nupdates           | 39600    |
| policy_entropy     | 2.52     |
| total_timesteps    | 792000   |
| value_loss         | 4.68e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.367   |
| fps                | 446      |
| nupdates           | 39700    |
| policy_entropy     | 2.49     |
| total_timesteps    | 794000   |
| value_loss         | 3.79e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.409   |
| fps                | 446      |
| nupdates           | 39800    |
| policy_entropy     | 2.46     |
| total_timesteps    | 796000   |
| value_loss         | 1.77e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.592    |
| fps                | 446      |
| nupdates           | 39900    |
| policy_entropy     | 2.43     |
| total_timesteps    | 798000   |
| value_loss         | 5.44e-06 |
---------------------------------
Eval num_timesteps=800000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -1.96    |
| fps                | 446      |
| nupdates           | 40000    |
| policy_entropy     | 2.46     |
| total_timesteps    | 800000   |
| value_loss         | 5.44e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.584    |
| fps                | 446      |
| nupdates           | 40100    |
| policy_entropy     | 2.49     |
| total_timesteps    | 802000   |
| value_loss         | 3.56e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.746    |
| fps                | 446      |
| nupdates           | 40200    |
| policy_entropy     | 2.39     |
| total_timesteps    | 804000   |
| value_loss         | 1.16e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.172   |
| fps                | 446      |
| nupdates           | 40300    |
| policy_entropy     | 2.5      |
| total_timesteps    | 806000   |
| value_loss         | 2.67e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.588    |
| fps                | 446      |
| nupdates           | 40400    |
| policy_entropy     | 2.46     |
| total_timesteps    | 808000   |
| value_loss         | 3.11e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.0871  |
| fps                | 446      |
| nupdates           | 40500    |
| policy_entropy     | 2.46     |
| total_timesteps    | 810000   |
| value_loss         | 3.61e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.335    |
| fps                | 446      |
| nupdates           | 40600    |
| policy_entropy     | 2.49     |
| total_timesteps    | 812000   |
| value_loss         | 2.71e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.502    |
| fps                | 446      |
| nupdates           | 40700    |
| policy_entropy     | 2.49     |
| total_timesteps    | 814000   |
| value_loss         | 1.33e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.0156   |
| fps                | 446      |
| nupdates           | 40800    |
| policy_entropy     | 2.42     |
| total_timesteps    | 816000   |
| value_loss         | 8.14e-06 |
---------------------------------
---------------------------------
| explained_variance | -2.11    |
| fps                | 446      |
| nupdates           | 40900    |
| policy_entropy     | 2.39     |
| total_timesteps    | 818000   |
| value_loss         | 8.98e-05 |
---------------------------------
Eval num_timesteps=820000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.668    |
| fps                | 446      |
| nupdates           | 41000    |
| policy_entropy     | 2.46     |
| total_timesteps    | 820000   |
| value_loss         | 3.37e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.55     |
| fps                | 446      |
| nupdates           | 41100    |
| policy_entropy     | 2.5      |
| total_timesteps    | 822000   |
| value_loss         | 1.56e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.496    |
| fps                | 446      |
| nupdates           | 41200    |
| policy_entropy     | 2.48     |
| total_timesteps    | 824000   |
| value_loss         | 8.88e-06 |
---------------------------------
---------------------------------
| explained_variance | -0.0622  |
| fps                | 446      |
| nupdates           | 41300    |
| policy_entropy     | 2.43     |
| total_timesteps    | 826000   |
| value_loss         | 2.92e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.184    |
| fps                | 446      |
| nupdates           | 41400    |
| policy_entropy     | 2.43     |
| total_timesteps    | 828000   |
| value_loss         | 2.2e-05  |
---------------------------------
---------------------------------
| explained_variance | -1.36    |
| fps                | 446      |
| nupdates           | 41500    |
| policy_entropy     | 2.46     |
| total_timesteps    | 830000   |
| value_loss         | 4.12e-05 |
---------------------------------
---------------------------------
| explained_variance | -2.16    |
| fps                | 446      |
| nupdates           | 41600    |
| policy_entropy     | 2.4      |
| total_timesteps    | 832000   |
| value_loss         | 3.61e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.659    |
| fps                | 446      |
| nupdates           | 41700    |
| policy_entropy     | 2.4      |
| total_timesteps    | 834000   |
| value_loss         | 1.17e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.574    |
| fps                | 446      |
| nupdates           | 41800    |
| policy_entropy     | 2.45     |
| total_timesteps    | 836000   |
| value_loss         | 1.38e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.475    |
| fps                | 446      |
| nupdates           | 41900    |
| policy_entropy     | 2.49     |
| total_timesteps    | 838000   |
| value_loss         | 1.59e-05 |
---------------------------------
Eval num_timesteps=840000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.539    |
| fps                | 446      |
| nupdates           | 42000    |
| policy_entropy     | 2.43     |
| total_timesteps    | 840000   |
| value_loss         | 1.95e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.623    |
| fps                | 446      |
| nupdates           | 42100    |
| policy_entropy     | 2.49     |
| total_timesteps    | 842000   |
| value_loss         | 1.38e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.0362  |
| fps                | 446      |
| nupdates           | 42200    |
| policy_entropy     | 2.46     |
| total_timesteps    | 844000   |
| value_loss         | 2.47e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.166    |
| fps                | 446      |
| nupdates           | 42300    |
| policy_entropy     | 2.49     |
| total_timesteps    | 846000   |
| value_loss         | 2.49e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.468    |
| fps                | 446      |
| nupdates           | 42400    |
| policy_entropy     | 2.46     |
| total_timesteps    | 848000   |
| value_loss         | 1.19e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.38     |
| fps                | 446      |
| nupdates           | 42500    |
| policy_entropy     | 2.42     |
| total_timesteps    | 850000   |
| value_loss         | 9.17e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.653    |
| fps                | 446      |
| nupdates           | 42600    |
| policy_entropy     | 2.49     |
| total_timesteps    | 852000   |
| value_loss         | 5.75e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.775    |
| fps                | 446      |
| nupdates           | 42700    |
| policy_entropy     | 2.43     |
| total_timesteps    | 854000   |
| value_loss         | 2.68e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.51     |
| fps                | 446      |
| nupdates           | 42800    |
| policy_entropy     | 2.49     |
| total_timesteps    | 856000   |
| value_loss         | 1.3e-05  |
---------------------------------
---------------------------------
| explained_variance | -0.288   |
| fps                | 446      |
| nupdates           | 42900    |
| policy_entropy     | 2.46     |
| total_timesteps    | 858000   |
| value_loss         | 9.34e-05 |
---------------------------------
Eval num_timesteps=860000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.613    |
| fps                | 446      |
| nupdates           | 43000    |
| policy_entropy     | 2.46     |
| total_timesteps    | 860000   |
| value_loss         | 1.09e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.674   |
| fps                | 446      |
| nupdates           | 43100    |
| policy_entropy     | 2.36     |
| total_timesteps    | 862000   |
| value_loss         | 1.88e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.346    |
| fps                | 446      |
| nupdates           | 43200    |
| policy_entropy     | 2.46     |
| total_timesteps    | 864000   |
| value_loss         | 1.44e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.209    |
| fps                | 446      |
| nupdates           | 43300    |
| policy_entropy     | 2.52     |
| total_timesteps    | 866000   |
| value_loss         | 3.86e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.606    |
| fps                | 446      |
| nupdates           | 43400    |
| policy_entropy     | 2.43     |
| total_timesteps    | 868000   |
| value_loss         | 7.01e-06 |
---------------------------------
---------------------------------
| explained_variance | -0.234   |
| fps                | 446      |
| nupdates           | 43500    |
| policy_entropy     | 2.5      |
| total_timesteps    | 870000   |
| value_loss         | 5.19e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.118    |
| fps                | 446      |
| nupdates           | 43600    |
| policy_entropy     | 2.43     |
| total_timesteps    | 872000   |
| value_loss         | 5.58e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.356    |
| fps                | 446      |
| nupdates           | 43700    |
| policy_entropy     | 2.43     |
| total_timesteps    | 874000   |
| value_loss         | 2.74e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.583    |
| fps                | 446      |
| nupdates           | 43800    |
| policy_entropy     | 2.49     |
| total_timesteps    | 876000   |
| value_loss         | 1.17e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.252   |
| fps                | 446      |
| nupdates           | 43900    |
| policy_entropy     | 2.42     |
| total_timesteps    | 878000   |
| value_loss         | 1.16e-05 |
---------------------------------
Eval num_timesteps=880000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.248    |
| fps                | 446      |
| nupdates           | 44000    |
| policy_entropy     | 2.49     |
| total_timesteps    | 880000   |
| value_loss         | 1.08e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.842   |
| fps                | 446      |
| nupdates           | 44100    |
| policy_entropy     | 2.42     |
| total_timesteps    | 882000   |
| value_loss         | 5.17e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.642    |
| fps                | 446      |
| nupdates           | 44200    |
| policy_entropy     | 2.46     |
| total_timesteps    | 884000   |
| value_loss         | 5.04e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.668    |
| fps                | 446      |
| nupdates           | 44300    |
| policy_entropy     | 2.46     |
| total_timesteps    | 886000   |
| value_loss         | 4.26e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.681    |
| fps                | 446      |
| nupdates           | 44400    |
| policy_entropy     | 2.46     |
| total_timesteps    | 888000   |
| value_loss         | 6.92e-06 |
---------------------------------
---------------------------------
| explained_variance | -0.603   |
| fps                | 446      |
| nupdates           | 44500    |
| policy_entropy     | 2.49     |
| total_timesteps    | 890000   |
| value_loss         | 3.55e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.163   |
| fps                | 446      |
| nupdates           | 44600    |
| policy_entropy     | 2.41     |
| total_timesteps    | 892000   |
| value_loss         | 0.000259 |
---------------------------------
---------------------------------
| explained_variance | 0.248    |
| fps                | 446      |
| nupdates           | 44700    |
| policy_entropy     | 2.53     |
| total_timesteps    | 894000   |
| value_loss         | 6.4e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.17     |
| fps                | 446      |
| nupdates           | 44800    |
| policy_entropy     | 2.43     |
| total_timesteps    | 896000   |
| value_loss         | 1.44e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.714    |
| fps                | 446      |
| nupdates           | 44900    |
| policy_entropy     | 2.46     |
| total_timesteps    | 898000   |
| value_loss         | 1.41e-05 |
---------------------------------
Eval num_timesteps=900000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.619    |
| fps                | 446      |
| nupdates           | 45000    |
| policy_entropy     | 2.46     |
| total_timesteps    | 900000   |
| value_loss         | 2.47e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.392    |
| fps                | 446      |
| nupdates           | 45100    |
| policy_entropy     | 2.43     |
| total_timesteps    | 902000   |
| value_loss         | 4.43e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.556    |
| fps                | 446      |
| nupdates           | 45200    |
| policy_entropy     | 2.4      |
| total_timesteps    | 904000   |
| value_loss         | 2.36e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.499    |
| fps                | 446      |
| nupdates           | 45300    |
| policy_entropy     | 2.52     |
| total_timesteps    | 906000   |
| value_loss         | 1.65e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.281    |
| fps                | 446      |
| nupdates           | 45400    |
| policy_entropy     | 2.49     |
| total_timesteps    | 908000   |
| value_loss         | 3e-05    |
---------------------------------
---------------------------------
| explained_variance | 0.434    |
| fps                | 446      |
| nupdates           | 45500    |
| policy_entropy     | 2.4      |
| total_timesteps    | 910000   |
| value_loss         | 7.69e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.689    |
| fps                | 446      |
| nupdates           | 45600    |
| policy_entropy     | 2.49     |
| total_timesteps    | 912000   |
| value_loss         | 1.75e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.23     |
| fps                | 446      |
| nupdates           | 45700    |
| policy_entropy     | 2.49     |
| total_timesteps    | 914000   |
| value_loss         | 1.61e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.579    |
| fps                | 446      |
| nupdates           | 45800    |
| policy_entropy     | 2.48     |
| total_timesteps    | 916000   |
| value_loss         | 1.41e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.71    |
| fps                | 446      |
| nupdates           | 45900    |
| policy_entropy     | 2.49     |
| total_timesteps    | 918000   |
| value_loss         | 0.000145 |
---------------------------------
Eval num_timesteps=920000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -2.72    |
| fps                | 446      |
| nupdates           | 46000    |
| policy_entropy     | 2.45     |
| total_timesteps    | 920000   |
| value_loss         | 0.000136 |
---------------------------------
---------------------------------
| explained_variance | -0.942   |
| fps                | 446      |
| nupdates           | 46100    |
| policy_entropy     | 2.42     |
| total_timesteps    | 922000   |
| value_loss         | 2.88e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.632    |
| fps                | 446      |
| nupdates           | 46200    |
| policy_entropy     | 2.48     |
| total_timesteps    | 924000   |
| value_loss         | 1.74e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.578    |
| fps                | 446      |
| nupdates           | 46300    |
| policy_entropy     | 2.46     |
| total_timesteps    | 926000   |
| value_loss         | 9.22e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.487    |
| fps                | 446      |
| nupdates           | 46400    |
| policy_entropy     | 2.52     |
| total_timesteps    | 928000   |
| value_loss         | 1.42e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.0982  |
| fps                | 446      |
| nupdates           | 46500    |
| policy_entropy     | 2.39     |
| total_timesteps    | 930000   |
| value_loss         | 1.4e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.356    |
| fps                | 446      |
| nupdates           | 46600    |
| policy_entropy     | 2.52     |
| total_timesteps    | 932000   |
| value_loss         | 3.81e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.549    |
| fps                | 446      |
| nupdates           | 46700    |
| policy_entropy     | 2.46     |
| total_timesteps    | 934000   |
| value_loss         | 5.06e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.459    |
| fps                | 446      |
| nupdates           | 46800    |
| policy_entropy     | 2.46     |
| total_timesteps    | 936000   |
| value_loss         | 2.44e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.318    |
| fps                | 446      |
| nupdates           | 46900    |
| policy_entropy     | 2.49     |
| total_timesteps    | 938000   |
| value_loss         | 2.33e-05 |
---------------------------------
Eval num_timesteps=940000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.461    |
| fps                | 446      |
| nupdates           | 47000    |
| policy_entropy     | 2.46     |
| total_timesteps    | 940000   |
| value_loss         | 1.27e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.0346   |
| fps                | 446      |
| nupdates           | 47100    |
| policy_entropy     | 2.46     |
| total_timesteps    | 942000   |
| value_loss         | 2.72e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.618    |
| fps                | 446      |
| nupdates           | 47200    |
| policy_entropy     | 2.45     |
| total_timesteps    | 944000   |
| value_loss         | 1.5e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.113    |
| fps                | 446      |
| nupdates           | 47300    |
| policy_entropy     | 2.43     |
| total_timesteps    | 946000   |
| value_loss         | 3.59e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.411    |
| fps                | 446      |
| nupdates           | 47400    |
| policy_entropy     | 2.49     |
| total_timesteps    | 948000   |
| value_loss         | 1.3e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.353    |
| fps                | 446      |
| nupdates           | 47500    |
| policy_entropy     | 2.42     |
| total_timesteps    | 950000   |
| value_loss         | 1.18e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.376   |
| fps                | 446      |
| nupdates           | 47600    |
| policy_entropy     | 2.42     |
| total_timesteps    | 952000   |
| value_loss         | 6.3e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.46     |
| fps                | 446      |
| nupdates           | 47700    |
| policy_entropy     | 2.49     |
| total_timesteps    | 954000   |
| value_loss         | 1.58e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.503    |
| fps                | 446      |
| nupdates           | 47800    |
| policy_entropy     | 2.49     |
| total_timesteps    | 956000   |
| value_loss         | 1.68e-05 |
---------------------------------
---------------------------------
| explained_variance | -2.33    |
| fps                | 446      |
| nupdates           | 47900    |
| policy_entropy     | 2.42     |
| total_timesteps    | 958000   |
| value_loss         | 0.000107 |
---------------------------------
Eval num_timesteps=960000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.245    |
| fps                | 446      |
| nupdates           | 48000    |
| policy_entropy     | 2.42     |
| total_timesteps    | 960000   |
| value_loss         | 8.83e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.225    |
| fps                | 446      |
| nupdates           | 48100    |
| policy_entropy     | 2.5      |
| total_timesteps    | 962000   |
| value_loss         | 7.55e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.733    |
| fps                | 446      |
| nupdates           | 48200    |
| policy_entropy     | 2.43     |
| total_timesteps    | 964000   |
| value_loss         | 8.44e-06 |
---------------------------------
---------------------------------
| explained_variance | -3.08    |
| fps                | 446      |
| nupdates           | 48300    |
| policy_entropy     | 2.45     |
| total_timesteps    | 966000   |
| value_loss         | 0.000626 |
---------------------------------
---------------------------------
| explained_variance | 0.494    |
| fps                | 446      |
| nupdates           | 48400    |
| policy_entropy     | 2.49     |
| total_timesteps    | 968000   |
| value_loss         | 1.32e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.137    |
| fps                | 447      |
| nupdates           | 48500    |
| policy_entropy     | 2.43     |
| total_timesteps    | 970000   |
| value_loss         | 9.12e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.495    |
| fps                | 447      |
| nupdates           | 48600    |
| policy_entropy     | 2.48     |
| total_timesteps    | 972000   |
| value_loss         | 7.22e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.255    |
| fps                | 447      |
| nupdates           | 48700    |
| policy_entropy     | 2.49     |
| total_timesteps    | 974000   |
| value_loss         | 3.92e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.331    |
| fps                | 447      |
| nupdates           | 48800    |
| policy_entropy     | 2.42     |
| total_timesteps    | 976000   |
| value_loss         | 1.67e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.419    |
| fps                | 447      |
| nupdates           | 48900    |
| policy_entropy     | 2.43     |
| total_timesteps    | 978000   |
| value_loss         | 9.32e-06 |
---------------------------------
Eval num_timesteps=980000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -0.414   |
| fps                | 446      |
| nupdates           | 49000    |
| policy_entropy     | 2.49     |
| total_timesteps    | 980000   |
| value_loss         | 2.5e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.191    |
| fps                | 447      |
| nupdates           | 49100    |
| policy_entropy     | 2.46     |
| total_timesteps    | 982000   |
| value_loss         | 2.26e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.28     |
| fps                | 447      |
| nupdates           | 49200    |
| policy_entropy     | 2.5      |
| total_timesteps    | 984000   |
| value_loss         | 8.57e-05 |
---------------------------------
---------------------------------
| explained_variance | -2.03    |
| fps                | 447      |
| nupdates           | 49300    |
| policy_entropy     | 2.43     |
| total_timesteps    | 986000   |
| value_loss         | 0.000113 |
---------------------------------
---------------------------------
| explained_variance | -6.51    |
| fps                | 447      |
| nupdates           | 49400    |
| policy_entropy     | 2.43     |
| total_timesteps    | 988000   |
| value_loss         | 0.00123  |
---------------------------------
---------------------------------
| explained_variance | -0.91    |
| fps                | 447      |
| nupdates           | 49500    |
| policy_entropy     | 2.39     |
| total_timesteps    | 990000   |
| value_loss         | 3.48e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.649    |
| fps                | 447      |
| nupdates           | 49600    |
| policy_entropy     | 2.52     |
| total_timesteps    | 992000   |
| value_loss         | 1.07e-05 |
---------------------------------
---------------------------------
| explained_variance | -2.5     |
| fps                | 447      |
| nupdates           | 49700    |
| policy_entropy     | 2.49     |
| total_timesteps    | 994000   |
| value_loss         | 0.000331 |
---------------------------------
---------------------------------
| explained_variance | 0.51     |
| fps                | 447      |
| nupdates           | 49800    |
| policy_entropy     | 2.48     |
| total_timesteps    | 996000   |
| value_loss         | 3.58e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.599    |
| fps                | 447      |
| nupdates           | 49900    |
| policy_entropy     | 2.46     |
| total_timesteps    | 998000   |
| value_loss         | 6.05e-06 |
---------------------------------
Eval num_timesteps=1000000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -1.12    |
| fps                | 447      |
| nupdates           | 50000    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1000000  |
| value_loss         | 2.68e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.0202   |
| fps                | 447      |
| nupdates           | 50100    |
| policy_entropy     | 2.51     |
| total_timesteps    | 1002000  |
| value_loss         | 3.3e-05  |
---------------------------------
---------------------------------
| explained_variance | -0.054   |
| fps                | 447      |
| nupdates           | 50200    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1004000  |
| value_loss         | 2.2e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.398    |
| fps                | 447      |
| nupdates           | 50300    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1006000  |
| value_loss         | 1.69e-05 |
---------------------------------
---------------------------------
| explained_variance | -4.2     |
| fps                | 447      |
| nupdates           | 50400    |
| policy_entropy     | 2.4      |
| total_timesteps    | 1008000  |
| value_loss         | 5.97e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.383    |
| fps                | 447      |
| nupdates           | 50500    |
| policy_entropy     | 2.48     |
| total_timesteps    | 1010000  |
| value_loss         | 1.17e-05 |
---------------------------------
---------------------------------
| explained_variance | -3.51    |
| fps                | 447      |
| nupdates           | 50600    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1012000  |
| value_loss         | 0.000742 |
---------------------------------
---------------------------------
| explained_variance | 0.645    |
| fps                | 447      |
| nupdates           | 50700    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1014000  |
| value_loss         | 4.39e-06 |
---------------------------------
---------------------------------
| explained_variance | -2.99    |
| fps                | 447      |
| nupdates           | 50800    |
| policy_entropy     | 2.45     |
| total_timesteps    | 1016000  |
| value_loss         | 0.00029  |
---------------------------------
---------------------------------
| explained_variance | -0.489   |
| fps                | 447      |
| nupdates           | 50900    |
| policy_entropy     | 2.41     |
| total_timesteps    | 1018000  |
| value_loss         | 1.83e-05 |
---------------------------------
Eval num_timesteps=1020000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -0.739   |
| fps                | 447      |
| nupdates           | 51000    |
| policy_entropy     | 2.41     |
| total_timesteps    | 1020000  |
| value_loss         | 3.24e-05 |
---------------------------------
---------------------------------
| explained_variance | -8.16    |
| fps                | 447      |
| nupdates           | 51100    |
| policy_entropy     | 2.39     |
| total_timesteps    | 1022000  |
| value_loss         | 7.43e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.94    |
| fps                | 447      |
| nupdates           | 51200    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1024000  |
| value_loss         | 0.00017  |
---------------------------------
---------------------------------
| explained_variance | -1.35    |
| fps                | 447      |
| nupdates           | 51300    |
| policy_entropy     | 2.4      |
| total_timesteps    | 1026000  |
| value_loss         | 0.000349 |
---------------------------------
---------------------------------
| explained_variance | 0.67     |
| fps                | 447      |
| nupdates           | 51400    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1028000  |
| value_loss         | 8.47e-06 |
---------------------------------
---------------------------------
| explained_variance | -2.86    |
| fps                | 447      |
| nupdates           | 51500    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1030000  |
| value_loss         | 0.00025  |
---------------------------------
---------------------------------
| explained_variance | -1.46    |
| fps                | 447      |
| nupdates           | 51600    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1032000  |
| value_loss         | 5.17e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.457    |
| fps                | 447      |
| nupdates           | 51700    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1034000  |
| value_loss         | 4.2e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.58     |
| fps                | 447      |
| nupdates           | 51800    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1036000  |
| value_loss         | 8.92e-06 |
---------------------------------
---------------------------------
| explained_variance | -7.73    |
| fps                | 447      |
| nupdates           | 51900    |
| policy_entropy     | 2.45     |
| total_timesteps    | 1038000  |
| value_loss         | 0.000244 |
---------------------------------
Eval num_timesteps=1040000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.58     |
| fps                | 447      |
| nupdates           | 52000    |
| policy_entropy     | 2.41     |
| total_timesteps    | 1040000  |
| value_loss         | 6.99e-06 |
---------------------------------
---------------------------------
| explained_variance | -0.951   |
| fps                | 447      |
| nupdates           | 52100    |
| policy_entropy     | 2.53     |
| total_timesteps    | 1042000  |
| value_loss         | 0.000147 |
---------------------------------
---------------------------------
| explained_variance | 0.801    |
| fps                | 447      |
| nupdates           | 52200    |
| policy_entropy     | 2.39     |
| total_timesteps    | 1044000  |
| value_loss         | 8.46e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.472    |
| fps                | 447      |
| nupdates           | 52300    |
| policy_entropy     | 2.45     |
| total_timesteps    | 1046000  |
| value_loss         | 1.44e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.991   |
| fps                | 447      |
| nupdates           | 52400    |
| policy_entropy     | 2.45     |
| total_timesteps    | 1048000  |
| value_loss         | 4.3e-05  |
---------------------------------
---------------------------------
| explained_variance | -1.21    |
| fps                | 447      |
| nupdates           | 52500    |
| policy_entropy     | 2.54     |
| total_timesteps    | 1050000  |
| value_loss         | 0.000199 |
---------------------------------
---------------------------------
| explained_variance | 0.402    |
| fps                | 447      |
| nupdates           | 52600    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1052000  |
| value_loss         | 2.06e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.28    |
| fps                | 447      |
| nupdates           | 52700    |
| policy_entropy     | 2.47     |
| total_timesteps    | 1054000  |
| value_loss         | 0.000127 |
---------------------------------
---------------------------------
| explained_variance | 0.226    |
| fps                | 447      |
| nupdates           | 52800    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1056000  |
| value_loss         | 6.84e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.522    |
| fps                | 447      |
| nupdates           | 52900    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1058000  |
| value_loss         | 1.95e-05 |
---------------------------------
Eval num_timesteps=1060000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -0.986   |
| fps                | 447      |
| nupdates           | 53000    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1060000  |
| value_loss         | 0.000104 |
---------------------------------
---------------------------------
| explained_variance | 0.586    |
| fps                | 447      |
| nupdates           | 53100    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1062000  |
| value_loss         | 1.09e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.713    |
| fps                | 447      |
| nupdates           | 53200    |
| policy_entropy     | 2.36     |
| total_timesteps    | 1064000  |
| value_loss         | 1.19e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.0828   |
| fps                | 447      |
| nupdates           | 53300    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1066000  |
| value_loss         | 3.64e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.364    |
| fps                | 447      |
| nupdates           | 53400    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1068000  |
| value_loss         | 3.16e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.43    |
| fps                | 447      |
| nupdates           | 53500    |
| policy_entropy     | 2.47     |
| total_timesteps    | 1070000  |
| value_loss         | 0.000153 |
---------------------------------
---------------------------------
| explained_variance | -3.35    |
| fps                | 447      |
| nupdates           | 53600    |
| policy_entropy     | 2.35     |
| total_timesteps    | 1072000  |
| value_loss         | 0.000247 |
---------------------------------
---------------------------------
| explained_variance | -3.45    |
| fps                | 447      |
| nupdates           | 53700    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1074000  |
| value_loss         | 0.000146 |
---------------------------------
---------------------------------
| explained_variance | 0.41     |
| fps                | 447      |
| nupdates           | 53800    |
| policy_entropy     | 2.39     |
| total_timesteps    | 1076000  |
| value_loss         | 9.63e-06 |
---------------------------------
---------------------------------
| explained_variance | -0.0768  |
| fps                | 447      |
| nupdates           | 53900    |
| policy_entropy     | 2.39     |
| total_timesteps    | 1078000  |
| value_loss         | 1.9e-05  |
---------------------------------
Eval num_timesteps=1080000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -4.17    |
| fps                | 447      |
| nupdates           | 54000    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1080000  |
| value_loss         | 0.000148 |
---------------------------------
---------------------------------
| explained_variance | 0.123    |
| fps                | 447      |
| nupdates           | 54100    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1082000  |
| value_loss         | 6.42e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.639    |
| fps                | 447      |
| nupdates           | 54200    |
| policy_entropy     | 2.47     |
| total_timesteps    | 1084000  |
| value_loss         | 9.18e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.562    |
| fps                | 447      |
| nupdates           | 54300    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1086000  |
| value_loss         | 5.19e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.596    |
| fps                | 447      |
| nupdates           | 54400    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1088000  |
| value_loss         | 1.64e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.0968  |
| fps                | 447      |
| nupdates           | 54500    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1090000  |
| value_loss         | 1.82e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.714    |
| fps                | 447      |
| nupdates           | 54600    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1092000  |
| value_loss         | 5.24e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.433    |
| fps                | 447      |
| nupdates           | 54700    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1094000  |
| value_loss         | 4.24e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.359   |
| fps                | 447      |
| nupdates           | 54800    |
| policy_entropy     | 2.48     |
| total_timesteps    | 1096000  |
| value_loss         | 0.000151 |
---------------------------------
---------------------------------
| explained_variance | -1.18    |
| fps                | 447      |
| nupdates           | 54900    |
| policy_entropy     | 2.51     |
| total_timesteps    | 1098000  |
| value_loss         | 8.75e-05 |
---------------------------------
Eval num_timesteps=1100000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.349    |
| fps                | 447      |
| nupdates           | 55000    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1100000  |
| value_loss         | 1.05e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.0236   |
| fps                | 447      |
| nupdates           | 55100    |
| policy_entropy     | 2.48     |
| total_timesteps    | 1102000  |
| value_loss         | 2.77e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.25     |
| fps                | 447      |
| nupdates           | 55200    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1104000  |
| value_loss         | 1.94e-05 |
---------------------------------
---------------------------------
| explained_variance | -2.36    |
| fps                | 447      |
| nupdates           | 55300    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1106000  |
| value_loss         | 0.000479 |
---------------------------------
---------------------------------
| explained_variance | -7.23    |
| fps                | 447      |
| nupdates           | 55400    |
| policy_entropy     | 2.39     |
| total_timesteps    | 1108000  |
| value_loss         | 0.000169 |
---------------------------------
---------------------------------
| explained_variance | 0.68     |
| fps                | 447      |
| nupdates           | 55500    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1110000  |
| value_loss         | 5.27e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.625    |
| fps                | 447      |
| nupdates           | 55600    |
| policy_entropy     | 2.45     |
| total_timesteps    | 1112000  |
| value_loss         | 1.8e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.0235   |
| fps                | 447      |
| nupdates           | 55700    |
| policy_entropy     | 2.39     |
| total_timesteps    | 1114000  |
| value_loss         | 1.86e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.288    |
| fps                | 447      |
| nupdates           | 55800    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1116000  |
| value_loss         | 2.79e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.543   |
| fps                | 447      |
| nupdates           | 55900    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1118000  |
| value_loss         | 9.16e-05 |
---------------------------------
Eval num_timesteps=1120000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -2.17    |
| fps                | 447      |
| nupdates           | 56000    |
| policy_entropy     | 2.44     |
| total_timesteps    | 1120000  |
| value_loss         | 9.83e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.502    |
| fps                | 447      |
| nupdates           | 56100    |
| policy_entropy     | 2.52     |
| total_timesteps    | 1122000  |
| value_loss         | 1.72e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.604    |
| fps                | 447      |
| nupdates           | 56200    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1124000  |
| value_loss         | 1.07e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.261    |
| fps                | 447      |
| nupdates           | 56300    |
| policy_entropy     | 2.52     |
| total_timesteps    | 1126000  |
| value_loss         | 8.05e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.634    |
| fps                | 447      |
| nupdates           | 56400    |
| policy_entropy     | 2.44     |
| total_timesteps    | 1128000  |
| value_loss         | 5.16e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.628    |
| fps                | 447      |
| nupdates           | 56500    |
| policy_entropy     | 2.47     |
| total_timesteps    | 1130000  |
| value_loss         | 1.15e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.814    |
| fps                | 447      |
| nupdates           | 56600    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1132000  |
| value_loss         | 9.99e-06 |
---------------------------------
---------------------------------
| explained_variance | -1.13    |
| fps                | 447      |
| nupdates           | 56700    |
| policy_entropy     | 2.39     |
| total_timesteps    | 1134000  |
| value_loss         | 3.91e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.195    |
| fps                | 447      |
| nupdates           | 56800    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1136000  |
| value_loss         | 1.96e-05 |
---------------------------------
---------------------------------
| explained_variance | -4.07    |
| fps                | 447      |
| nupdates           | 56900    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1138000  |
| value_loss         | 0.000223 |
---------------------------------
Eval num_timesteps=1140000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -0.322   |
| fps                | 447      |
| nupdates           | 57000    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1140000  |
| value_loss         | 2.28e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.486    |
| fps                | 447      |
| nupdates           | 57100    |
| policy_entropy     | 2.52     |
| total_timesteps    | 1142000  |
| value_loss         | 2.95e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.187    |
| fps                | 447      |
| nupdates           | 57200    |
| policy_entropy     | 2.52     |
| total_timesteps    | 1144000  |
| value_loss         | 2.85e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.361    |
| fps                | 447      |
| nupdates           | 57300    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1146000  |
| value_loss         | 2.39e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.628    |
| fps                | 447      |
| nupdates           | 57400    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1148000  |
| value_loss         | 7.5e-06  |
---------------------------------
---------------------------------
| explained_variance | -0.137   |
| fps                | 447      |
| nupdates           | 57500    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1150000  |
| value_loss         | 5.2e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.548    |
| fps                | 447      |
| nupdates           | 57600    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1152000  |
| value_loss         | 8.45e-06 |
---------------------------------
---------------------------------
| explained_variance | -3.96    |
| fps                | 447      |
| nupdates           | 57700    |
| policy_entropy     | 2.4      |
| total_timesteps    | 1154000  |
| value_loss         | 0.000181 |
---------------------------------
---------------------------------
| explained_variance | 0.479    |
| fps                | 447      |
| nupdates           | 57800    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1156000  |
| value_loss         | 1.77e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.474    |
| fps                | 447      |
| nupdates           | 57900    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1158000  |
| value_loss         | 4.84e-05 |
---------------------------------
Eval num_timesteps=1160000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.0707   |
| fps                | 447      |
| nupdates           | 58000    |
| policy_entropy     | 2.52     |
| total_timesteps    | 1160000  |
| value_loss         | 0.000134 |
---------------------------------
---------------------------------
| explained_variance | 0.604    |
| fps                | 447      |
| nupdates           | 58100    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1162000  |
| value_loss         | 8.82e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.523    |
| fps                | 447      |
| nupdates           | 58200    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1164000  |
| value_loss         | 1.48e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.357    |
| fps                | 447      |
| nupdates           | 58300    |
| policy_entropy     | 2.47     |
| total_timesteps    | 1166000  |
| value_loss         | 2.06e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.377   |
| fps                | 447      |
| nupdates           | 58400    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1168000  |
| value_loss         | 4.77e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.32     |
| fps                | 447      |
| nupdates           | 58500    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1170000  |
| value_loss         | 2.18e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.455    |
| fps                | 447      |
| nupdates           | 58600    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1172000  |
| value_loss         | 0.000101 |
---------------------------------
---------------------------------
| explained_variance | 0.0532   |
| fps                | 447      |
| nupdates           | 58700    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1174000  |
| value_loss         | 1.67e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.586    |
| fps                | 447      |
| nupdates           | 58800    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1176000  |
| value_loss         | 2.25e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.38     |
| fps                | 447      |
| nupdates           | 58900    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1178000  |
| value_loss         | 1.3e-05  |
---------------------------------
Eval num_timesteps=1180000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -0.442   |
| fps                | 447      |
| nupdates           | 59000    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1180000  |
| value_loss         | 4.53e-05 |
---------------------------------
---------------------------------
| explained_variance | -2.87    |
| fps                | 447      |
| nupdates           | 59100    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1182000  |
| value_loss         | 0.000184 |
---------------------------------
---------------------------------
| explained_variance | 0.508    |
| fps                | 447      |
| nupdates           | 59200    |
| policy_entropy     | 2.52     |
| total_timesteps    | 1184000  |
| value_loss         | 2.49e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.579    |
| fps                | 447      |
| nupdates           | 59300    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1186000  |
| value_loss         | 6.64e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.262    |
| fps                | 447      |
| nupdates           | 59400    |
| policy_entropy     | 2.5      |
| total_timesteps    | 1188000  |
| value_loss         | 2.56e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.65     |
| fps                | 447      |
| nupdates           | 59500    |
| policy_entropy     | 2.47     |
| total_timesteps    | 1190000  |
| value_loss         | 8.58e-06 |
---------------------------------
---------------------------------
| explained_variance | -0.837   |
| fps                | 447      |
| nupdates           | 59600    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1192000  |
| value_loss         | 2.68e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.104   |
| fps                | 447      |
| nupdates           | 59700    |
| policy_entropy     | 2.5      |
| total_timesteps    | 1194000  |
| value_loss         | 3.23e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.426    |
| fps                | 447      |
| nupdates           | 59800    |
| policy_entropy     | 2.45     |
| total_timesteps    | 1196000  |
| value_loss         | 2.34e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.327    |
| fps                | 447      |
| nupdates           | 59900    |
| policy_entropy     | 2.45     |
| total_timesteps    | 1198000  |
| value_loss         | 1.68e-05 |
---------------------------------
Eval num_timesteps=1200000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.384    |
| fps                | 447      |
| nupdates           | 60000    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1200000  |
| value_loss         | 1.78e-05 |
---------------------------------
---------------------------------
| explained_variance | -2.31    |
| fps                | 447      |
| nupdates           | 60100    |
| policy_entropy     | 2.39     |
| total_timesteps    | 1202000  |
| value_loss         | 2.96e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.471    |
| fps                | 447      |
| nupdates           | 60200    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1204000  |
| value_loss         | 1.24e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.691    |
| fps                | 447      |
| nupdates           | 60300    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1206000  |
| value_loss         | 6.77e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.193    |
| fps                | 447      |
| nupdates           | 60400    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1208000  |
| value_loss         | 1.52e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.0583   |
| fps                | 447      |
| nupdates           | 60500    |
| policy_entropy     | 2.45     |
| total_timesteps    | 1210000  |
| value_loss         | 3.46e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.145    |
| fps                | 447      |
| nupdates           | 60600    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1212000  |
| value_loss         | 1.82e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.326   |
| fps                | 447      |
| nupdates           | 60700    |
| policy_entropy     | 2.39     |
| total_timesteps    | 1214000  |
| value_loss         | 1.15e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.366    |
| fps                | 447      |
| nupdates           | 60800    |
| policy_entropy     | 2.55     |
| total_timesteps    | 1216000  |
| value_loss         | 2.24e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.57    |
| fps                | 447      |
| nupdates           | 60900    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1218000  |
| value_loss         | 5.82e-05 |
---------------------------------
Eval num_timesteps=1220000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -0.131   |
| fps                | 447      |
| nupdates           | 61000    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1220000  |
| value_loss         | 5.18e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.481    |
| fps                | 447      |
| nupdates           | 61100    |
| policy_entropy     | 2.52     |
| total_timesteps    | 1222000  |
| value_loss         | 1.25e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.169    |
| fps                | 447      |
| nupdates           | 61200    |
| policy_entropy     | 2.45     |
| total_timesteps    | 1224000  |
| value_loss         | 1.67e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.699    |
| fps                | 447      |
| nupdates           | 61300    |
| policy_entropy     | 2.45     |
| total_timesteps    | 1226000  |
| value_loss         | 1.42e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.547    |
| fps                | 447      |
| nupdates           | 61400    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1228000  |
| value_loss         | 8.47e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.308    |
| fps                | 447      |
| nupdates           | 61500    |
| policy_entropy     | 2.52     |
| total_timesteps    | 1230000  |
| value_loss         | 9.14e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.656    |
| fps                | 447      |
| nupdates           | 61600    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1232000  |
| value_loss         | 1.53e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.137   |
| fps                | 447      |
| nupdates           | 61700    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1234000  |
| value_loss         | 1.47e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.379    |
| fps                | 447      |
| nupdates           | 61800    |
| policy_entropy     | 2.54     |
| total_timesteps    | 1236000  |
| value_loss         | 5.24e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.0579  |
| fps                | 447      |
| nupdates           | 61900    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1238000  |
| value_loss         | 5.63e-05 |
---------------------------------
Eval num_timesteps=1240000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.436    |
| fps                | 447      |
| nupdates           | 62000    |
| policy_entropy     | 2.48     |
| total_timesteps    | 1240000  |
| value_loss         | 1.9e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.214    |
| fps                | 447      |
| nupdates           | 62100    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1242000  |
| value_loss         | 1.26e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.183    |
| fps                | 447      |
| nupdates           | 62200    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1244000  |
| value_loss         | 9.99e-06 |
---------------------------------
---------------------------------
| explained_variance | -1.63    |
| fps                | 447      |
| nupdates           | 62300    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1246000  |
| value_loss         | 6.61e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.165   |
| fps                | 447      |
| nupdates           | 62400    |
| policy_entropy     | 2.52     |
| total_timesteps    | 1248000  |
| value_loss         | 2.81e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.548    |
| fps                | 447      |
| nupdates           | 62500    |
| policy_entropy     | 2.45     |
| total_timesteps    | 1250000  |
| value_loss         | 9.17e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.617    |
| fps                | 447      |
| nupdates           | 62600    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1252000  |
| value_loss         | 8.23e-06 |
---------------------------------
---------------------------------
| explained_variance | -1.82    |
| fps                | 447      |
| nupdates           | 62700    |
| policy_entropy     | 2.45     |
| total_timesteps    | 1254000  |
| value_loss         | 0.000158 |
---------------------------------
---------------------------------
| explained_variance | 0.202    |
| fps                | 447      |
| nupdates           | 62800    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1256000  |
| value_loss         | 4.19e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.422    |
| fps                | 447      |
| nupdates           | 62900    |
| policy_entropy     | 2.39     |
| total_timesteps    | 1258000  |
| value_loss         | 9.56e-06 |
---------------------------------
Eval num_timesteps=1260000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.368    |
| fps                | 447      |
| nupdates           | 63000    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1260000  |
| value_loss         | 1.8e-05  |
---------------------------------
---------------------------------
| explained_variance | -3.94    |
| fps                | 447      |
| nupdates           | 63100    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1262000  |
| value_loss         | 0.00013  |
---------------------------------
---------------------------------
| explained_variance | 0.449    |
| fps                | 447      |
| nupdates           | 63200    |
| policy_entropy     | 2.52     |
| total_timesteps    | 1264000  |
| value_loss         | 2.93e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.918   |
| fps                | 447      |
| nupdates           | 63300    |
| policy_entropy     | 2.47     |
| total_timesteps    | 1266000  |
| value_loss         | 9.12e-05 |
---------------------------------
---------------------------------
| explained_variance | -2.33    |
| fps                | 447      |
| nupdates           | 63400    |
| policy_entropy     | 2.35     |
| total_timesteps    | 1268000  |
| value_loss         | 7.08e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.208    |
| fps                | 447      |
| nupdates           | 63500    |
| policy_entropy     | 2.48     |
| total_timesteps    | 1270000  |
| value_loss         | 3.81e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.134    |
| fps                | 447      |
| nupdates           | 63600    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1272000  |
| value_loss         | 1.43e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.76     |
| fps                | 447      |
| nupdates           | 63700    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1274000  |
| value_loss         | 3.01e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.463    |
| fps                | 447      |
| nupdates           | 63800    |
| policy_entropy     | 2.4      |
| total_timesteps    | 1276000  |
| value_loss         | 2.39e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.666    |
| fps                | 447      |
| nupdates           | 63900    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1278000  |
| value_loss         | 6.31e-06 |
---------------------------------
Eval num_timesteps=1280000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -1.75    |
| fps                | 447      |
| nupdates           | 64000    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1280000  |
| value_loss         | 0.000103 |
---------------------------------
---------------------------------
| explained_variance | 0.418    |
| fps                | 447      |
| nupdates           | 64100    |
| policy_entropy     | 2.56     |
| total_timesteps    | 1282000  |
| value_loss         | 3.51e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.438    |
| fps                | 447      |
| nupdates           | 64200    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1284000  |
| value_loss         | 1.37e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.45     |
| fps                | 447      |
| nupdates           | 64300    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1286000  |
| value_loss         | 4.41e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.286    |
| fps                | 447      |
| nupdates           | 64400    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1288000  |
| value_loss         | 2.93e-05 |
---------------------------------
---------------------------------
| explained_variance | -3.07    |
| fps                | 447      |
| nupdates           | 64500    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1290000  |
| value_loss         | 0.00116  |
---------------------------------
---------------------------------
| explained_variance | 0.684    |
| fps                | 447      |
| nupdates           | 64600    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1292000  |
| value_loss         | 4.93e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.727    |
| fps                | 447      |
| nupdates           | 64700    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1294000  |
| value_loss         | 7.1e-06  |
---------------------------------
---------------------------------
| explained_variance | -0.197   |
| fps                | 447      |
| nupdates           | 64800    |
| policy_entropy     | 2.48     |
| total_timesteps    | 1296000  |
| value_loss         | 1.86e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.784   |
| fps                | 447      |
| nupdates           | 64900    |
| policy_entropy     | 2.5      |
| total_timesteps    | 1298000  |
| value_loss         | 0.000114 |
---------------------------------
Eval num_timesteps=1300000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -2.75    |
| fps                | 447      |
| nupdates           | 65000    |
| policy_entropy     | 2.41     |
| total_timesteps    | 1300000  |
| value_loss         | 8.64e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.737    |
| fps                | 447      |
| nupdates           | 65100    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1302000  |
| value_loss         | 7.43e-06 |
---------------------------------
---------------------------------
| explained_variance | -7.64    |
| fps                | 447      |
| nupdates           | 65200    |
| policy_entropy     | 2.44     |
| total_timesteps    | 1304000  |
| value_loss         | 7.56e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.651    |
| fps                | 447      |
| nupdates           | 65300    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1306000  |
| value_loss         | 2.03e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.374   |
| fps                | 447      |
| nupdates           | 65400    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1308000  |
| value_loss         | 0.000139 |
---------------------------------
---------------------------------
| explained_variance | -0.314   |
| fps                | 447      |
| nupdates           | 65500    |
| policy_entropy     | 2.52     |
| total_timesteps    | 1310000  |
| value_loss         | 6.42e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.31     |
| fps                | 447      |
| nupdates           | 65600    |
| policy_entropy     | 2.5      |
| total_timesteps    | 1312000  |
| value_loss         | 1.63e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.17    |
| fps                | 447      |
| nupdates           | 65700    |
| policy_entropy     | 2.45     |
| total_timesteps    | 1314000  |
| value_loss         | 2e-05    |
---------------------------------
---------------------------------
| explained_variance | 0.531    |
| fps                | 447      |
| nupdates           | 65800    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1316000  |
| value_loss         | 1.83e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.43     |
| fps                | 447      |
| nupdates           | 65900    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1318000  |
| value_loss         | 1.42e-05 |
---------------------------------
Eval num_timesteps=1320000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.535    |
| fps                | 447      |
| nupdates           | 66000    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1320000  |
| value_loss         | 3.66e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.223    |
| fps                | 447      |
| nupdates           | 66100    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1322000  |
| value_loss         | 1.43e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.432   |
| fps                | 447      |
| nupdates           | 66200    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1324000  |
| value_loss         | 2.06e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.662   |
| fps                | 447      |
| nupdates           | 66300    |
| policy_entropy     | 2.5      |
| total_timesteps    | 1326000  |
| value_loss         | 0.000108 |
---------------------------------
---------------------------------
| explained_variance | 0.841    |
| fps                | 447      |
| nupdates           | 66400    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1328000  |
| value_loss         | 1.23e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.769   |
| fps                | 447      |
| nupdates           | 66500    |
| policy_entropy     | 2.39     |
| total_timesteps    | 1330000  |
| value_loss         | 8.26e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.72     |
| fps                | 447      |
| nupdates           | 66600    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1332000  |
| value_loss         | 2.63e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.473    |
| fps                | 447      |
| nupdates           | 66700    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1334000  |
| value_loss         | 6.05e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.444    |
| fps                | 447      |
| nupdates           | 66800    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1336000  |
| value_loss         | 7.93e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.474    |
| fps                | 447      |
| nupdates           | 66900    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1338000  |
| value_loss         | 7.58e-06 |
---------------------------------
Eval num_timesteps=1340000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -0.565   |
| fps                | 447      |
| nupdates           | 67000    |
| policy_entropy     | 2.52     |
| total_timesteps    | 1340000  |
| value_loss         | 0.000232 |
---------------------------------
---------------------------------
| explained_variance | 0.541    |
| fps                | 447      |
| nupdates           | 67100    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1342000  |
| value_loss         | 1.87e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.51     |
| fps                | 447      |
| nupdates           | 67200    |
| policy_entropy     | 2.39     |
| total_timesteps    | 1344000  |
| value_loss         | 1.19e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.551    |
| fps                | 447      |
| nupdates           | 67300    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1346000  |
| value_loss         | 1.82e-05 |
---------------------------------
---------------------------------
| explained_variance | -2.9     |
| fps                | 447      |
| nupdates           | 67400    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1348000  |
| value_loss         | 4.57e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.593    |
| fps                | 447      |
| nupdates           | 67500    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1350000  |
| value_loss         | 1.76e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.503    |
| fps                | 447      |
| nupdates           | 67600    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1352000  |
| value_loss         | 1.95e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.598    |
| fps                | 447      |
| nupdates           | 67700    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1354000  |
| value_loss         | 1.02e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.452    |
| fps                | 447      |
| nupdates           | 67800    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1356000  |
| value_loss         | 1.75e-05 |
---------------------------------
---------------------------------
| explained_variance | -3.22    |
| fps                | 447      |
| nupdates           | 67900    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1358000  |
| value_loss         | 0.000242 |
---------------------------------
Eval num_timesteps=1360000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.636    |
| fps                | 447      |
| nupdates           | 68000    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1360000  |
| value_loss         | 1.27e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.615   |
| fps                | 447      |
| nupdates           | 68100    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1362000  |
| value_loss         | 3.61e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.448    |
| fps                | 447      |
| nupdates           | 68200    |
| policy_entropy     | 2.52     |
| total_timesteps    | 1364000  |
| value_loss         | 1.02e-05 |
---------------------------------
---------------------------------
| explained_variance | -3.42    |
| fps                | 447      |
| nupdates           | 68300    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1366000  |
| value_loss         | 0.000106 |
---------------------------------
---------------------------------
| explained_variance | -0.106   |
| fps                | 447      |
| nupdates           | 68400    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1368000  |
| value_loss         | 6.1e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.684    |
| fps                | 447      |
| nupdates           | 68500    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1370000  |
| value_loss         | 5.1e-06  |
---------------------------------
---------------------------------
| explained_variance | -1.86    |
| fps                | 447      |
| nupdates           | 68600    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1372000  |
| value_loss         | 0.000113 |
---------------------------------
---------------------------------
| explained_variance | -1.21    |
| fps                | 447      |
| nupdates           | 68700    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1374000  |
| value_loss         | 1.54e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.385    |
| fps                | 447      |
| nupdates           | 68800    |
| policy_entropy     | 2.48     |
| total_timesteps    | 1376000  |
| value_loss         | 1.28e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.456    |
| fps                | 447      |
| nupdates           | 68900    |
| policy_entropy     | 2.4      |
| total_timesteps    | 1378000  |
| value_loss         | 1.46e-05 |
---------------------------------
Eval num_timesteps=1380000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.51     |
| fps                | 447      |
| nupdates           | 69000    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1380000  |
| value_loss         | 1.62e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.518    |
| fps                | 447      |
| nupdates           | 69100    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1382000  |
| value_loss         | 5.45e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.0607   |
| fps                | 447      |
| nupdates           | 69200    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1384000  |
| value_loss         | 5.35e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.282   |
| fps                | 447      |
| nupdates           | 69300    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1386000  |
| value_loss         | 2.46e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.296    |
| fps                | 447      |
| nupdates           | 69400    |
| policy_entropy     | 2.53     |
| total_timesteps    | 1388000  |
| value_loss         | 4.95e-05 |
---------------------------------
---------------------------------
| explained_variance | -2.49    |
| fps                | 447      |
| nupdates           | 69500    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1390000  |
| value_loss         | 3.97e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.116   |
| fps                | 447      |
| nupdates           | 69600    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1392000  |
| value_loss         | 6.5e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.00117  |
| fps                | 447      |
| nupdates           | 69700    |
| policy_entropy     | 2.52     |
| total_timesteps    | 1394000  |
| value_loss         | 2.59e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.1     |
| fps                | 447      |
| nupdates           | 69800    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1396000  |
| value_loss         | 3.33e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.561    |
| fps                | 447      |
| nupdates           | 69900    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1398000  |
| value_loss         | 6.2e-06  |
---------------------------------
Eval num_timesteps=1400000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -1.43    |
| fps                | 447      |
| nupdates           | 70000    |
| policy_entropy     | 2.48     |
| total_timesteps    | 1400000  |
| value_loss         | 6.04e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.233   |
| fps                | 447      |
| nupdates           | 70100    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1402000  |
| value_loss         | 6.72e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.23    |
| fps                | 447      |
| nupdates           | 70200    |
| policy_entropy     | 2.39     |
| total_timesteps    | 1404000  |
| value_loss         | 4.61e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.537    |
| fps                | 447      |
| nupdates           | 70300    |
| policy_entropy     | 2.45     |
| total_timesteps    | 1406000  |
| value_loss         | 1.05e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.391    |
| fps                | 447      |
| nupdates           | 70400    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1408000  |
| value_loss         | 2.71e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.623    |
| fps                | 447      |
| nupdates           | 70500    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1410000  |
| value_loss         | 8.57e-06 |
---------------------------------
---------------------------------
| explained_variance | -0.168   |
| fps                | 447      |
| nupdates           | 70600    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1412000  |
| value_loss         | 2.63e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.154    |
| fps                | 447      |
| nupdates           | 70700    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1414000  |
| value_loss         | 6.18e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.774    |
| fps                | 447      |
| nupdates           | 70800    |
| policy_entropy     | 2.41     |
| total_timesteps    | 1416000  |
| value_loss         | 5.08e-06 |
---------------------------------
---------------------------------
| explained_variance | -0.851   |
| fps                | 447      |
| nupdates           | 70900    |
| policy_entropy     | 2.52     |
| total_timesteps    | 1418000  |
| value_loss         | 5.99e-05 |
---------------------------------
Eval num_timesteps=1420000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.686    |
| fps                | 447      |
| nupdates           | 71000    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1420000  |
| value_loss         | 6.71e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.246    |
| fps                | 447      |
| nupdates           | 71100    |
| policy_entropy     | 2.48     |
| total_timesteps    | 1422000  |
| value_loss         | 9.77e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.362    |
| fps                | 447      |
| nupdates           | 71200    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1424000  |
| value_loss         | 5.01e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.656    |
| fps                | 447      |
| nupdates           | 71300    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1426000  |
| value_loss         | 7.69e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.169    |
| fps                | 447      |
| nupdates           | 71400    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1428000  |
| value_loss         | 2.3e-05  |
---------------------------------
---------------------------------
| explained_variance | -2.87    |
| fps                | 447      |
| nupdates           | 71500    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1430000  |
| value_loss         | 8.47e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.106    |
| fps                | 447      |
| nupdates           | 71600    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1432000  |
| value_loss         | 2.35e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.59    |
| fps                | 447      |
| nupdates           | 71700    |
| policy_entropy     | 2.52     |
| total_timesteps    | 1434000  |
| value_loss         | 6.61e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.05    |
| fps                | 447      |
| nupdates           | 71800    |
| policy_entropy     | 2.41     |
| total_timesteps    | 1436000  |
| value_loss         | 4.87e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.387   |
| fps                | 447      |
| nupdates           | 71900    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1438000  |
| value_loss         | 3.82e-05 |
---------------------------------
Eval num_timesteps=1440000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.702    |
| fps                | 447      |
| nupdates           | 72000    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1440000  |
| value_loss         | 9.37e-06 |
---------------------------------
---------------------------------
| explained_variance | -0.455   |
| fps                | 447      |
| nupdates           | 72100    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1442000  |
| value_loss         | 5.67e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.126    |
| fps                | 447      |
| nupdates           | 72200    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1444000  |
| value_loss         | 1.61e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.409    |
| fps                | 447      |
| nupdates           | 72300    |
| policy_entropy     | 2.52     |
| total_timesteps    | 1446000  |
| value_loss         | 7.07e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.206    |
| fps                | 447      |
| nupdates           | 72400    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1448000  |
| value_loss         | 5.2e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.423    |
| fps                | 447      |
| nupdates           | 72500    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1450000  |
| value_loss         | 2.77e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.956   |
| fps                | 447      |
| nupdates           | 72600    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1452000  |
| value_loss         | 6.29e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.0102  |
| fps                | 447      |
| nupdates           | 72700    |
| policy_entropy     | 2.53     |
| total_timesteps    | 1454000  |
| value_loss         | 1.68e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.385   |
| fps                | 447      |
| nupdates           | 72800    |
| policy_entropy     | 2.36     |
| total_timesteps    | 1456000  |
| value_loss         | 1.67e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.364    |
| fps                | 447      |
| nupdates           | 72900    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1458000  |
| value_loss         | 1.53e-05 |
---------------------------------
Eval num_timesteps=1460000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.533    |
| fps                | 447      |
| nupdates           | 73000    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1460000  |
| value_loss         | 1.41e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.669   |
| fps                | 447      |
| nupdates           | 73100    |
| policy_entropy     | 2.48     |
| total_timesteps    | 1462000  |
| value_loss         | 6.79e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.23     |
| fps                | 447      |
| nupdates           | 73200    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1464000  |
| value_loss         | 4.47e-05 |
---------------------------------
---------------------------------
| explained_variance | -2.04    |
| fps                | 447      |
| nupdates           | 73300    |
| policy_entropy     | 2.39     |
| total_timesteps    | 1466000  |
| value_loss         | 4.29e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.443   |
| fps                | 447      |
| nupdates           | 73400    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1468000  |
| value_loss         | 1.59e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.36     |
| fps                | 447      |
| nupdates           | 73500    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1470000  |
| value_loss         | 1.33e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.206    |
| fps                | 447      |
| nupdates           | 73600    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1472000  |
| value_loss         | 1.28e-05 |
---------------------------------
---------------------------------
| explained_variance | -5.29    |
| fps                | 447      |
| nupdates           | 73700    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1474000  |
| value_loss         | 0.000215 |
---------------------------------
---------------------------------
| explained_variance | -1.32    |
| fps                | 447      |
| nupdates           | 73800    |
| policy_entropy     | 2.36     |
| total_timesteps    | 1476000  |
| value_loss         | 2e-05    |
---------------------------------
---------------------------------
| explained_variance | 0.132    |
| fps                | 447      |
| nupdates           | 73900    |
| policy_entropy     | 2.47     |
| total_timesteps    | 1478000  |
| value_loss         | 1.99e-05 |
---------------------------------
Eval num_timesteps=1480000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.24     |
| fps                | 447      |
| nupdates           | 74000    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1480000  |
| value_loss         | 3.94e-05 |
---------------------------------
---------------------------------
| explained_variance | -2.12    |
| fps                | 447      |
| nupdates           | 74100    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1482000  |
| value_loss         | 6.96e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.0023   |
| fps                | 447      |
| nupdates           | 74200    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1484000  |
| value_loss         | 3.94e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.798    |
| fps                | 447      |
| nupdates           | 74300    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1486000  |
| value_loss         | 7.99e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.557    |
| fps                | 447      |
| nupdates           | 74400    |
| policy_entropy     | 2.52     |
| total_timesteps    | 1488000  |
| value_loss         | 1.09e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.178   |
| fps                | 447      |
| nupdates           | 74500    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1490000  |
| value_loss         | 1.44e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.19    |
| fps                | 447      |
| nupdates           | 74600    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1492000  |
| value_loss         | 6e-05    |
---------------------------------
---------------------------------
| explained_variance | -0.29    |
| fps                | 447      |
| nupdates           | 74700    |
| policy_entropy     | 2.5      |
| total_timesteps    | 1494000  |
| value_loss         | 4.7e-05  |
---------------------------------
---------------------------------
| explained_variance | -0.454   |
| fps                | 447      |
| nupdates           | 74800    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1496000  |
| value_loss         | 3.72e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.628    |
| fps                | 447      |
| nupdates           | 74900    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1498000  |
| value_loss         | 6.71e-06 |
---------------------------------
Eval num_timesteps=1500000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.352    |
| fps                | 447      |
| nupdates           | 75000    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1500000  |
| value_loss         | 2.1e-05  |
---------------------------------
---------------------------------
| explained_variance | -2.25    |
| fps                | 447      |
| nupdates           | 75100    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1502000  |
| value_loss         | 4.13e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.0772  |
| fps                | 447      |
| nupdates           | 75200    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1504000  |
| value_loss         | 1.16e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.581    |
| fps                | 447      |
| nupdates           | 75300    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1506000  |
| value_loss         | 1.45e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.717    |
| fps                | 447      |
| nupdates           | 75400    |
| policy_entropy     | 2.36     |
| total_timesteps    | 1508000  |
| value_loss         | 5.1e-06  |
---------------------------------
---------------------------------
| explained_variance | 0.305    |
| fps                | 447      |
| nupdates           | 75500    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1510000  |
| value_loss         | 2.18e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.705   |
| fps                | 447      |
| nupdates           | 75600    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1512000  |
| value_loss         | 2.87e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.303    |
| fps                | 447      |
| nupdates           | 75700    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1514000  |
| value_loss         | 3.72e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.572    |
| fps                | 447      |
| nupdates           | 75800    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1516000  |
| value_loss         | 1.58e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.512    |
| fps                | 447      |
| nupdates           | 75900    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1518000  |
| value_loss         | 4.09e-06 |
---------------------------------
Eval num_timesteps=1520000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -0.536   |
| fps                | 447      |
| nupdates           | 76000    |
| policy_entropy     | 2.5      |
| total_timesteps    | 1520000  |
| value_loss         | 0.000133 |
---------------------------------
---------------------------------
| explained_variance | 0.194    |
| fps                | 447      |
| nupdates           | 76100    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1522000  |
| value_loss         | 1.44e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.598    |
| fps                | 447      |
| nupdates           | 76200    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1524000  |
| value_loss         | 1.04e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.161    |
| fps                | 447      |
| nupdates           | 76300    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1526000  |
| value_loss         | 1.51e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.63     |
| fps                | 447      |
| nupdates           | 76400    |
| policy_entropy     | 2.52     |
| total_timesteps    | 1528000  |
| value_loss         | 8.82e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.77     |
| fps                | 447      |
| nupdates           | 76500    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1530000  |
| value_loss         | 3.35e-06 |
---------------------------------
---------------------------------
| explained_variance | -0.964   |
| fps                | 447      |
| nupdates           | 76600    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1532000  |
| value_loss         | 8.02e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.378    |
| fps                | 447      |
| nupdates           | 76700    |
| policy_entropy     | 2.48     |
| total_timesteps    | 1534000  |
| value_loss         | 1.22e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.363    |
| fps                | 447      |
| nupdates           | 76800    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1536000  |
| value_loss         | 4.64e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.122   |
| fps                | 447      |
| nupdates           | 76900    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1538000  |
| value_loss         | 2.46e-05 |
---------------------------------
Eval num_timesteps=1540000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.398    |
| fps                | 447      |
| nupdates           | 77000    |
| policy_entropy     | 2.45     |
| total_timesteps    | 1540000  |
| value_loss         | 1.33e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.565    |
| fps                | 447      |
| nupdates           | 77100    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1542000  |
| value_loss         | 8.01e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.138    |
| fps                | 447      |
| nupdates           | 77200    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1544000  |
| value_loss         | 6.86e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.394    |
| fps                | 447      |
| nupdates           | 77300    |
| policy_entropy     | 2.45     |
| total_timesteps    | 1546000  |
| value_loss         | 2.65e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.431    |
| fps                | 447      |
| nupdates           | 77400    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1548000  |
| value_loss         | 9.81e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.35     |
| fps                | 447      |
| nupdates           | 77500    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1550000  |
| value_loss         | 8.98e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.744    |
| fps                | 447      |
| nupdates           | 77600    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1552000  |
| value_loss         | 1.98e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.663    |
| fps                | 447      |
| nupdates           | 77700    |
| policy_entropy     | 2.45     |
| total_timesteps    | 1554000  |
| value_loss         | 3.24e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.649    |
| fps                | 447      |
| nupdates           | 77800    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1556000  |
| value_loss         | 6.15e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.638    |
| fps                | 447      |
| nupdates           | 77900    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1558000  |
| value_loss         | 8.15e-06 |
---------------------------------
Eval num_timesteps=1560000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.0204   |
| fps                | 447      |
| nupdates           | 78000    |
| policy_entropy     | 2.39     |
| total_timesteps    | 1560000  |
| value_loss         | 9.22e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.229    |
| fps                | 447      |
| nupdates           | 78100    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1562000  |
| value_loss         | 1.68e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.354   |
| fps                | 447      |
| nupdates           | 78200    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1564000  |
| value_loss         | 3.57e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.952   |
| fps                | 447      |
| nupdates           | 78300    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1566000  |
| value_loss         | 0.000135 |
---------------------------------
---------------------------------
| explained_variance | 0.61     |
| fps                | 447      |
| nupdates           | 78400    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1568000  |
| value_loss         | 5.47e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.645    |
| fps                | 447      |
| nupdates           | 78500    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1570000  |
| value_loss         | 1.26e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.296    |
| fps                | 447      |
| nupdates           | 78600    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1572000  |
| value_loss         | 9.61e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.681    |
| fps                | 447      |
| nupdates           | 78700    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1574000  |
| value_loss         | 7.03e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.773    |
| fps                | 447      |
| nupdates           | 78800    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1576000  |
| value_loss         | 4.21e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.488    |
| fps                | 447      |
| nupdates           | 78900    |
| policy_entropy     | 2.39     |
| total_timesteps    | 1578000  |
| value_loss         | 8.23e-06 |
---------------------------------
Eval num_timesteps=1580000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -0.383   |
| fps                | 447      |
| nupdates           | 79000    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1580000  |
| value_loss         | 5.73e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.77     |
| fps                | 447      |
| nupdates           | 79100    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1582000  |
| value_loss         | 3.27e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.809    |
| fps                | 447      |
| nupdates           | 79200    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1584000  |
| value_loss         | 2.19e-06 |
---------------------------------
---------------------------------
| explained_variance | -0.129   |
| fps                | 447      |
| nupdates           | 79300    |
| policy_entropy     | 2.45     |
| total_timesteps    | 1586000  |
| value_loss         | 3.72e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.444    |
| fps                | 447      |
| nupdates           | 79400    |
| policy_entropy     | 2.4      |
| total_timesteps    | 1588000  |
| value_loss         | 1.12e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.586    |
| fps                | 447      |
| nupdates           | 79500    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1590000  |
| value_loss         | 2.48e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.656    |
| fps                | 447      |
| nupdates           | 79600    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1592000  |
| value_loss         | 1.08e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.81    |
| fps                | 447      |
| nupdates           | 79700    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1594000  |
| value_loss         | 3.99e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.62     |
| fps                | 447      |
| nupdates           | 79800    |
| policy_entropy     | 2.4      |
| total_timesteps    | 1596000  |
| value_loss         | 1.07e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.0317   |
| fps                | 447      |
| nupdates           | 79900    |
| policy_entropy     | 2.39     |
| total_timesteps    | 1598000  |
| value_loss         | 1.33e-05 |
---------------------------------
Eval num_timesteps=1600000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.527    |
| fps                | 447      |
| nupdates           | 80000    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1600000  |
| value_loss         | 1.64e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.0867  |
| fps                | 447      |
| nupdates           | 80100    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1602000  |
| value_loss         | 1.73e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.608    |
| fps                | 447      |
| nupdates           | 80200    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1604000  |
| value_loss         | 1.08e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.715    |
| fps                | 447      |
| nupdates           | 80300    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1606000  |
| value_loss         | 3.23e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.558    |
| fps                | 447      |
| nupdates           | 80400    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1608000  |
| value_loss         | 1.96e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.407    |
| fps                | 447      |
| nupdates           | 80500    |
| policy_entropy     | 2.4      |
| total_timesteps    | 1610000  |
| value_loss         | 4.35e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.365    |
| fps                | 447      |
| nupdates           | 80600    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1612000  |
| value_loss         | 1.12e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.492    |
| fps                | 447      |
| nupdates           | 80700    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1614000  |
| value_loss         | 1.27e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.37    |
| fps                | 447      |
| nupdates           | 80800    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1616000  |
| value_loss         | 2.03e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.534    |
| fps                | 447      |
| nupdates           | 80900    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1618000  |
| value_loss         | 1.42e-05 |
---------------------------------
Eval num_timesteps=1620000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.648    |
| fps                | 447      |
| nupdates           | 81000    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1620000  |
| value_loss         | 1.12e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.283    |
| fps                | 447      |
| nupdates           | 81100    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1622000  |
| value_loss         | 1.76e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.599    |
| fps                | 447      |
| nupdates           | 81200    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1624000  |
| value_loss         | 1.38e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.707    |
| fps                | 447      |
| nupdates           | 81300    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1626000  |
| value_loss         | 1.95e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.7      |
| fps                | 447      |
| nupdates           | 81400    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1628000  |
| value_loss         | 4.8e-06  |
---------------------------------
---------------------------------
| explained_variance | 0.233    |
| fps                | 447      |
| nupdates           | 81500    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1630000  |
| value_loss         | 2.03e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.214    |
| fps                | 447      |
| nupdates           | 81600    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1632000  |
| value_loss         | 2.45e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.614    |
| fps                | 447      |
| nupdates           | 81700    |
| policy_entropy     | 2.48     |
| total_timesteps    | 1634000  |
| value_loss         | 8.16e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.456    |
| fps                | 447      |
| nupdates           | 81800    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1636000  |
| value_loss         | 1.81e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.4      |
| fps                | 447      |
| nupdates           | 81900    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1638000  |
| value_loss         | 1.64e-05 |
---------------------------------
Eval num_timesteps=1640000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.661    |
| fps                | 447      |
| nupdates           | 82000    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1640000  |
| value_loss         | 6.62e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.453    |
| fps                | 447      |
| nupdates           | 82100    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1642000  |
| value_loss         | 1.82e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.0487   |
| fps                | 447      |
| nupdates           | 82200    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1644000  |
| value_loss         | 1.18e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.0362   |
| fps                | 447      |
| nupdates           | 82300    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1646000  |
| value_loss         | 4.5e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.341    |
| fps                | 447      |
| nupdates           | 82400    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1648000  |
| value_loss         | 9.23e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.686    |
| fps                | 447      |
| nupdates           | 82500    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1650000  |
| value_loss         | 5.91e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.504    |
| fps                | 447      |
| nupdates           | 82600    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1652000  |
| value_loss         | 1.2e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.132    |
| fps                | 447      |
| nupdates           | 82700    |
| policy_entropy     | 2.44     |
| total_timesteps    | 1654000  |
| value_loss         | 2.32e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.516    |
| fps                | 447      |
| nupdates           | 82800    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1656000  |
| value_loss         | 1.12e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.629    |
| fps                | 447      |
| nupdates           | 82900    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1658000  |
| value_loss         | 8.52e-06 |
---------------------------------
Eval num_timesteps=1660000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.0284   |
| fps                | 447      |
| nupdates           | 83000    |
| policy_entropy     | 2.52     |
| total_timesteps    | 1660000  |
| value_loss         | 3.55e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.986    |
| fps                | 447      |
| nupdates           | 83100    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1662000  |
| value_loss         | 9.62e-07 |
---------------------------------
---------------------------------
| explained_variance | 0.536    |
| fps                | 447      |
| nupdates           | 83200    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1664000  |
| value_loss         | 1.1e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.654    |
| fps                | 447      |
| nupdates           | 83300    |
| policy_entropy     | 2.4      |
| total_timesteps    | 1666000  |
| value_loss         | 1.08e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.382   |
| fps                | 447      |
| nupdates           | 83400    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1668000  |
| value_loss         | 1.75e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.709    |
| fps                | 447      |
| nupdates           | 83500    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1670000  |
| value_loss         | 3.79e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.427    |
| fps                | 447      |
| nupdates           | 83600    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1672000  |
| value_loss         | 3.07e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.473    |
| fps                | 447      |
| nupdates           | 83700    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1674000  |
| value_loss         | 7.95e-06 |
---------------------------------
---------------------------------
| explained_variance | -2.56    |
| fps                | 447      |
| nupdates           | 83800    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1676000  |
| value_loss         | 7.28e-05 |
---------------------------------
---------------------------------
| explained_variance | -10.1    |
| fps                | 447      |
| nupdates           | 83900    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1678000  |
| value_loss         | 0.000211 |
---------------------------------
Eval num_timesteps=1680000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -0.876   |
| fps                | 447      |
| nupdates           | 84000    |
| policy_entropy     | 2.39     |
| total_timesteps    | 1680000  |
| value_loss         | 3.05e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.19     |
| fps                | 447      |
| nupdates           | 84100    |
| policy_entropy     | 2.39     |
| total_timesteps    | 1682000  |
| value_loss         | 1.89e-05 |
---------------------------------
---------------------------------
| explained_variance | -3.87    |
| fps                | 447      |
| nupdates           | 84200    |
| policy_entropy     | 2.35     |
| total_timesteps    | 1684000  |
| value_loss         | 4.7e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.302    |
| fps                | 447      |
| nupdates           | 84300    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1686000  |
| value_loss         | 2.1e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.354    |
| fps                | 447      |
| nupdates           | 84400    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1688000  |
| value_loss         | 1.21e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.096   |
| fps                | 447      |
| nupdates           | 84500    |
| policy_entropy     | 2.55     |
| total_timesteps    | 1690000  |
| value_loss         | 7.45e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.464    |
| fps                | 447      |
| nupdates           | 84600    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1692000  |
| value_loss         | 2.55e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.502    |
| fps                | 447      |
| nupdates           | 84700    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1694000  |
| value_loss         | 6.42e-06 |
---------------------------------
---------------------------------
| explained_variance | -0.721   |
| fps                | 447      |
| nupdates           | 84800    |
| policy_entropy     | 2.39     |
| total_timesteps    | 1696000  |
| value_loss         | 9.83e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.52     |
| fps                | 447      |
| nupdates           | 84900    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1698000  |
| value_loss         | 2.4e-05  |
---------------------------------
Eval num_timesteps=1700000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.551    |
| fps                | 447      |
| nupdates           | 85000    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1700000  |
| value_loss         | 2.13e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.614    |
| fps                | 447      |
| nupdates           | 85100    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1702000  |
| value_loss         | 4.49e-06 |
---------------------------------
---------------------------------
| explained_variance | -0.0759  |
| fps                | 447      |
| nupdates           | 85200    |
| policy_entropy     | 2.39     |
| total_timesteps    | 1704000  |
| value_loss         | 1.39e-05 |
---------------------------------
---------------------------------
| explained_variance | -2.08    |
| fps                | 447      |
| nupdates           | 85300    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1706000  |
| value_loss         | 0.00146  |
---------------------------------
---------------------------------
| explained_variance | 0.4      |
| fps                | 447      |
| nupdates           | 85400    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1708000  |
| value_loss         | 3.53e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.518    |
| fps                | 447      |
| nupdates           | 85500    |
| policy_entropy     | 2.48     |
| total_timesteps    | 1710000  |
| value_loss         | 2.61e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.15    |
| fps                | 447      |
| nupdates           | 85600    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1712000  |
| value_loss         | 0.000102 |
---------------------------------
---------------------------------
| explained_variance | 0.833    |
| fps                | 447      |
| nupdates           | 85700    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1714000  |
| value_loss         | 7e-06    |
---------------------------------
---------------------------------
| explained_variance | 0.524    |
| fps                | 447      |
| nupdates           | 85800    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1716000  |
| value_loss         | 6.3e-06  |
---------------------------------
---------------------------------
| explained_variance | 0.651    |
| fps                | 447      |
| nupdates           | 85900    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1718000  |
| value_loss         | 6.96e-06 |
---------------------------------
Eval num_timesteps=1720000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -1.39    |
| fps                | 447      |
| nupdates           | 86000    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1720000  |
| value_loss         | 4.98e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.405    |
| fps                | 447      |
| nupdates           | 86100    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1722000  |
| value_loss         | 1.13e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.382    |
| fps                | 447      |
| nupdates           | 86200    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1724000  |
| value_loss         | 1.8e-05  |
---------------------------------
---------------------------------
| explained_variance | -0.774   |
| fps                | 447      |
| nupdates           | 86300    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1726000  |
| value_loss         | 7.9e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.377    |
| fps                | 447      |
| nupdates           | 86400    |
| policy_entropy     | 2.47     |
| total_timesteps    | 1728000  |
| value_loss         | 1.85e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.223    |
| fps                | 447      |
| nupdates           | 86500    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1730000  |
| value_loss         | 2.71e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.321    |
| fps                | 447      |
| nupdates           | 86600    |
| policy_entropy     | 2.5      |
| total_timesteps    | 1732000  |
| value_loss         | 2.45e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.0643  |
| fps                | 447      |
| nupdates           | 86700    |
| policy_entropy     | 2.45     |
| total_timesteps    | 1734000  |
| value_loss         | 9.18e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.529    |
| fps                | 447      |
| nupdates           | 86800    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1736000  |
| value_loss         | 1.31e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.549    |
| fps                | 447      |
| nupdates           | 86900    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1738000  |
| value_loss         | 2.17e-05 |
---------------------------------
Eval num_timesteps=1740000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -0.343   |
| fps                | 447      |
| nupdates           | 87000    |
| policy_entropy     | 2.52     |
| total_timesteps    | 1740000  |
| value_loss         | 0.000124 |
---------------------------------
---------------------------------
| explained_variance | 0.558    |
| fps                | 447      |
| nupdates           | 87100    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1742000  |
| value_loss         | 9.75e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.428    |
| fps                | 447      |
| nupdates           | 87200    |
| policy_entropy     | 2.4      |
| total_timesteps    | 1744000  |
| value_loss         | 6.44e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.188    |
| fps                | 447      |
| nupdates           | 87300    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1746000  |
| value_loss         | 1.68e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.349   |
| fps                | 447      |
| nupdates           | 87400    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1748000  |
| value_loss         | 3.27e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.488    |
| fps                | 447      |
| nupdates           | 87500    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1750000  |
| value_loss         | 1.13e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.562    |
| fps                | 447      |
| nupdates           | 87600    |
| policy_entropy     | 2.5      |
| total_timesteps    | 1752000  |
| value_loss         | 8.06e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.533    |
| fps                | 447      |
| nupdates           | 87700    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1754000  |
| value_loss         | 1.56e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.922   |
| fps                | 447      |
| nupdates           | 87800    |
| policy_entropy     | 2.4      |
| total_timesteps    | 1756000  |
| value_loss         | 3.39e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.491    |
| fps                | 447      |
| nupdates           | 87900    |
| policy_entropy     | 2.47     |
| total_timesteps    | 1758000  |
| value_loss         | 1.61e-05 |
---------------------------------
Eval num_timesteps=1760000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.445    |
| fps                | 447      |
| nupdates           | 88000    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1760000  |
| value_loss         | 1.19e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.185    |
| fps                | 447      |
| nupdates           | 88100    |
| policy_entropy     | 2.48     |
| total_timesteps    | 1762000  |
| value_loss         | 3.57e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.128   |
| fps                | 447      |
| nupdates           | 88200    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1764000  |
| value_loss         | 2.43e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.662    |
| fps                | 447      |
| nupdates           | 88300    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1766000  |
| value_loss         | 5.82e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.531    |
| fps                | 447      |
| nupdates           | 88400    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1768000  |
| value_loss         | 1.13e-05 |
---------------------------------
---------------------------------
| explained_variance | -5.8     |
| fps                | 447      |
| nupdates           | 88500    |
| policy_entropy     | 2.39     |
| total_timesteps    | 1770000  |
| value_loss         | 8.27e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.327    |
| fps                | 447      |
| nupdates           | 88600    |
| policy_entropy     | 2.52     |
| total_timesteps    | 1772000  |
| value_loss         | 3.04e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.519    |
| fps                | 447      |
| nupdates           | 88700    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1774000  |
| value_loss         | 2.31e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.162    |
| fps                | 447      |
| nupdates           | 88800    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1776000  |
| value_loss         | 1.41e-05 |
---------------------------------
---------------------------------
| explained_variance | -2.07    |
| fps                | 447      |
| nupdates           | 88900    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1778000  |
| value_loss         | 0.00012  |
---------------------------------
Eval num_timesteps=1780000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.197    |
| fps                | 447      |
| nupdates           | 89000    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1780000  |
| value_loss         | 1.44e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.209   |
| fps                | 447      |
| nupdates           | 89100    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1782000  |
| value_loss         | 6.16e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.399    |
| fps                | 447      |
| nupdates           | 89200    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1784000  |
| value_loss         | 3.04e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.19     |
| fps                | 447      |
| nupdates           | 89300    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1786000  |
| value_loss         | 1.8e-05  |
---------------------------------
---------------------------------
| explained_variance | -1.31    |
| fps                | 447      |
| nupdates           | 89400    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1788000  |
| value_loss         | 0.000129 |
---------------------------------
---------------------------------
| explained_variance | 0.666    |
| fps                | 447      |
| nupdates           | 89500    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1790000  |
| value_loss         | 5.18e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.437    |
| fps                | 447      |
| nupdates           | 89600    |
| policy_entropy     | 2.53     |
| total_timesteps    | 1792000  |
| value_loss         | 7.2e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.469    |
| fps                | 447      |
| nupdates           | 89700    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1794000  |
| value_loss         | 9e-06    |
---------------------------------
---------------------------------
| explained_variance | 0.669    |
| fps                | 447      |
| nupdates           | 89800    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1796000  |
| value_loss         | 5.24e-06 |
---------------------------------
---------------------------------
| explained_variance | -1.37    |
| fps                | 447      |
| nupdates           | 89900    |
| policy_entropy     | 2.39     |
| total_timesteps    | 1798000  |
| value_loss         | 5.62e-05 |
---------------------------------
Eval num_timesteps=1800000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.228    |
| fps                | 447      |
| nupdates           | 90000    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1800000  |
| value_loss         | 5.6e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.486    |
| fps                | 447      |
| nupdates           | 90100    |
| policy_entropy     | 2.48     |
| total_timesteps    | 1802000  |
| value_loss         | 1.98e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.92    |
| fps                | 447      |
| nupdates           | 90200    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1804000  |
| value_loss         | 7.04e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.472    |
| fps                | 447      |
| nupdates           | 90300    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1806000  |
| value_loss         | 8.46e-06 |
---------------------------------
---------------------------------
| explained_variance | -0.205   |
| fps                | 447      |
| nupdates           | 90400    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1808000  |
| value_loss         | 4.24e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.58     |
| fps                | 447      |
| nupdates           | 90500    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1810000  |
| value_loss         | 1.71e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.452    |
| fps                | 447      |
| nupdates           | 90600    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1812000  |
| value_loss         | 1.7e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.049    |
| fps                | 447      |
| nupdates           | 90700    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1814000  |
| value_loss         | 4.26e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.54    |
| fps                | 447      |
| nupdates           | 90800    |
| policy_entropy     | 2.45     |
| total_timesteps    | 1816000  |
| value_loss         | 2.85e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.371    |
| fps                | 447      |
| nupdates           | 90900    |
| policy_entropy     | 2.52     |
| total_timesteps    | 1818000  |
| value_loss         | 2.7e-05  |
---------------------------------
Eval num_timesteps=1820000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.51     |
| fps                | 447      |
| nupdates           | 91000    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1820000  |
| value_loss         | 1.02e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.923   |
| fps                | 447      |
| nupdates           | 91100    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1822000  |
| value_loss         | 2e-05    |
---------------------------------
---------------------------------
| explained_variance | 0.34     |
| fps                | 447      |
| nupdates           | 91200    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1824000  |
| value_loss         | 1.26e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.497    |
| fps                | 447      |
| nupdates           | 91300    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1826000  |
| value_loss         | 5.65e-06 |
---------------------------------
---------------------------------
| explained_variance | -1.33    |
| fps                | 447      |
| nupdates           | 91400    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1828000  |
| value_loss         | 3.32e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.246    |
| fps                | 447      |
| nupdates           | 91500    |
| policy_entropy     | 2.53     |
| total_timesteps    | 1830000  |
| value_loss         | 1.28e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.273    |
| fps                | 447      |
| nupdates           | 91600    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1832000  |
| value_loss         | 3.95e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.132   |
| fps                | 447      |
| nupdates           | 91700    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1834000  |
| value_loss         | 4.01e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.358    |
| fps                | 447      |
| nupdates           | 91800    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1836000  |
| value_loss         | 1.55e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.405    |
| fps                | 447      |
| nupdates           | 91900    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1838000  |
| value_loss         | 1.06e-05 |
---------------------------------
Eval num_timesteps=1840000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.341    |
| fps                | 447      |
| nupdates           | 92000    |
| policy_entropy     | 2.5      |
| total_timesteps    | 1840000  |
| value_loss         | 1.98e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.593    |
| fps                | 447      |
| nupdates           | 92100    |
| policy_entropy     | 2.4      |
| total_timesteps    | 1842000  |
| value_loss         | 3.45e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.654    |
| fps                | 447      |
| nupdates           | 92200    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1844000  |
| value_loss         | 4.39e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.47     |
| fps                | 447      |
| nupdates           | 92300    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1846000  |
| value_loss         | 1.5e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.431    |
| fps                | 447      |
| nupdates           | 92400    |
| policy_entropy     | 2.48     |
| total_timesteps    | 1848000  |
| value_loss         | 3.21e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.783    |
| fps                | 447      |
| nupdates           | 92500    |
| policy_entropy     | 2.39     |
| total_timesteps    | 1850000  |
| value_loss         | 2.56e-06 |
---------------------------------
---------------------------------
| explained_variance | -2.77    |
| fps                | 447      |
| nupdates           | 92600    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1852000  |
| value_loss         | 6.4e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.136    |
| fps                | 447      |
| nupdates           | 92700    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1854000  |
| value_loss         | 2.85e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.243    |
| fps                | 447      |
| nupdates           | 92800    |
| policy_entropy     | 2.48     |
| total_timesteps    | 1856000  |
| value_loss         | 3.64e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.0723   |
| fps                | 447      |
| nupdates           | 92900    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1858000  |
| value_loss         | 8.24e-06 |
---------------------------------
Eval num_timesteps=1860000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -0.278   |
| fps                | 447      |
| nupdates           | 93000    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1860000  |
| value_loss         | 4.78e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.477    |
| fps                | 447      |
| nupdates           | 93100    |
| policy_entropy     | 2.52     |
| total_timesteps    | 1862000  |
| value_loss         | 2.94e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.574    |
| fps                | 447      |
| nupdates           | 93200    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1864000  |
| value_loss         | 9.54e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.393    |
| fps                | 447      |
| nupdates           | 93300    |
| policy_entropy     | 2.53     |
| total_timesteps    | 1866000  |
| value_loss         | 2.07e-05 |
---------------------------------
---------------------------------
| explained_variance | -2.42    |
| fps                | 447      |
| nupdates           | 93400    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1868000  |
| value_loss         | 0.000133 |
---------------------------------
---------------------------------
| explained_variance | 0.475    |
| fps                | 447      |
| nupdates           | 93500    |
| policy_entropy     | 2.48     |
| total_timesteps    | 1870000  |
| value_loss         | 1.62e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.0116  |
| fps                | 447      |
| nupdates           | 93600    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1872000  |
| value_loss         | 2.04e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.318   |
| fps                | 447      |
| nupdates           | 93700    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1874000  |
| value_loss         | 6.63e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.81     |
| fps                | 447      |
| nupdates           | 93800    |
| policy_entropy     | 2.4      |
| total_timesteps    | 1876000  |
| value_loss         | 8.99e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.336    |
| fps                | 447      |
| nupdates           | 93900    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1878000  |
| value_loss         | 1.16e-05 |
---------------------------------
Eval num_timesteps=1880000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.691    |
| fps                | 447      |
| nupdates           | 94000    |
| policy_entropy     | 2.39     |
| total_timesteps    | 1880000  |
| value_loss         | 6.35e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.629    |
| fps                | 447      |
| nupdates           | 94100    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1882000  |
| value_loss         | 1.03e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.0471   |
| fps                | 447      |
| nupdates           | 94200    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1884000  |
| value_loss         | 1.54e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.459    |
| fps                | 447      |
| nupdates           | 94300    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1886000  |
| value_loss         | 1.7e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.649    |
| fps                | 447      |
| nupdates           | 94400    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1888000  |
| value_loss         | 5.76e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.342    |
| fps                | 447      |
| nupdates           | 94500    |
| policy_entropy     | 2.5      |
| total_timesteps    | 1890000  |
| value_loss         | 3.01e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.219    |
| fps                | 447      |
| nupdates           | 94600    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1892000  |
| value_loss         | 2.92e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.556    |
| fps                | 447      |
| nupdates           | 94700    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1894000  |
| value_loss         | 1.31e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.536    |
| fps                | 447      |
| nupdates           | 94800    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1896000  |
| value_loss         | 3.33e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.559   |
| fps                | 447      |
| nupdates           | 94900    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1898000  |
| value_loss         | 2.4e-05  |
---------------------------------
Eval num_timesteps=1900000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.547    |
| fps                | 447      |
| nupdates           | 95000    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1900000  |
| value_loss         | 1.47e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.66    |
| fps                | 447      |
| nupdates           | 95100    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1902000  |
| value_loss         | 5.33e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.326    |
| fps                | 447      |
| nupdates           | 95200    |
| policy_entropy     | 2.52     |
| total_timesteps    | 1904000  |
| value_loss         | 2.3e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.347    |
| fps                | 447      |
| nupdates           | 95300    |
| policy_entropy     | 2.48     |
| total_timesteps    | 1906000  |
| value_loss         | 2.3e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.647    |
| fps                | 447      |
| nupdates           | 95400    |
| policy_entropy     | 2.44     |
| total_timesteps    | 1908000  |
| value_loss         | 3.5e-06  |
---------------------------------
---------------------------------
| explained_variance | 0.582    |
| fps                | 447      |
| nupdates           | 95500    |
| policy_entropy     | 2.39     |
| total_timesteps    | 1910000  |
| value_loss         | 5e-06    |
---------------------------------
---------------------------------
| explained_variance | 0.706    |
| fps                | 447      |
| nupdates           | 95600    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1912000  |
| value_loss         | 2.08e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.514    |
| fps                | 447      |
| nupdates           | 95700    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1914000  |
| value_loss         | 9.03e-06 |
---------------------------------
---------------------------------
| explained_variance | -0.0316  |
| fps                | 447      |
| nupdates           | 95800    |
| policy_entropy     | 2.53     |
| total_timesteps    | 1916000  |
| value_loss         | 9.21e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.129    |
| fps                | 447      |
| nupdates           | 95900    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1918000  |
| value_loss         | 6.64e-06 |
---------------------------------
Eval num_timesteps=1920000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -0.105   |
| fps                | 447      |
| nupdates           | 96000    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1920000  |
| value_loss         | 4.08e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.355    |
| fps                | 447      |
| nupdates           | 96100    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1922000  |
| value_loss         | 1.07e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.586    |
| fps                | 447      |
| nupdates           | 96200    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1924000  |
| value_loss         | 1.37e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.384    |
| fps                | 447      |
| nupdates           | 96300    |
| policy_entropy     | 2.52     |
| total_timesteps    | 1926000  |
| value_loss         | 8.9e-06  |
---------------------------------
---------------------------------
| explained_variance | 0.611    |
| fps                | 447      |
| nupdates           | 96400    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1928000  |
| value_loss         | 1e-05    |
---------------------------------
---------------------------------
| explained_variance | 0.781    |
| fps                | 447      |
| nupdates           | 96500    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1930000  |
| value_loss         | 3.4e-06  |
---------------------------------
---------------------------------
| explained_variance | 0.35     |
| fps                | 447      |
| nupdates           | 96600    |
| policy_entropy     | 2.56     |
| total_timesteps    | 1932000  |
| value_loss         | 4.02e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.205   |
| fps                | 447      |
| nupdates           | 96700    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1934000  |
| value_loss         | 4.15e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.0519  |
| fps                | 447      |
| nupdates           | 96800    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1936000  |
| value_loss         | 1.77e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.596    |
| fps                | 447      |
| nupdates           | 96900    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1938000  |
| value_loss         | 5.34e-06 |
---------------------------------
Eval num_timesteps=1940000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.65     |
| fps                | 447      |
| nupdates           | 97000    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1940000  |
| value_loss         | 1.84e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.603    |
| fps                | 447      |
| nupdates           | 97100    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1942000  |
| value_loss         | 9.82e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.478    |
| fps                | 447      |
| nupdates           | 97200    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1944000  |
| value_loss         | 8.31e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.666    |
| fps                | 447      |
| nupdates           | 97300    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1946000  |
| value_loss         | 9.51e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.362    |
| fps                | 447      |
| nupdates           | 97400    |
| policy_entropy     | 2.52     |
| total_timesteps    | 1948000  |
| value_loss         | 2.23e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.49     |
| fps                | 447      |
| nupdates           | 97500    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1950000  |
| value_loss         | 1.15e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.652    |
| fps                | 447      |
| nupdates           | 97600    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1952000  |
| value_loss         | 1.04e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.411    |
| fps                | 447      |
| nupdates           | 97700    |
| policy_entropy     | 2.48     |
| total_timesteps    | 1954000  |
| value_loss         | 1.37e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.279    |
| fps                | 447      |
| nupdates           | 97800    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1956000  |
| value_loss         | 9.76e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.509    |
| fps                | 447      |
| nupdates           | 97900    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1958000  |
| value_loss         | 2.54e-05 |
---------------------------------
Eval num_timesteps=1960000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.582    |
| fps                | 447      |
| nupdates           | 98000    |
| policy_entropy     | 2.5      |
| total_timesteps    | 1960000  |
| value_loss         | 9.49e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.685    |
| fps                | 447      |
| nupdates           | 98100    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1962000  |
| value_loss         | 7.21e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.278    |
| fps                | 447      |
| nupdates           | 98200    |
| policy_entropy     | 2.59     |
| total_timesteps    | 1964000  |
| value_loss         | 3.29e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.385    |
| fps                | 447      |
| nupdates           | 98300    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1966000  |
| value_loss         | 9.85e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.264    |
| fps                | 447      |
| nupdates           | 98400    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1968000  |
| value_loss         | 1.37e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.478    |
| fps                | 447      |
| nupdates           | 98500    |
| policy_entropy     | 2.53     |
| total_timesteps    | 1970000  |
| value_loss         | 1.69e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.0272  |
| fps                | 447      |
| nupdates           | 98600    |
| policy_entropy     | 2.58     |
| total_timesteps    | 1972000  |
| value_loss         | 0.000123 |
---------------------------------
---------------------------------
| explained_variance | 0.449    |
| fps                | 447      |
| nupdates           | 98700    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1974000  |
| value_loss         | 5.15e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.594    |
| fps                | 447      |
| nupdates           | 98800    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1976000  |
| value_loss         | 8.96e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.398    |
| fps                | 447      |
| nupdates           | 98900    |
| policy_entropy     | 2.55     |
| total_timesteps    | 1978000  |
| value_loss         | 4.29e-05 |
---------------------------------
Eval num_timesteps=1980000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -2.89    |
| fps                | 447      |
| nupdates           | 99000    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1980000  |
| value_loss         | 0.000114 |
---------------------------------
---------------------------------
| explained_variance | 0.149    |
| fps                | 447      |
| nupdates           | 99100    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1982000  |
| value_loss         | 2.02e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.204    |
| fps                | 447      |
| nupdates           | 99200    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1984000  |
| value_loss         | 2.77e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.693    |
| fps                | 447      |
| nupdates           | 99300    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1986000  |
| value_loss         | 9.01e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.549    |
| fps                | 447      |
| nupdates           | 99400    |
| policy_entropy     | 2.45     |
| total_timesteps    | 1988000  |
| value_loss         | 1.33e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.682    |
| fps                | 447      |
| nupdates           | 99500    |
| policy_entropy     | 2.46     |
| total_timesteps    | 1990000  |
| value_loss         | 7.68e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.332    |
| fps                | 447      |
| nupdates           | 99600    |
| policy_entropy     | 2.42     |
| total_timesteps    | 1992000  |
| value_loss         | 9.55e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.486    |
| fps                | 447      |
| nupdates           | 99700    |
| policy_entropy     | 2.45     |
| total_timesteps    | 1994000  |
| value_loss         | 1.67e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.605    |
| fps                | 447      |
| nupdates           | 99800    |
| policy_entropy     | 2.49     |
| total_timesteps    | 1996000  |
| value_loss         | 1.61e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.387    |
| fps                | 447      |
| nupdates           | 99900    |
| policy_entropy     | 2.43     |
| total_timesteps    | 1998000  |
| value_loss         | 8.94e-06 |
---------------------------------
Eval num_timesteps=2000000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.411    |
| fps                | 447      |
| nupdates           | 100000   |
| policy_entropy     | 2.52     |
| total_timesteps    | 2000000  |
| value_loss         | 3.22e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.632    |
| fps                | 447      |
| nupdates           | 100100   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2002000  |
| value_loss         | 7.79e-06 |
---------------------------------
---------------------------------
| explained_variance | -0.00262 |
| fps                | 447      |
| nupdates           | 100200   |
| policy_entropy     | 2.4      |
| total_timesteps    | 2004000  |
| value_loss         | 6.76e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.116    |
| fps                | 447      |
| nupdates           | 100300   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2006000  |
| value_loss         | 1.55e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.565    |
| fps                | 447      |
| nupdates           | 100400   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2008000  |
| value_loss         | 8.23e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.104    |
| fps                | 447      |
| nupdates           | 100500   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2010000  |
| value_loss         | 1.58e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.236    |
| fps                | 447      |
| nupdates           | 100600   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2012000  |
| value_loss         | 1.19e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.428    |
| fps                | 447      |
| nupdates           | 100700   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2014000  |
| value_loss         | 2.13e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.0502  |
| fps                | 447      |
| nupdates           | 100800   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2016000  |
| value_loss         | 9.62e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.627    |
| fps                | 447      |
| nupdates           | 100900   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2018000  |
| value_loss         | 6.47e-06 |
---------------------------------
Eval num_timesteps=2020000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.511    |
| fps                | 447      |
| nupdates           | 101000   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2020000  |
| value_loss         | 2.24e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.823    |
| fps                | 447      |
| nupdates           | 101100   |
| policy_entropy     | 2.39     |
| total_timesteps    | 2022000  |
| value_loss         | 9.59e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.503    |
| fps                | 447      |
| nupdates           | 101200   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2024000  |
| value_loss         | 1.66e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.237    |
| fps                | 447      |
| nupdates           | 101300   |
| policy_entropy     | 2.39     |
| total_timesteps    | 2026000  |
| value_loss         | 1.11e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.23     |
| fps                | 447      |
| nupdates           | 101400   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2028000  |
| value_loss         | 8.19e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.449    |
| fps                | 447      |
| nupdates           | 101500   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2030000  |
| value_loss         | 1.1e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.48     |
| fps                | 447      |
| nupdates           | 101600   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2032000  |
| value_loss         | 1.63e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.53    |
| fps                | 447      |
| nupdates           | 101700   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2034000  |
| value_loss         | 1.69e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.345    |
| fps                | 447      |
| nupdates           | 101800   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2036000  |
| value_loss         | 8.52e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.662    |
| fps                | 447      |
| nupdates           | 101900   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2038000  |
| value_loss         | 4.48e-06 |
---------------------------------
Eval num_timesteps=2040000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.418    |
| fps                | 447      |
| nupdates           | 102000   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2040000  |
| value_loss         | 1.06e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.495    |
| fps                | 447      |
| nupdates           | 102100   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2042000  |
| value_loss         | 2.3e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.534    |
| fps                | 447      |
| nupdates           | 102200   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2044000  |
| value_loss         | 1.87e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.194    |
| fps                | 447      |
| nupdates           | 102300   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2046000  |
| value_loss         | 1.71e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.599    |
| fps                | 447      |
| nupdates           | 102400   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2048000  |
| value_loss         | 9.21e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.482    |
| fps                | 447      |
| nupdates           | 102500   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2050000  |
| value_loss         | 8.34e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.794    |
| fps                | 447      |
| nupdates           | 102600   |
| policy_entropy     | 2.39     |
| total_timesteps    | 2052000  |
| value_loss         | 4.36e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.499    |
| fps                | 447      |
| nupdates           | 102700   |
| policy_entropy     | 2.45     |
| total_timesteps    | 2054000  |
| value_loss         | 1.59e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.122    |
| fps                | 447      |
| nupdates           | 102800   |
| policy_entropy     | 2.52     |
| total_timesteps    | 2056000  |
| value_loss         | 2.44e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.51     |
| fps                | 447      |
| nupdates           | 102900   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2058000  |
| value_loss         | 1.55e-05 |
---------------------------------
Eval num_timesteps=2060000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.519    |
| fps                | 447      |
| nupdates           | 103000   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2060000  |
| value_loss         | 4.22e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.135    |
| fps                | 447      |
| nupdates           | 103100   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2062000  |
| value_loss         | 2.73e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.585    |
| fps                | 447      |
| nupdates           | 103200   |
| policy_entropy     | 2.39     |
| total_timesteps    | 2064000  |
| value_loss         | 9.72e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.659    |
| fps                | 447      |
| nupdates           | 103300   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2066000  |
| value_loss         | 5.38e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.516    |
| fps                | 447      |
| nupdates           | 103400   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2068000  |
| value_loss         | 9.86e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.747    |
| fps                | 447      |
| nupdates           | 103500   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2070000  |
| value_loss         | 6.92e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.679    |
| fps                | 447      |
| nupdates           | 103600   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2072000  |
| value_loss         | 6.44e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.129    |
| fps                | 447      |
| nupdates           | 103700   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2074000  |
| value_loss         | 4.71e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.662    |
| fps                | 447      |
| nupdates           | 103800   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2076000  |
| value_loss         | 4.31e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.609    |
| fps                | 447      |
| nupdates           | 103900   |
| policy_entropy     | 2.45     |
| total_timesteps    | 2078000  |
| value_loss         | 6.6e-06  |
---------------------------------
Eval num_timesteps=2080000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.456    |
| fps                | 447      |
| nupdates           | 104000   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2080000  |
| value_loss         | 7.4e-06  |
---------------------------------
---------------------------------
| explained_variance | 0.64     |
| fps                | 447      |
| nupdates           | 104100   |
| policy_entropy     | 2.39     |
| total_timesteps    | 2082000  |
| value_loss         | 8.05e-06 |
---------------------------------
---------------------------------
| explained_variance | -0.538   |
| fps                | 447      |
| nupdates           | 104200   |
| policy_entropy     | 2.45     |
| total_timesteps    | 2084000  |
| value_loss         | 3.8e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.4      |
| fps                | 447      |
| nupdates           | 104300   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2086000  |
| value_loss         | 2.41e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.782    |
| fps                | 447      |
| nupdates           | 104400   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2088000  |
| value_loss         | 2.44e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.454    |
| fps                | 447      |
| nupdates           | 104500   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2090000  |
| value_loss         | 1.29e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.69     |
| fps                | 447      |
| nupdates           | 104600   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2092000  |
| value_loss         | 4.47e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.232    |
| fps                | 447      |
| nupdates           | 104700   |
| policy_entropy     | 2.56     |
| total_timesteps    | 2094000  |
| value_loss         | 3.02e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.593    |
| fps                | 447      |
| nupdates           | 104800   |
| policy_entropy     | 2.4      |
| total_timesteps    | 2096000  |
| value_loss         | 1.06e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.769    |
| fps                | 447      |
| nupdates           | 104900   |
| policy_entropy     | 2.45     |
| total_timesteps    | 2098000  |
| value_loss         | 2.38e-06 |
---------------------------------
Eval num_timesteps=2100000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.0688   |
| fps                | 447      |
| nupdates           | 105000   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2100000  |
| value_loss         | 2.18e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.431    |
| fps                | 447      |
| nupdates           | 105100   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2102000  |
| value_loss         | 2.9e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.232    |
| fps                | 447      |
| nupdates           | 105200   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2104000  |
| value_loss         | 4.49e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.273    |
| fps                | 447      |
| nupdates           | 105300   |
| policy_entropy     | 2.45     |
| total_timesteps    | 2106000  |
| value_loss         | 3.28e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.503    |
| fps                | 447      |
| nupdates           | 105400   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2108000  |
| value_loss         | 3.2e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.368    |
| fps                | 447      |
| nupdates           | 105500   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2110000  |
| value_loss         | 2.45e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.31     |
| fps                | 447      |
| nupdates           | 105600   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2112000  |
| value_loss         | 2.52e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.742    |
| fps                | 447      |
| nupdates           | 105700   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2114000  |
| value_loss         | 3.38e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.489    |
| fps                | 447      |
| nupdates           | 105800   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2116000  |
| value_loss         | 8.86e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.457    |
| fps                | 447      |
| nupdates           | 105900   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2118000  |
| value_loss         | 9.11e-06 |
---------------------------------
Eval num_timesteps=2120000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.8      |
| fps                | 447      |
| nupdates           | 106000   |
| policy_entropy     | 2.4      |
| total_timesteps    | 2120000  |
| value_loss         | 2.14e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.621    |
| fps                | 447      |
| nupdates           | 106100   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2122000  |
| value_loss         | 1.23e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.532    |
| fps                | 447      |
| nupdates           | 106200   |
| policy_entropy     | 2.45     |
| total_timesteps    | 2124000  |
| value_loss         | 1.74e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.69     |
| fps                | 447      |
| nupdates           | 106300   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2126000  |
| value_loss         | 7.13e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.45     |
| fps                | 447      |
| nupdates           | 106400   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2128000  |
| value_loss         | 1.46e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.476    |
| fps                | 447      |
| nupdates           | 106500   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2130000  |
| value_loss         | 3.28e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.704    |
| fps                | 447      |
| nupdates           | 106600   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2132000  |
| value_loss         | 7.66e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.559    |
| fps                | 447      |
| nupdates           | 106700   |
| policy_entropy     | 2.45     |
| total_timesteps    | 2134000  |
| value_loss         | 6.19e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.577    |
| fps                | 447      |
| nupdates           | 106800   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2136000  |
| value_loss         | 7.73e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.0628   |
| fps                | 447      |
| nupdates           | 106900   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2138000  |
| value_loss         | 2.91e-05 |
---------------------------------
Eval num_timesteps=2140000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.581    |
| fps                | 447      |
| nupdates           | 107000   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2140000  |
| value_loss         | 1.13e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.448    |
| fps                | 447      |
| nupdates           | 107100   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2142000  |
| value_loss         | 1.57e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.728    |
| fps                | 447      |
| nupdates           | 107200   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2144000  |
| value_loss         | 3.83e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.537    |
| fps                | 447      |
| nupdates           | 107300   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2146000  |
| value_loss         | 1.15e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.491    |
| fps                | 447      |
| nupdates           | 107400   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2148000  |
| value_loss         | 9.25e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.578    |
| fps                | 447      |
| nupdates           | 107500   |
| policy_entropy     | 2.5      |
| total_timesteps    | 2150000  |
| value_loss         | 8.73e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.632    |
| fps                | 447      |
| nupdates           | 107600   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2152000  |
| value_loss         | 1.4e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.593    |
| fps                | 447      |
| nupdates           | 107700   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2154000  |
| value_loss         | 1.03e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.409    |
| fps                | 447      |
| nupdates           | 107800   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2156000  |
| value_loss         | 3e-05    |
---------------------------------
---------------------------------
| explained_variance | 0.711    |
| fps                | 447      |
| nupdates           | 107900   |
| policy_entropy     | 2.45     |
| total_timesteps    | 2158000  |
| value_loss         | 9.05e-06 |
---------------------------------
Eval num_timesteps=2160000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.462    |
| fps                | 447      |
| nupdates           | 108000   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2160000  |
| value_loss         | 1.53e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.488    |
| fps                | 447      |
| nupdates           | 108100   |
| policy_entropy     | 2.39     |
| total_timesteps    | 2162000  |
| value_loss         | 1.34e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.58     |
| fps                | 447      |
| nupdates           | 108200   |
| policy_entropy     | 2.52     |
| total_timesteps    | 2164000  |
| value_loss         | 1.06e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.451    |
| fps                | 447      |
| nupdates           | 108300   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2166000  |
| value_loss         | 1.73e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.528    |
| fps                | 447      |
| nupdates           | 108400   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2168000  |
| value_loss         | 2.49e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.128    |
| fps                | 447      |
| nupdates           | 108500   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2170000  |
| value_loss         | 1.25e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.7     |
| fps                | 447      |
| nupdates           | 108600   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2172000  |
| value_loss         | 3.14e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.698   |
| fps                | 447      |
| nupdates           | 108700   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2174000  |
| value_loss         | 3.77e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.483    |
| fps                | 447      |
| nupdates           | 108800   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2176000  |
| value_loss         | 1.18e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.69    |
| fps                | 447      |
| nupdates           | 108900   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2178000  |
| value_loss         | 0.000171 |
---------------------------------
Eval num_timesteps=2180000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -0.153   |
| fps                | 447      |
| nupdates           | 109000   |
| policy_entropy     | 2.45     |
| total_timesteps    | 2180000  |
| value_loss         | 6.56e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.0412   |
| fps                | 447      |
| nupdates           | 109100   |
| policy_entropy     | 2.48     |
| total_timesteps    | 2182000  |
| value_loss         | 3.27e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.784    |
| fps                | 447      |
| nupdates           | 109200   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2184000  |
| value_loss         | 4.75e-06 |
---------------------------------
---------------------------------
| explained_variance | -0.00705 |
| fps                | 447      |
| nupdates           | 109300   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2186000  |
| value_loss         | 3.03e-05 |
---------------------------------
---------------------------------
| explained_variance | -2.46    |
| fps                | 447      |
| nupdates           | 109400   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2188000  |
| value_loss         | 0.000292 |
---------------------------------
---------------------------------
| explained_variance | -0.286   |
| fps                | 447      |
| nupdates           | 109500   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2190000  |
| value_loss         | 4.49e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.492    |
| fps                | 447      |
| nupdates           | 109600   |
| policy_entropy     | 2.44     |
| total_timesteps    | 2192000  |
| value_loss         | 1.03e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.28    |
| fps                | 447      |
| nupdates           | 109700   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2194000  |
| value_loss         | 4.67e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.66     |
| fps                | 447      |
| nupdates           | 109800   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2196000  |
| value_loss         | 7.29e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.717    |
| fps                | 447      |
| nupdates           | 109900   |
| policy_entropy     | 2.47     |
| total_timesteps    | 2198000  |
| value_loss         | 5.77e-06 |
---------------------------------
Eval num_timesteps=2200000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.566    |
| fps                | 447      |
| nupdates           | 110000   |
| policy_entropy     | 2.52     |
| total_timesteps    | 2200000  |
| value_loss         | 1.36e-05 |
---------------------------------
---------------------------------
| explained_variance | -2.62    |
| fps                | 447      |
| nupdates           | 110100   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2202000  |
| value_loss         | 0.000181 |
---------------------------------
---------------------------------
| explained_variance | 0.159    |
| fps                | 447      |
| nupdates           | 110200   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2204000  |
| value_loss         | 1.42e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.549    |
| fps                | 447      |
| nupdates           | 110300   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2206000  |
| value_loss         | 9.21e-06 |
---------------------------------
---------------------------------
| explained_variance | -2.69    |
| fps                | 447      |
| nupdates           | 110400   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2208000  |
| value_loss         | 0.000333 |
---------------------------------
---------------------------------
| explained_variance | 0.46     |
| fps                | 447      |
| nupdates           | 110500   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2210000  |
| value_loss         | 1.97e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.342    |
| fps                | 447      |
| nupdates           | 110600   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2212000  |
| value_loss         | 1.54e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.8     |
| fps                | 447      |
| nupdates           | 110700   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2214000  |
| value_loss         | 3.31e-05 |
---------------------------------
---------------------------------
| explained_variance | -3       |
| fps                | 447      |
| nupdates           | 110800   |
| policy_entropy     | 2.39     |
| total_timesteps    | 2216000  |
| value_loss         | 3.64e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.632    |
| fps                | 447      |
| nupdates           | 110900   |
| policy_entropy     | 2.4      |
| total_timesteps    | 2218000  |
| value_loss         | 6.46e-06 |
---------------------------------
Eval num_timesteps=2220000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.662    |
| fps                | 447      |
| nupdates           | 111000   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2220000  |
| value_loss         | 8.47e-06 |
---------------------------------
---------------------------------
| explained_variance | -0.122   |
| fps                | 447      |
| nupdates           | 111100   |
| policy_entropy     | 2.33     |
| total_timesteps    | 2222000  |
| value_loss         | 6.76e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.596    |
| fps                | 447      |
| nupdates           | 111200   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2224000  |
| value_loss         | 9.53e-06 |
---------------------------------
---------------------------------
| explained_variance | -0.656   |
| fps                | 447      |
| nupdates           | 111300   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2226000  |
| value_loss         | 4.99e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.04    |
| fps                | 447      |
| nupdates           | 111400   |
| policy_entropy     | 2.45     |
| total_timesteps    | 2228000  |
| value_loss         | 7.38e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.084   |
| fps                | 447      |
| nupdates           | 111500   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2230000  |
| value_loss         | 3.27e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.599    |
| fps                | 447      |
| nupdates           | 111600   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2232000  |
| value_loss         | 1.1e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.308    |
| fps                | 447      |
| nupdates           | 111700   |
| policy_entropy     | 2.5      |
| total_timesteps    | 2234000  |
| value_loss         | 1.09e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.52    |
| fps                | 447      |
| nupdates           | 111800   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2236000  |
| value_loss         | 0.000151 |
---------------------------------
---------------------------------
| explained_variance | 0.548    |
| fps                | 447      |
| nupdates           | 111900   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2238000  |
| value_loss         | 1.13e-05 |
---------------------------------
Eval num_timesteps=2240000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -0.0974  |
| fps                | 447      |
| nupdates           | 112000   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2240000  |
| value_loss         | 2.31e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.507    |
| fps                | 447      |
| nupdates           | 112100   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2242000  |
| value_loss         | 1.21e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.0082  |
| fps                | 447      |
| nupdates           | 112200   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2244000  |
| value_loss         | 2.82e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.406    |
| fps                | 447      |
| nupdates           | 112300   |
| policy_entropy     | 2.45     |
| total_timesteps    | 2246000  |
| value_loss         | 1.75e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.308    |
| fps                | 447      |
| nupdates           | 112400   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2248000  |
| value_loss         | 4.47e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.534    |
| fps                | 447      |
| nupdates           | 112500   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2250000  |
| value_loss         | 1.37e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.228    |
| fps                | 447      |
| nupdates           | 112600   |
| policy_entropy     | 2.53     |
| total_timesteps    | 2252000  |
| value_loss         | 4.76e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.682    |
| fps                | 447      |
| nupdates           | 112700   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2254000  |
| value_loss         | 4.47e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.568    |
| fps                | 447      |
| nupdates           | 112800   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2256000  |
| value_loss         | 8.86e-06 |
---------------------------------
---------------------------------
| explained_variance | -1.52    |
| fps                | 447      |
| nupdates           | 112900   |
| policy_entropy     | 2.52     |
| total_timesteps    | 2258000  |
| value_loss         | 0.000448 |
---------------------------------
Eval num_timesteps=2260000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -0.893   |
| fps                | 447      |
| nupdates           | 113000   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2260000  |
| value_loss         | 9.93e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.172   |
| fps                | 447      |
| nupdates           | 113100   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2262000  |
| value_loss         | 2.77e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.9     |
| fps                | 447      |
| nupdates           | 113200   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2264000  |
| value_loss         | 6.78e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.359   |
| fps                | 447      |
| nupdates           | 113300   |
| policy_entropy     | 2.39     |
| total_timesteps    | 2266000  |
| value_loss         | 3.35e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.27    |
| fps                | 447      |
| nupdates           | 113400   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2268000  |
| value_loss         | 5.5e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.53     |
| fps                | 447      |
| nupdates           | 113500   |
| policy_entropy     | 2.47     |
| total_timesteps    | 2270000  |
| value_loss         | 9.39e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.307    |
| fps                | 447      |
| nupdates           | 113600   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2272000  |
| value_loss         | 1.39e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.4     |
| fps                | 447      |
| nupdates           | 113700   |
| policy_entropy     | 2.45     |
| total_timesteps    | 2274000  |
| value_loss         | 2.7e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.564    |
| fps                | 447      |
| nupdates           | 113800   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2276000  |
| value_loss         | 1.12e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.0282   |
| fps                | 447      |
| nupdates           | 113900   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2278000  |
| value_loss         | 3.89e-05 |
---------------------------------
Eval num_timesteps=2280000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.104    |
| fps                | 447      |
| nupdates           | 114000   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2280000  |
| value_loss         | 1.78e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.638    |
| fps                | 447      |
| nupdates           | 114100   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2282000  |
| value_loss         | 8.75e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.552    |
| fps                | 447      |
| nupdates           | 114200   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2284000  |
| value_loss         | 1.07e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.225   |
| fps                | 447      |
| nupdates           | 114300   |
| policy_entropy     | 2.4      |
| total_timesteps    | 2286000  |
| value_loss         | 3.5e-05  |
---------------------------------
---------------------------------
| explained_variance | -0.766   |
| fps                | 447      |
| nupdates           | 114400   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2288000  |
| value_loss         | 3.03e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.85    |
| fps                | 447      |
| nupdates           | 114500   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2290000  |
| value_loss         | 0.000177 |
---------------------------------
---------------------------------
| explained_variance | -0.509   |
| fps                | 447      |
| nupdates           | 114600   |
| policy_entropy     | 2.36     |
| total_timesteps    | 2292000  |
| value_loss         | 1.79e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.29     |
| fps                | 447      |
| nupdates           | 114700   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2294000  |
| value_loss         | 1.34e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.281    |
| fps                | 447      |
| nupdates           | 114800   |
| policy_entropy     | 2.4      |
| total_timesteps    | 2296000  |
| value_loss         | 1.55e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.691    |
| fps                | 447      |
| nupdates           | 114900   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2298000  |
| value_loss         | 7.03e-06 |
---------------------------------
Eval num_timesteps=2300000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.489    |
| fps                | 447      |
| nupdates           | 115000   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2300000  |
| value_loss         | 1.64e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.273    |
| fps                | 447      |
| nupdates           | 115100   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2302000  |
| value_loss         | 4.29e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.394    |
| fps                | 447      |
| nupdates           | 115200   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2304000  |
| value_loss         | 7.62e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.646    |
| fps                | 447      |
| nupdates           | 115300   |
| policy_entropy     | 2.55     |
| total_timesteps    | 2306000  |
| value_loss         | 1.93e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.649    |
| fps                | 447      |
| nupdates           | 115400   |
| policy_entropy     | 2.5      |
| total_timesteps    | 2308000  |
| value_loss         | 9.93e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.67     |
| fps                | 447      |
| nupdates           | 115500   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2310000  |
| value_loss         | 8.66e-06 |
---------------------------------
---------------------------------
| explained_variance | -0.372   |
| fps                | 447      |
| nupdates           | 115600   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2312000  |
| value_loss         | 6.67e-05 |
---------------------------------
---------------------------------
| explained_variance | -2.49    |
| fps                | 447      |
| nupdates           | 115700   |
| policy_entropy     | 2.47     |
| total_timesteps    | 2314000  |
| value_loss         | 0.000415 |
---------------------------------
---------------------------------
| explained_variance | 0.252    |
| fps                | 447      |
| nupdates           | 115800   |
| policy_entropy     | 2.47     |
| total_timesteps    | 2316000  |
| value_loss         | 2.79e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.31    |
| fps                | 447      |
| nupdates           | 115900   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2318000  |
| value_loss         | 4.72e-05 |
---------------------------------
Eval num_timesteps=2320000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.518    |
| fps                | 447      |
| nupdates           | 116000   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2320000  |
| value_loss         | 1.05e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.788    |
| fps                | 447      |
| nupdates           | 116100   |
| policy_entropy     | 2.4      |
| total_timesteps    | 2322000  |
| value_loss         | 7.71e-06 |
---------------------------------
---------------------------------
| explained_variance | -0.76    |
| fps                | 447      |
| nupdates           | 116200   |
| policy_entropy     | 2.48     |
| total_timesteps    | 2324000  |
| value_loss         | 4.6e-05  |
---------------------------------
---------------------------------
| explained_variance | -1.05    |
| fps                | 447      |
| nupdates           | 116300   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2326000  |
| value_loss         | 8.66e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.402    |
| fps                | 447      |
| nupdates           | 116400   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2328000  |
| value_loss         | 3.33e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.592    |
| fps                | 447      |
| nupdates           | 116500   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2330000  |
| value_loss         | 7.7e-06  |
---------------------------------
---------------------------------
| explained_variance | 0.368    |
| fps                | 447      |
| nupdates           | 116600   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2332000  |
| value_loss         | 1.79e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.147   |
| fps                | 447      |
| nupdates           | 116700   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2334000  |
| value_loss         | 4.43e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.492    |
| fps                | 447      |
| nupdates           | 116800   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2336000  |
| value_loss         | 1.26e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.299    |
| fps                | 447      |
| nupdates           | 116900   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2338000  |
| value_loss         | 1.92e-05 |
---------------------------------
Eval num_timesteps=2340000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -2.43    |
| fps                | 447      |
| nupdates           | 117000   |
| policy_entropy     | 2.54     |
| total_timesteps    | 2340000  |
| value_loss         | 9.37e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.37    |
| fps                | 447      |
| nupdates           | 117100   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2342000  |
| value_loss         | 4.38e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.15    |
| fps                | 447      |
| nupdates           | 117200   |
| policy_entropy     | 2.51     |
| total_timesteps    | 2344000  |
| value_loss         | 2.47e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.696    |
| fps                | 447      |
| nupdates           | 117300   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2346000  |
| value_loss         | 1.21e-05 |
---------------------------------
---------------------------------
| explained_variance | -3.82    |
| fps                | 447      |
| nupdates           | 117400   |
| policy_entropy     | 2.41     |
| total_timesteps    | 2348000  |
| value_loss         | 0.000283 |
---------------------------------
---------------------------------
| explained_variance | -1.38    |
| fps                | 447      |
| nupdates           | 117500   |
| policy_entropy     | 2.52     |
| total_timesteps    | 2350000  |
| value_loss         | 0.000153 |
---------------------------------
---------------------------------
| explained_variance | 0.479    |
| fps                | 447      |
| nupdates           | 117600   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2352000  |
| value_loss         | 2.04e-05 |
---------------------------------
---------------------------------
| explained_variance | -3.61    |
| fps                | 447      |
| nupdates           | 117700   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2354000  |
| value_loss         | 0.00022  |
---------------------------------
---------------------------------
| explained_variance | -0.673   |
| fps                | 447      |
| nupdates           | 117800   |
| policy_entropy     | 2.52     |
| total_timesteps    | 2356000  |
| value_loss         | 4.52e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.625    |
| fps                | 447      |
| nupdates           | 117900   |
| policy_entropy     | 2.45     |
| total_timesteps    | 2358000  |
| value_loss         | 6.72e-06 |
---------------------------------
Eval num_timesteps=2360000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.579    |
| fps                | 447      |
| nupdates           | 118000   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2360000  |
| value_loss         | 6.76e-06 |
---------------------------------
---------------------------------
| explained_variance | -0.508   |
| fps                | 447      |
| nupdates           | 118100   |
| policy_entropy     | 2.4      |
| total_timesteps    | 2362000  |
| value_loss         | 2.96e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.944    |
| fps                | 447      |
| nupdates           | 118200   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2364000  |
| value_loss         | 4e-06    |
---------------------------------
---------------------------------
| explained_variance | 0.54     |
| fps                | 447      |
| nupdates           | 118300   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2366000  |
| value_loss         | 1.37e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.714   |
| fps                | 447      |
| nupdates           | 118400   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2368000  |
| value_loss         | 4.37e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.864   |
| fps                | 447      |
| nupdates           | 118500   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2370000  |
| value_loss         | 8.26e-05 |
---------------------------------
---------------------------------
| explained_variance | -4.61    |
| fps                | 447      |
| nupdates           | 118600   |
| policy_entropy     | 2.45     |
| total_timesteps    | 2372000  |
| value_loss         | 0.000384 |
---------------------------------
---------------------------------
| explained_variance | 0.042    |
| fps                | 447      |
| nupdates           | 118700   |
| policy_entropy     | 2.53     |
| total_timesteps    | 2374000  |
| value_loss         | 7.41e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.321   |
| fps                | 447      |
| nupdates           | 118800   |
| policy_entropy     | 2.45     |
| total_timesteps    | 2376000  |
| value_loss         | 7.43e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.425   |
| fps                | 447      |
| nupdates           | 118900   |
| policy_entropy     | 2.52     |
| total_timesteps    | 2378000  |
| value_loss         | 9.12e-05 |
---------------------------------
Eval num_timesteps=2380000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -0.108   |
| fps                | 447      |
| nupdates           | 119000   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2380000  |
| value_loss         | 2.31e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.286   |
| fps                | 447      |
| nupdates           | 119100   |
| policy_entropy     | 2.4      |
| total_timesteps    | 2382000  |
| value_loss         | 2.54e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.934   |
| fps                | 447      |
| nupdates           | 119200   |
| policy_entropy     | 2.39     |
| total_timesteps    | 2384000  |
| value_loss         | 4.06e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.333    |
| fps                | 447      |
| nupdates           | 119300   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2386000  |
| value_loss         | 8.14e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.668    |
| fps                | 447      |
| nupdates           | 119400   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2388000  |
| value_loss         | 5.3e-06  |
---------------------------------
---------------------------------
| explained_variance | 0.429    |
| fps                | 447      |
| nupdates           | 119500   |
| policy_entropy     | 2.45     |
| total_timesteps    | 2390000  |
| value_loss         | 3.24e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.484    |
| fps                | 447      |
| nupdates           | 119600   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2392000  |
| value_loss         | 1.45e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.432    |
| fps                | 447      |
| nupdates           | 119700   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2394000  |
| value_loss         | 3.81e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.121   |
| fps                | 447      |
| nupdates           | 119800   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2396000  |
| value_loss         | 3.36e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.456    |
| fps                | 447      |
| nupdates           | 119900   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2398000  |
| value_loss         | 2.55e-05 |
---------------------------------
Eval num_timesteps=2400000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -0.09    |
| fps                | 447      |
| nupdates           | 120000   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2400000  |
| value_loss         | 2.1e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.581    |
| fps                | 447      |
| nupdates           | 120100   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2402000  |
| value_loss         | 2.98e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.335    |
| fps                | 447      |
| nupdates           | 120200   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2404000  |
| value_loss         | 1.81e-05 |
---------------------------------
---------------------------------
| explained_variance | -4.04    |
| fps                | 447      |
| nupdates           | 120300   |
| policy_entropy     | 2.4      |
| total_timesteps    | 2406000  |
| value_loss         | 0.000528 |
---------------------------------
---------------------------------
| explained_variance | 0.657    |
| fps                | 447      |
| nupdates           | 120400   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2408000  |
| value_loss         | 9.31e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.504    |
| fps                | 447      |
| nupdates           | 120500   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2410000  |
| value_loss         | 1.37e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.223    |
| fps                | 447      |
| nupdates           | 120600   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2412000  |
| value_loss         | 2.56e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.336    |
| fps                | 447      |
| nupdates           | 120700   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2414000  |
| value_loss         | 1.05e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.89    |
| fps                | 447      |
| nupdates           | 120800   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2416000  |
| value_loss         | 4.38e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.666    |
| fps                | 447      |
| nupdates           | 120900   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2418000  |
| value_loss         | 4.85e-06 |
---------------------------------
Eval num_timesteps=2420000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -0.0816  |
| fps                | 447      |
| nupdates           | 121000   |
| policy_entropy     | 2.39     |
| total_timesteps    | 2420000  |
| value_loss         | 1.58e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.429    |
| fps                | 447      |
| nupdates           | 121100   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2422000  |
| value_loss         | 1.02e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.623   |
| fps                | 447      |
| nupdates           | 121200   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2424000  |
| value_loss         | 4.59e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.471    |
| fps                | 447      |
| nupdates           | 121300   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2426000  |
| value_loss         | 3.22e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.566    |
| fps                | 447      |
| nupdates           | 121400   |
| policy_entropy     | 2.39     |
| total_timesteps    | 2428000  |
| value_loss         | 6.88e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.458    |
| fps                | 447      |
| nupdates           | 121500   |
| policy_entropy     | 2.45     |
| total_timesteps    | 2430000  |
| value_loss         | 3.77e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.801    |
| fps                | 447      |
| nupdates           | 121600   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2432000  |
| value_loss         | 3.14e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.619    |
| fps                | 447      |
| nupdates           | 121700   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2434000  |
| value_loss         | 4.38e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.507    |
| fps                | 447      |
| nupdates           | 121800   |
| policy_entropy     | 2.45     |
| total_timesteps    | 2436000  |
| value_loss         | 2.55e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.668    |
| fps                | 447      |
| nupdates           | 121900   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2438000  |
| value_loss         | 7.47e-06 |
---------------------------------
Eval num_timesteps=2440000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.417    |
| fps                | 447      |
| nupdates           | 122000   |
| policy_entropy     | 2.45     |
| total_timesteps    | 2440000  |
| value_loss         | 6.95e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.4      |
| fps                | 447      |
| nupdates           | 122100   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2442000  |
| value_loss         | 1.92e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.529    |
| fps                | 447      |
| nupdates           | 122200   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2444000  |
| value_loss         | 1.43e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.544    |
| fps                | 447      |
| nupdates           | 122300   |
| policy_entropy     | 2.45     |
| total_timesteps    | 2446000  |
| value_loss         | 2.6e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.666    |
| fps                | 447      |
| nupdates           | 122400   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2448000  |
| value_loss         | 5.87e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.0716   |
| fps                | 447      |
| nupdates           | 122500   |
| policy_entropy     | 2.36     |
| total_timesteps    | 2450000  |
| value_loss         | 1.19e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.423    |
| fps                | 447      |
| nupdates           | 122600   |
| policy_entropy     | 2.56     |
| total_timesteps    | 2452000  |
| value_loss         | 2.15e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.953   |
| fps                | 447      |
| nupdates           | 122700   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2454000  |
| value_loss         | 8.81e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.923    |
| fps                | 447      |
| nupdates           | 122800   |
| policy_entropy     | 2.33     |
| total_timesteps    | 2456000  |
| value_loss         | 1.19e-06 |
---------------------------------
---------------------------------
| explained_variance | -4.51    |
| fps                | 447      |
| nupdates           | 122900   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2458000  |
| value_loss         | 0.000197 |
---------------------------------
Eval num_timesteps=2460000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.549    |
| fps                | 447      |
| nupdates           | 123000   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2460000  |
| value_loss         | 1.57e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.954    |
| fps                | 447      |
| nupdates           | 123100   |
| policy_entropy     | 2.39     |
| total_timesteps    | 2462000  |
| value_loss         | 7.94e-07 |
---------------------------------
---------------------------------
| explained_variance | 0.621    |
| fps                | 447      |
| nupdates           | 123200   |
| policy_entropy     | 2.5      |
| total_timesteps    | 2464000  |
| value_loss         | 7.01e-06 |
---------------------------------
---------------------------------
| explained_variance | -2.12    |
| fps                | 447      |
| nupdates           | 123300   |
| policy_entropy     | 2.4      |
| total_timesteps    | 2466000  |
| value_loss         | 1.97e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.127    |
| fps                | 447      |
| nupdates           | 123400   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2468000  |
| value_loss         | 1.51e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.575    |
| fps                | 447      |
| nupdates           | 123500   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2470000  |
| value_loss         | 1.11e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.558    |
| fps                | 447      |
| nupdates           | 123600   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2472000  |
| value_loss         | 2.79e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.555    |
| fps                | 447      |
| nupdates           | 123700   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2474000  |
| value_loss         | 4.16e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.0819   |
| fps                | 447      |
| nupdates           | 123800   |
| policy_entropy     | 2.5      |
| total_timesteps    | 2476000  |
| value_loss         | 2.39e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.658    |
| fps                | 447      |
| nupdates           | 123900   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2478000  |
| value_loss         | 7.75e-06 |
---------------------------------
Eval num_timesteps=2480000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.628    |
| fps                | 447      |
| nupdates           | 124000   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2480000  |
| value_loss         | 6.82e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.349    |
| fps                | 447      |
| nupdates           | 124100   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2482000  |
| value_loss         | 5.7e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.319    |
| fps                | 447      |
| nupdates           | 124200   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2484000  |
| value_loss         | 4.82e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.458    |
| fps                | 447      |
| nupdates           | 124300   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2486000  |
| value_loss         | 3.12e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.591    |
| fps                | 447      |
| nupdates           | 124400   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2488000  |
| value_loss         | 7.58e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.675    |
| fps                | 447      |
| nupdates           | 124500   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2490000  |
| value_loss         | 1.03e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.351    |
| fps                | 447      |
| nupdates           | 124600   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2492000  |
| value_loss         | 9.02e-06 |
---------------------------------
---------------------------------
| explained_variance | -0.702   |
| fps                | 447      |
| nupdates           | 124700   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2494000  |
| value_loss         | 4.17e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.655    |
| fps                | 447      |
| nupdates           | 124800   |
| policy_entropy     | 2.4      |
| total_timesteps    | 2496000  |
| value_loss         | 4.08e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.474    |
| fps                | 447      |
| nupdates           | 124900   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2498000  |
| value_loss         | 8.73e-06 |
---------------------------------
Eval num_timesteps=2500000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.953    |
| fps                | 447      |
| nupdates           | 125000   |
| policy_entropy     | 2.4      |
| total_timesteps    | 2500000  |
| value_loss         | 3.15e-07 |
---------------------------------
---------------------------------
| explained_variance | 0.372    |
| fps                | 447      |
| nupdates           | 125100   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2502000  |
| value_loss         | 2.84e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.469    |
| fps                | 447      |
| nupdates           | 125200   |
| policy_entropy     | 2.52     |
| total_timesteps    | 2504000  |
| value_loss         | 1.03e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.484    |
| fps                | 447      |
| nupdates           | 125300   |
| policy_entropy     | 2.52     |
| total_timesteps    | 2506000  |
| value_loss         | 1.43e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.251    |
| fps                | 447      |
| nupdates           | 125400   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2508000  |
| value_loss         | 1.38e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.506    |
| fps                | 447      |
| nupdates           | 125500   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2510000  |
| value_loss         | 1.61e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.464    |
| fps                | 447      |
| nupdates           | 125600   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2512000  |
| value_loss         | 1.55e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.581    |
| fps                | 447      |
| nupdates           | 125700   |
| policy_entropy     | 2.36     |
| total_timesteps    | 2514000  |
| value_loss         | 1.31e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.26     |
| fps                | 447      |
| nupdates           | 125800   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2516000  |
| value_loss         | 2.21e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.774    |
| fps                | 447      |
| nupdates           | 125900   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2518000  |
| value_loss         | 5.57e-06 |
---------------------------------
Eval num_timesteps=2520000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.775    |
| fps                | 447      |
| nupdates           | 126000   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2520000  |
| value_loss         | 6.63e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.523    |
| fps                | 447      |
| nupdates           | 126100   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2522000  |
| value_loss         | 2.38e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.602    |
| fps                | 447      |
| nupdates           | 126200   |
| policy_entropy     | 2.5      |
| total_timesteps    | 2524000  |
| value_loss         | 4.37e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.183    |
| fps                | 447      |
| nupdates           | 126300   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2526000  |
| value_loss         | 2.21e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.29    |
| fps                | 447      |
| nupdates           | 126400   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2528000  |
| value_loss         | 2.21e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.468    |
| fps                | 447      |
| nupdates           | 126500   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2530000  |
| value_loss         | 1.95e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.478    |
| fps                | 447      |
| nupdates           | 126600   |
| policy_entropy     | 2.52     |
| total_timesteps    | 2532000  |
| value_loss         | 1.03e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.263   |
| fps                | 447      |
| nupdates           | 126700   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2534000  |
| value_loss         | 1.92e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.177   |
| fps                | 447      |
| nupdates           | 126800   |
| policy_entropy     | 2.45     |
| total_timesteps    | 2536000  |
| value_loss         | 3.26e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.55     |
| fps                | 447      |
| nupdates           | 126900   |
| policy_entropy     | 2.5      |
| total_timesteps    | 2538000  |
| value_loss         | 1.52e-05 |
---------------------------------
Eval num_timesteps=2540000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.0964   |
| fps                | 447      |
| nupdates           | 127000   |
| policy_entropy     | 2.52     |
| total_timesteps    | 2540000  |
| value_loss         | 5.7e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.769    |
| fps                | 447      |
| nupdates           | 127100   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2542000  |
| value_loss         | 1.12e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.6      |
| fps                | 447      |
| nupdates           | 127200   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2544000  |
| value_loss         | 2.47e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.637    |
| fps                | 447      |
| nupdates           | 127300   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2546000  |
| value_loss         | 5.63e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.575    |
| fps                | 447      |
| nupdates           | 127400   |
| policy_entropy     | 2.4      |
| total_timesteps    | 2548000  |
| value_loss         | 1.33e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.252    |
| fps                | 447      |
| nupdates           | 127500   |
| policy_entropy     | 2.45     |
| total_timesteps    | 2550000  |
| value_loss         | 1.19e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.461   |
| fps                | 447      |
| nupdates           | 127600   |
| policy_entropy     | 2.45     |
| total_timesteps    | 2552000  |
| value_loss         | 8.14e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.481    |
| fps                | 447      |
| nupdates           | 127700   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2554000  |
| value_loss         | 2.34e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.619    |
| fps                | 447      |
| nupdates           | 127800   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2556000  |
| value_loss         | 7.61e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.341    |
| fps                | 447      |
| nupdates           | 127900   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2558000  |
| value_loss         | 4.5e-05  |
---------------------------------
Eval num_timesteps=2560000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -0.602   |
| fps                | 447      |
| nupdates           | 128000   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2560000  |
| value_loss         | 1.46e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.258    |
| fps                | 447      |
| nupdates           | 128100   |
| policy_entropy     | 2.52     |
| total_timesteps    | 2562000  |
| value_loss         | 3.83e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.462    |
| fps                | 447      |
| nupdates           | 128200   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2564000  |
| value_loss         | 1.45e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.87    |
| fps                | 447      |
| nupdates           | 128300   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2566000  |
| value_loss         | 4.55e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.183   |
| fps                | 447      |
| nupdates           | 128400   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2568000  |
| value_loss         | 2.28e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.602    |
| fps                | 447      |
| nupdates           | 128500   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2570000  |
| value_loss         | 1.32e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.55     |
| fps                | 447      |
| nupdates           | 128600   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2572000  |
| value_loss         | 1.23e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.523    |
| fps                | 447      |
| nupdates           | 128700   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2574000  |
| value_loss         | 1.07e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.609    |
| fps                | 447      |
| nupdates           | 128800   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2576000  |
| value_loss         | 2.01e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.607    |
| fps                | 447      |
| nupdates           | 128900   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2578000  |
| value_loss         | 7.61e-06 |
---------------------------------
Eval num_timesteps=2580000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.478    |
| fps                | 447      |
| nupdates           | 129000   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2580000  |
| value_loss         | 9.5e-06  |
---------------------------------
---------------------------------
| explained_variance | 0.521    |
| fps                | 447      |
| nupdates           | 129100   |
| policy_entropy     | 2.39     |
| total_timesteps    | 2582000  |
| value_loss         | 8.01e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.502    |
| fps                | 447      |
| nupdates           | 129200   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2584000  |
| value_loss         | 1.07e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.155   |
| fps                | 447      |
| nupdates           | 129300   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2586000  |
| value_loss         | 1.55e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.54     |
| fps                | 447      |
| nupdates           | 129400   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2588000  |
| value_loss         | 1.95e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.507    |
| fps                | 447      |
| nupdates           | 129500   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2590000  |
| value_loss         | 8.58e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.609    |
| fps                | 447      |
| nupdates           | 129600   |
| policy_entropy     | 2.4      |
| total_timesteps    | 2592000  |
| value_loss         | 7.14e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.422    |
| fps                | 447      |
| nupdates           | 129700   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2594000  |
| value_loss         | 9.74e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.735    |
| fps                | 447      |
| nupdates           | 129800   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2596000  |
| value_loss         | 4.14e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.501    |
| fps                | 447      |
| nupdates           | 129900   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2598000  |
| value_loss         | 2.15e-05 |
---------------------------------
Eval num_timesteps=2600000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.531    |
| fps                | 447      |
| nupdates           | 130000   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2600000  |
| value_loss         | 8.7e-06  |
---------------------------------
---------------------------------
| explained_variance | 0.498    |
| fps                | 447      |
| nupdates           | 130100   |
| policy_entropy     | 2.53     |
| total_timesteps    | 2602000  |
| value_loss         | 1.64e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.242    |
| fps                | 447      |
| nupdates           | 130200   |
| policy_entropy     | 2.52     |
| total_timesteps    | 2604000  |
| value_loss         | 5.89e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.572    |
| fps                | 447      |
| nupdates           | 130300   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2606000  |
| value_loss         | 5.01e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.507    |
| fps                | 447      |
| nupdates           | 130400   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2608000  |
| value_loss         | 1.25e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.477    |
| fps                | 447      |
| nupdates           | 130500   |
| policy_entropy     | 2.4      |
| total_timesteps    | 2610000  |
| value_loss         | 1.15e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.383    |
| fps                | 447      |
| nupdates           | 130600   |
| policy_entropy     | 2.4      |
| total_timesteps    | 2612000  |
| value_loss         | 2.49e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.327    |
| fps                | 447      |
| nupdates           | 130700   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2614000  |
| value_loss         | 2.68e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.399    |
| fps                | 447      |
| nupdates           | 130800   |
| policy_entropy     | 2.45     |
| total_timesteps    | 2616000  |
| value_loss         | 4.74e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.0019   |
| fps                | 447      |
| nupdates           | 130900   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2618000  |
| value_loss         | 1.64e-05 |
---------------------------------
Eval num_timesteps=2620000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.603    |
| fps                | 447      |
| nupdates           | 131000   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2620000  |
| value_loss         | 4.27e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.472    |
| fps                | 447      |
| nupdates           | 131100   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2622000  |
| value_loss         | 1.34e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.162    |
| fps                | 447      |
| nupdates           | 131200   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2624000  |
| value_loss         | 2.39e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.704    |
| fps                | 447      |
| nupdates           | 131300   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2626000  |
| value_loss         | 7.03e-06 |
---------------------------------
---------------------------------
| explained_variance | -0.123   |
| fps                | 447      |
| nupdates           | 131400   |
| policy_entropy     | 2.39     |
| total_timesteps    | 2628000  |
| value_loss         | 1.69e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.588    |
| fps                | 447      |
| nupdates           | 131500   |
| policy_entropy     | 2.45     |
| total_timesteps    | 2630000  |
| value_loss         | 1.08e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.756    |
| fps                | 447      |
| nupdates           | 131600   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2632000  |
| value_loss         | 2.97e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.715    |
| fps                | 447      |
| nupdates           | 131700   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2634000  |
| value_loss         | 8.63e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.642    |
| fps                | 447      |
| nupdates           | 131800   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2636000  |
| value_loss         | 6.7e-06  |
---------------------------------
---------------------------------
| explained_variance | 0.66     |
| fps                | 447      |
| nupdates           | 131900   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2638000  |
| value_loss         | 1.77e-05 |
---------------------------------
Eval num_timesteps=2640000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.693    |
| fps                | 447      |
| nupdates           | 132000   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2640000  |
| value_loss         | 9.2e-06  |
---------------------------------
---------------------------------
| explained_variance | 0.237    |
| fps                | 447      |
| nupdates           | 132100   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2642000  |
| value_loss         | 3.35e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.653    |
| fps                | 447      |
| nupdates           | 132200   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2644000  |
| value_loss         | 8.37e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.239    |
| fps                | 447      |
| nupdates           | 132300   |
| policy_entropy     | 2.4      |
| total_timesteps    | 2646000  |
| value_loss         | 9.91e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.436    |
| fps                | 447      |
| nupdates           | 132400   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2648000  |
| value_loss         | 1.36e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.47     |
| fps                | 447      |
| nupdates           | 132500   |
| policy_entropy     | 2.52     |
| total_timesteps    | 2650000  |
| value_loss         | 1.63e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.0889  |
| fps                | 447      |
| nupdates           | 132600   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2652000  |
| value_loss         | 2.32e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.79     |
| fps                | 447      |
| nupdates           | 132700   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2654000  |
| value_loss         | 4.08e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.471    |
| fps                | 447      |
| nupdates           | 132800   |
| policy_entropy     | 2.4      |
| total_timesteps    | 2656000  |
| value_loss         | 6e-06    |
---------------------------------
---------------------------------
| explained_variance | 0.518    |
| fps                | 447      |
| nupdates           | 132900   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2658000  |
| value_loss         | 8.5e-06  |
---------------------------------
Eval num_timesteps=2660000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.249    |
| fps                | 447      |
| nupdates           | 133000   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2660000  |
| value_loss         | 1.22e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.599    |
| fps                | 447      |
| nupdates           | 133100   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2662000  |
| value_loss         | 1.57e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.45     |
| fps                | 447      |
| nupdates           | 133200   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2664000  |
| value_loss         | 3.24e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.00147  |
| fps                | 447      |
| nupdates           | 133300   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2666000  |
| value_loss         | 1.41e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.459    |
| fps                | 447      |
| nupdates           | 133400   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2668000  |
| value_loss         | 1.22e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.496    |
| fps                | 447      |
| nupdates           | 133500   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2670000  |
| value_loss         | 1.76e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.448    |
| fps                | 447      |
| nupdates           | 133600   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2672000  |
| value_loss         | 1.77e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.332   |
| fps                | 447      |
| nupdates           | 133700   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2674000  |
| value_loss         | 1.93e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.513    |
| fps                | 447      |
| nupdates           | 133800   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2676000  |
| value_loss         | 6.6e-06  |
---------------------------------
---------------------------------
| explained_variance | 0.539    |
| fps                | 447      |
| nupdates           | 133900   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2678000  |
| value_loss         | 9.65e-06 |
---------------------------------
Eval num_timesteps=2680000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.461    |
| fps                | 447      |
| nupdates           | 134000   |
| policy_entropy     | 2.5      |
| total_timesteps    | 2680000  |
| value_loss         | 4.41e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.569    |
| fps                | 447      |
| nupdates           | 134100   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2682000  |
| value_loss         | 1.06e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.48     |
| fps                | 447      |
| nupdates           | 134200   |
| policy_entropy     | 2.5      |
| total_timesteps    | 2684000  |
| value_loss         | 1.19e-05 |
---------------------------------
---------------------------------
| explained_variance | -1.87    |
| fps                | 447      |
| nupdates           | 134300   |
| policy_entropy     | 2.45     |
| total_timesteps    | 2686000  |
| value_loss         | 6.45e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.86    |
| fps                | 447      |
| nupdates           | 134400   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2688000  |
| value_loss         | 2.54e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.59     |
| fps                | 447      |
| nupdates           | 134500   |
| policy_entropy     | 2.39     |
| total_timesteps    | 2690000  |
| value_loss         | 5.04e-06 |
---------------------------------
---------------------------------
| explained_variance | -0.0572  |
| fps                | 447      |
| nupdates           | 134600   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2692000  |
| value_loss         | 2.68e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.638    |
| fps                | 447      |
| nupdates           | 134700   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2694000  |
| value_loss         | 8.61e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.748    |
| fps                | 447      |
| nupdates           | 134800   |
| policy_entropy     | 2.45     |
| total_timesteps    | 2696000  |
| value_loss         | 6.57e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.589    |
| fps                | 447      |
| nupdates           | 134900   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2698000  |
| value_loss         | 1.45e-05 |
---------------------------------
Eval num_timesteps=2700000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.821    |
| fps                | 447      |
| nupdates           | 135000   |
| policy_entropy     | 2.39     |
| total_timesteps    | 2700000  |
| value_loss         | 1.84e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.322    |
| fps                | 447      |
| nupdates           | 135100   |
| policy_entropy     | 2.4      |
| total_timesteps    | 2702000  |
| value_loss         | 1.6e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.628    |
| fps                | 447      |
| nupdates           | 135200   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2704000  |
| value_loss         | 8.52e-06 |
---------------------------------
---------------------------------
| explained_variance | -0.371   |
| fps                | 447      |
| nupdates           | 135300   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2706000  |
| value_loss         | 5.81e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.494    |
| fps                | 447      |
| nupdates           | 135400   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2708000  |
| value_loss         | 8.78e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.165    |
| fps                | 447      |
| nupdates           | 135500   |
| policy_entropy     | 2.39     |
| total_timesteps    | 2710000  |
| value_loss         | 1.32e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.454   |
| fps                | 447      |
| nupdates           | 135600   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2712000  |
| value_loss         | 3.79e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.493    |
| fps                | 447      |
| nupdates           | 135700   |
| policy_entropy     | 2.52     |
| total_timesteps    | 2714000  |
| value_loss         | 2.28e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.94     |
| fps                | 447      |
| nupdates           | 135800   |
| policy_entropy     | 2.39     |
| total_timesteps    | 2716000  |
| value_loss         | 5.37e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.532    |
| fps                | 447      |
| nupdates           | 135900   |
| policy_entropy     | 2.5      |
| total_timesteps    | 2718000  |
| value_loss         | 8.87e-06 |
---------------------------------
Eval num_timesteps=2720000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.698    |
| fps                | 447      |
| nupdates           | 136000   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2720000  |
| value_loss         | 4e-06    |
---------------------------------
---------------------------------
| explained_variance | 0.254    |
| fps                | 447      |
| nupdates           | 136100   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2722000  |
| value_loss         | 7.83e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.857    |
| fps                | 447      |
| nupdates           | 136200   |
| policy_entropy     | 2.4      |
| total_timesteps    | 2724000  |
| value_loss         | 2.14e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.249    |
| fps                | 447      |
| nupdates           | 136300   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2726000  |
| value_loss         | 1.29e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.549    |
| fps                | 447      |
| nupdates           | 136400   |
| policy_entropy     | 2.39     |
| total_timesteps    | 2728000  |
| value_loss         | 5.07e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.58     |
| fps                | 447      |
| nupdates           | 136500   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2730000  |
| value_loss         | 3.6e-06  |
---------------------------------
---------------------------------
| explained_variance | -0.00884 |
| fps                | 447      |
| nupdates           | 136600   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2732000  |
| value_loss         | 3.42e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.335    |
| fps                | 447      |
| nupdates           | 136700   |
| policy_entropy     | 2.5      |
| total_timesteps    | 2734000  |
| value_loss         | 3.69e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.325    |
| fps                | 447      |
| nupdates           | 136800   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2736000  |
| value_loss         | 1.37e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.668    |
| fps                | 447      |
| nupdates           | 136900   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2738000  |
| value_loss         | 6.27e-06 |
---------------------------------
Eval num_timesteps=2740000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.552    |
| fps                | 447      |
| nupdates           | 137000   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2740000  |
| value_loss         | 7.8e-06  |
---------------------------------
---------------------------------
| explained_variance | -0.104   |
| fps                | 447      |
| nupdates           | 137100   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2742000  |
| value_loss         | 5.18e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.637    |
| fps                | 447      |
| nupdates           | 137200   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2744000  |
| value_loss         | 1.72e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.333    |
| fps                | 447      |
| nupdates           | 137300   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2746000  |
| value_loss         | 3.73e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.575    |
| fps                | 447      |
| nupdates           | 137400   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2748000  |
| value_loss         | 7.45e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.277    |
| fps                | 447      |
| nupdates           | 137500   |
| policy_entropy     | 2.56     |
| total_timesteps    | 2750000  |
| value_loss         | 3.91e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.661    |
| fps                | 447      |
| nupdates           | 137600   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2752000  |
| value_loss         | 5.89e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.215    |
| fps                | 447      |
| nupdates           | 137700   |
| policy_entropy     | 2.53     |
| total_timesteps    | 2754000  |
| value_loss         | 1.83e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.527    |
| fps                | 447      |
| nupdates           | 137800   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2756000  |
| value_loss         | 1.52e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.613    |
| fps                | 447      |
| nupdates           | 137900   |
| policy_entropy     | 2.45     |
| total_timesteps    | 2758000  |
| value_loss         | 4.91e-06 |
---------------------------------
Eval num_timesteps=2760000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.609    |
| fps                | 447      |
| nupdates           | 138000   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2760000  |
| value_loss         | 6.02e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.497    |
| fps                | 447      |
| nupdates           | 138100   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2762000  |
| value_loss         | 1.86e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.454    |
| fps                | 447      |
| nupdates           | 138200   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2764000  |
| value_loss         | 1.72e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.303    |
| fps                | 447      |
| nupdates           | 138300   |
| policy_entropy     | 2.54     |
| total_timesteps    | 2766000  |
| value_loss         | 8.93e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.502    |
| fps                | 447      |
| nupdates           | 138400   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2768000  |
| value_loss         | 1.45e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.346    |
| fps                | 447      |
| nupdates           | 138500   |
| policy_entropy     | 2.53     |
| total_timesteps    | 2770000  |
| value_loss         | 2.52e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.603    |
| fps                | 447      |
| nupdates           | 138600   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2772000  |
| value_loss         | 1.07e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.589    |
| fps                | 447      |
| nupdates           | 138700   |
| policy_entropy     | 2.52     |
| total_timesteps    | 2774000  |
| value_loss         | 1.07e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.634    |
| fps                | 447      |
| nupdates           | 138800   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2776000  |
| value_loss         | 5.56e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.598    |
| fps                | 447      |
| nupdates           | 138900   |
| policy_entropy     | 2.39     |
| total_timesteps    | 2778000  |
| value_loss         | 6.47e-06 |
---------------------------------
Eval num_timesteps=2780000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.536    |
| fps                | 447      |
| nupdates           | 139000   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2780000  |
| value_loss         | 1.18e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.542    |
| fps                | 447      |
| nupdates           | 139100   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2782000  |
| value_loss         | 2.08e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.676    |
| fps                | 447      |
| nupdates           | 139200   |
| policy_entropy     | 2.45     |
| total_timesteps    | 2784000  |
| value_loss         | 1.46e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.494    |
| fps                | 447      |
| nupdates           | 139300   |
| policy_entropy     | 2.52     |
| total_timesteps    | 2786000  |
| value_loss         | 2.79e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.484    |
| fps                | 447      |
| nupdates           | 139400   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2788000  |
| value_loss         | 1.65e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.372    |
| fps                | 447      |
| nupdates           | 139500   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2790000  |
| value_loss         | 3.76e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.591    |
| fps                | 447      |
| nupdates           | 139600   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2792000  |
| value_loss         | 1.41e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.102    |
| fps                | 447      |
| nupdates           | 139700   |
| policy_entropy     | 2.56     |
| total_timesteps    | 2794000  |
| value_loss         | 6.45e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.622    |
| fps                | 447      |
| nupdates           | 139800   |
| policy_entropy     | 2.47     |
| total_timesteps    | 2796000  |
| value_loss         | 7.79e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.718    |
| fps                | 447      |
| nupdates           | 139900   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2798000  |
| value_loss         | 3.76e-06 |
---------------------------------
Eval num_timesteps=2800000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.551    |
| fps                | 447      |
| nupdates           | 140000   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2800000  |
| value_loss         | 9.31e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.793    |
| fps                | 447      |
| nupdates           | 140100   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2802000  |
| value_loss         | 3.19e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.37     |
| fps                | 447      |
| nupdates           | 140200   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2804000  |
| value_loss         | 8.55e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.501    |
| fps                | 447      |
| nupdates           | 140300   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2806000  |
| value_loss         | 1.31e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.624    |
| fps                | 447      |
| nupdates           | 140400   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2808000  |
| value_loss         | 1.03e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.406    |
| fps                | 447      |
| nupdates           | 140500   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2810000  |
| value_loss         | 8.88e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.54     |
| fps                | 447      |
| nupdates           | 140600   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2812000  |
| value_loss         | 9.38e-06 |
---------------------------------
---------------------------------
| explained_variance | -0.333   |
| fps                | 447      |
| nupdates           | 140700   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2814000  |
| value_loss         | 2.86e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.681    |
| fps                | 447      |
| nupdates           | 140800   |
| policy_entropy     | 2.4      |
| total_timesteps    | 2816000  |
| value_loss         | 1.89e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.656    |
| fps                | 447      |
| nupdates           | 140900   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2818000  |
| value_loss         | 7.93e-06 |
---------------------------------
Eval num_timesteps=2820000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.841    |
| fps                | 447      |
| nupdates           | 141000   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2820000  |
| value_loss         | 2.04e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.753    |
| fps                | 447      |
| nupdates           | 141100   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2822000  |
| value_loss         | 5.43e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.719    |
| fps                | 447      |
| nupdates           | 141200   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2824000  |
| value_loss         | 5.06e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.522    |
| fps                | 447      |
| nupdates           | 141300   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2826000  |
| value_loss         | 1.19e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.503    |
| fps                | 447      |
| nupdates           | 141400   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2828000  |
| value_loss         | 9.73e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.524    |
| fps                | 447      |
| nupdates           | 141500   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2830000  |
| value_loss         | 1.78e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.585    |
| fps                | 447      |
| nupdates           | 141600   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2832000  |
| value_loss         | 5.35e-06 |
---------------------------------
---------------------------------
| explained_variance | -0.563   |
| fps                | 447      |
| nupdates           | 141700   |
| policy_entropy     | 2.45     |
| total_timesteps    | 2834000  |
| value_loss         | 2.82e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.666    |
| fps                | 447      |
| nupdates           | 141800   |
| policy_entropy     | 2.39     |
| total_timesteps    | 2836000  |
| value_loss         | 2.47e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.262    |
| fps                | 447      |
| nupdates           | 141900   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2838000  |
| value_loss         | 5.99e-06 |
---------------------------------
Eval num_timesteps=2840000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.328    |
| fps                | 447      |
| nupdates           | 142000   |
| policy_entropy     | 2.4      |
| total_timesteps    | 2840000  |
| value_loss         | 1.19e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.354    |
| fps                | 447      |
| nupdates           | 142100   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2842000  |
| value_loss         | 2.89e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.512    |
| fps                | 447      |
| nupdates           | 142200   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2844000  |
| value_loss         | 1.02e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.464    |
| fps                | 447      |
| nupdates           | 142300   |
| policy_entropy     | 2.45     |
| total_timesteps    | 2846000  |
| value_loss         | 1.81e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.659    |
| fps                | 447      |
| nupdates           | 142400   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2848000  |
| value_loss         | 6.32e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.665    |
| fps                | 447      |
| nupdates           | 142500   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2850000  |
| value_loss         | 5.89e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.65     |
| fps                | 447      |
| nupdates           | 142600   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2852000  |
| value_loss         | 1.35e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.577    |
| fps                | 447      |
| nupdates           | 142700   |
| policy_entropy     | 2.39     |
| total_timesteps    | 2854000  |
| value_loss         | 4.48e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.787    |
| fps                | 447      |
| nupdates           | 142800   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2856000  |
| value_loss         | 2.84e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.45     |
| fps                | 447      |
| nupdates           | 142900   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2858000  |
| value_loss         | 1.41e-05 |
---------------------------------
Eval num_timesteps=2860000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.491    |
| fps                | 447      |
| nupdates           | 143000   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2860000  |
| value_loss         | 1.5e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.72     |
| fps                | 447      |
| nupdates           | 143100   |
| policy_entropy     | 2.39     |
| total_timesteps    | 2862000  |
| value_loss         | 3.07e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.501    |
| fps                | 447      |
| nupdates           | 143200   |
| policy_entropy     | 2.56     |
| total_timesteps    | 2864000  |
| value_loss         | 2.59e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.149    |
| fps                | 447      |
| nupdates           | 143300   |
| policy_entropy     | 2.5      |
| total_timesteps    | 2866000  |
| value_loss         | 9.95e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.68     |
| fps                | 447      |
| nupdates           | 143400   |
| policy_entropy     | 2.39     |
| total_timesteps    | 2868000  |
| value_loss         | 4.49e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.523    |
| fps                | 447      |
| nupdates           | 143500   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2870000  |
| value_loss         | 5.65e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.503    |
| fps                | 447      |
| nupdates           | 143600   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2872000  |
| value_loss         | 1.34e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.0364  |
| fps                | 447      |
| nupdates           | 143700   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2874000  |
| value_loss         | 8.45e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.383    |
| fps                | 447      |
| nupdates           | 143800   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2876000  |
| value_loss         | 1.86e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.662    |
| fps                | 447      |
| nupdates           | 143900   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2878000  |
| value_loss         | 1.17e-05 |
---------------------------------
Eval num_timesteps=2880000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -0.0187  |
| fps                | 447      |
| nupdates           | 144000   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2880000  |
| value_loss         | 1.18e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.353    |
| fps                | 447      |
| nupdates           | 144100   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2882000  |
| value_loss         | 1.66e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.533    |
| fps                | 447      |
| nupdates           | 144200   |
| policy_entropy     | 2.5      |
| total_timesteps    | 2884000  |
| value_loss         | 1.24e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.48     |
| fps                | 447      |
| nupdates           | 144300   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2886000  |
| value_loss         | 2.16e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.701    |
| fps                | 447      |
| nupdates           | 144400   |
| policy_entropy     | 2.36     |
| total_timesteps    | 2888000  |
| value_loss         | 7.56e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.629    |
| fps                | 447      |
| nupdates           | 144500   |
| policy_entropy     | 2.53     |
| total_timesteps    | 2890000  |
| value_loss         | 1.19e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.506    |
| fps                | 447      |
| nupdates           | 144600   |
| policy_entropy     | 2.5      |
| total_timesteps    | 2892000  |
| value_loss         | 1.07e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.15     |
| fps                | 447      |
| nupdates           | 144700   |
| policy_entropy     | 2.56     |
| total_timesteps    | 2894000  |
| value_loss         | 6.58e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.274    |
| fps                | 447      |
| nupdates           | 144800   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2896000  |
| value_loss         | 1.26e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.623    |
| fps                | 447      |
| nupdates           | 144900   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2898000  |
| value_loss         | 5.37e-06 |
---------------------------------
Eval num_timesteps=2900000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -0.0706  |
| fps                | 447      |
| nupdates           | 145000   |
| policy_entropy     | 2.48     |
| total_timesteps    | 2900000  |
| value_loss         | 1.69e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.728    |
| fps                | 447      |
| nupdates           | 145100   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2902000  |
| value_loss         | 1e-05    |
---------------------------------
---------------------------------
| explained_variance | 0.677    |
| fps                | 447      |
| nupdates           | 145200   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2904000  |
| value_loss         | 6.22e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.318    |
| fps                | 447      |
| nupdates           | 145300   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2906000  |
| value_loss         | 1.58e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.854    |
| fps                | 447      |
| nupdates           | 145400   |
| policy_entropy     | 2.45     |
| total_timesteps    | 2908000  |
| value_loss         | 7.37e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.643    |
| fps                | 447      |
| nupdates           | 145500   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2910000  |
| value_loss         | 8.08e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.578    |
| fps                | 447      |
| nupdates           | 145600   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2912000  |
| value_loss         | 7.42e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.856    |
| fps                | 447      |
| nupdates           | 145700   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2914000  |
| value_loss         | 1.77e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.6      |
| fps                | 447      |
| nupdates           | 145800   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2916000  |
| value_loss         | 9.1e-06  |
---------------------------------
---------------------------------
| explained_variance | 0.338    |
| fps                | 447      |
| nupdates           | 145900   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2918000  |
| value_loss         | 1.4e-05  |
---------------------------------
Eval num_timesteps=2920000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | -0.924   |
| fps                | 447      |
| nupdates           | 146000   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2920000  |
| value_loss         | 0.000204 |
---------------------------------
---------------------------------
| explained_variance | 0.476    |
| fps                | 447      |
| nupdates           | 146100   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2922000  |
| value_loss         | 1.79e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.0516  |
| fps                | 447      |
| nupdates           | 146200   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2924000  |
| value_loss         | 6.35e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.178   |
| fps                | 447      |
| nupdates           | 146300   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2926000  |
| value_loss         | 6.11e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.423    |
| fps                | 447      |
| nupdates           | 146400   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2928000  |
| value_loss         | 1.75e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.484    |
| fps                | 447      |
| nupdates           | 146500   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2930000  |
| value_loss         | 1.63e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.456    |
| fps                | 447      |
| nupdates           | 146600   |
| policy_entropy     | 2.52     |
| total_timesteps    | 2932000  |
| value_loss         | 1.53e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.526    |
| fps                | 447      |
| nupdates           | 146700   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2934000  |
| value_loss         | 8.88e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.582    |
| fps                | 447      |
| nupdates           | 146800   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2936000  |
| value_loss         | 1.01e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.646    |
| fps                | 447      |
| nupdates           | 146900   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2938000  |
| value_loss         | 7.02e-06 |
---------------------------------
Eval num_timesteps=2940000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.603    |
| fps                | 447      |
| nupdates           | 147000   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2940000  |
| value_loss         | 6.42e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.667    |
| fps                | 447      |
| nupdates           | 147100   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2942000  |
| value_loss         | 8.25e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.55     |
| fps                | 447      |
| nupdates           | 147200   |
| policy_entropy     | 2.53     |
| total_timesteps    | 2944000  |
| value_loss         | 1.23e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.174   |
| fps                | 447      |
| nupdates           | 147300   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2946000  |
| value_loss         | 1.62e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.479    |
| fps                | 447      |
| nupdates           | 147400   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2948000  |
| value_loss         | 1.59e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.565    |
| fps                | 447      |
| nupdates           | 147500   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2950000  |
| value_loss         | 1.11e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.595    |
| fps                | 447      |
| nupdates           | 147600   |
| policy_entropy     | 2.48     |
| total_timesteps    | 2952000  |
| value_loss         | 6.68e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.567    |
| fps                | 447      |
| nupdates           | 147700   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2954000  |
| value_loss         | 6.2e-06  |
---------------------------------
---------------------------------
| explained_variance | 0.528    |
| fps                | 447      |
| nupdates           | 147800   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2956000  |
| value_loss         | 1.7e-05  |
---------------------------------
---------------------------------
| explained_variance | 0.797    |
| fps                | 447      |
| nupdates           | 147900   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2958000  |
| value_loss         | 2.75e-06 |
---------------------------------
Eval num_timesteps=2960000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.489    |
| fps                | 447      |
| nupdates           | 148000   |
| policy_entropy     | 2.52     |
| total_timesteps    | 2960000  |
| value_loss         | 1.41e-05 |
---------------------------------
---------------------------------
| explained_variance | -0.0297  |
| fps                | 447      |
| nupdates           | 148100   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2962000  |
| value_loss         | 2.43e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.426    |
| fps                | 447      |
| nupdates           | 148200   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2964000  |
| value_loss         | 3.31e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.576    |
| fps                | 447      |
| nupdates           | 148300   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2966000  |
| value_loss         | 5.21e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.622    |
| fps                | 447      |
| nupdates           | 148400   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2968000  |
| value_loss         | 1.44e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.581    |
| fps                | 447      |
| nupdates           | 148500   |
| policy_entropy     | 2.4      |
| total_timesteps    | 2970000  |
| value_loss         | 7.81e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.463    |
| fps                | 447      |
| nupdates           | 148600   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2972000  |
| value_loss         | 1.21e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.611    |
| fps                | 447      |
| nupdates           | 148700   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2974000  |
| value_loss         | 4.52e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.454    |
| fps                | 447      |
| nupdates           | 148800   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2976000  |
| value_loss         | 2.91e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.605    |
| fps                | 447      |
| nupdates           | 148900   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2978000  |
| value_loss         | 1.2e-05  |
---------------------------------
Eval num_timesteps=2980000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.649    |
| fps                | 447      |
| nupdates           | 149000   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2980000  |
| value_loss         | 7.69e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.336    |
| fps                | 447      |
| nupdates           | 149100   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2982000  |
| value_loss         | 2.93e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.645    |
| fps                | 447      |
| nupdates           | 149200   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2984000  |
| value_loss         | 6.02e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.657    |
| fps                | 447      |
| nupdates           | 149300   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2986000  |
| value_loss         | 6.03e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.339    |
| fps                | 447      |
| nupdates           | 149400   |
| policy_entropy     | 2.42     |
| total_timesteps    | 2988000  |
| value_loss         | 9.14e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.686    |
| fps                | 447      |
| nupdates           | 149500   |
| policy_entropy     | 2.46     |
| total_timesteps    | 2990000  |
| value_loss         | 5.82e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.399    |
| fps                | 447      |
| nupdates           | 149600   |
| policy_entropy     | 2.52     |
| total_timesteps    | 2992000  |
| value_loss         | 3.32e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.521    |
| fps                | 447      |
| nupdates           | 149700   |
| policy_entropy     | 2.49     |
| total_timesteps    | 2994000  |
| value_loss         | 1.58e-05 |
---------------------------------
---------------------------------
| explained_variance | 0.57     |
| fps                | 447      |
| nupdates           | 149800   |
| policy_entropy     | 2.43     |
| total_timesteps    | 2996000  |
| value_loss         | 4.99e-06 |
---------------------------------
---------------------------------
| explained_variance | 0.37     |
| fps                | 447      |
| nupdates           | 149900   |
| policy_entropy     | 2.52     |
| total_timesteps    | 2998000  |
| value_loss         | 8.54e-05 |
---------------------------------
Eval num_timesteps=3000000, episode_reward=-0.50 +/- 0.00
Episode length: 2.00 +/- 0.00
---------------------------------
| explained_variance | 0.591    |
| fps                | 447      |
| nupdates           | 150000   |
| policy_entropy     | 2.46     |
| total_timesteps    | 3000000  |
| value_loss         | 5.9e-06  |
---------------------------------
Job 291271 is done!
